{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "get_baseline_pretrained_sincos_resnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuAdol1Acd6A",
        "outputId": "d87bff0b-8445-4129-9374-147e2b732275"
      },
      "source": [
        "# install tape \n",
        "!pip install tape_proteins"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tape_proteins\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/f7/bdfe0ef6fd6ffb45f55c944176f518b0bc6ea0c9dddba0816578fb0e7290/tape_proteins-0.4-py3-none-any.whl (68kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 20kB 17.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 30kB 12.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 40kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 51kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: lmdb in /usr/local/lib/python3.6/dist-packages (from tape_proteins) (0.99)\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 11.3MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/9c/544396572c05841b7a2482c88be5dd54dcd18ba97abeb1e8d34daf921a54/boto3-1.16.30-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 15.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from tape_proteins) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tape_proteins) (4.41.1)\n",
            "Collecting torch<1.5,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 15kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tape_proteins) (1.4.1)\n",
            "Collecting biopython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/02/8b606c4aa92ff61b5eda71d23b499ab1de57d5e818be33f77b01a6f435a8/biopython-1.78-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 51.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->tape_proteins) (3.12.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX->tape_proteins) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->tape_proteins) (1.15.0)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.20.0,>=1.19.30\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/a3/1ee497faf994d180df5d14d456eef1ef46ca1ffce617816faa4ff8164608/botocore-1.19.30-py2.py3-none-any.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 50.3MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 11.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->tape_proteins) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->tape_proteins) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->tape_proteins) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->tape_proteins) (2.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX->tape_proteins) (50.3.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.30->boto3->tape_proteins) (2.8.1)\n",
            "\u001b[31mERROR: torchvision 0.8.1+cu101 has requirement torch==1.7.0, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.19.30 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboardX, jmespath, botocore, s3transfer, boto3, torch, biopython, tape-proteins\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "Successfully installed biopython-1.78 boto3-1.16.30 botocore-1.19.30 jmespath-0.10.0 s3transfer-0.3.3 tape-proteins-0.4 tensorboardX-2.1 torch-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qgGoCG8clGj",
        "outputId": "1d84fddf-7077-4db1-b11f-bc59ff4c5da3"
      },
      "source": [
        "!mkdir ./data\n",
        "!wget http://s3.amazonaws.com/proteindata/data_pytorch/fluorescence.tar.gz\n",
        "!tar -xzf fluorescence.tar.gz -C ./data\n",
        "!rm fluorescence.tar.gz\n",
        "!wget http://s3.amazonaws.com/proteindata/data_pytorch/proteinnet.tar.gz\n",
        "!tar -xzf proteinnet.tar.gz -C ./data\n",
        "!rm proteinnet.tar.gz\n",
        "!wget http://s3.amazonaws.com/proteindata/data_pytorch/remote_homology.tar.gz\n",
        "!tar -xzf remote_homology.tar.gz -C ./data\n",
        "!rm remote_homology.tar.gz\n",
        "!wget http://s3.amazonaws.com/proteindata/data_pytorch/secondary_structure.tar.gz\n",
        "!tar -xzf secondary_structure.tar.gz -C ./data\n",
        "!rm secondary_structure.tar.gz\n",
        "!wget http://s3.amazonaws.com/proteindata/data_pytorch/stability.tar.gz\n",
        "!tar -xzf stability.tar.gz -C ./data\n",
        "!rm stability.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-06 14:40:37--  http://s3.amazonaws.com/proteindata/data_pytorch/fluorescence.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.152.38\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.152.38|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1635678 (1.6M) [application/x-tar]\n",
            "Saving to: ‘fluorescence.tar.gz’\n",
            "\n",
            "fluorescence.tar.gz 100%[===================>]   1.56M  3.59MB/s    in 0.4s    \n",
            "\n",
            "2020-12-06 14:40:38 (3.59 MB/s) - ‘fluorescence.tar.gz’ saved [1635678/1635678]\n",
            "\n",
            "--2020-12-06 14:40:38--  http://s3.amazonaws.com/proteindata/data_pytorch/proteinnet.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.161.157\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.161.157|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 464501179 (443M) [application/x-tar]\n",
            "Saving to: ‘proteinnet.tar.gz’\n",
            "\n",
            "proteinnet.tar.gz   100%[===================>] 442.98M  37.9MB/s    in 11s     \n",
            "\n",
            "2020-12-06 14:40:50 (39.5 MB/s) - ‘proteinnet.tar.gz’ saved [464501179/464501179]\n",
            "\n",
            "--2020-12-06 14:40:58--  http://s3.amazonaws.com/proteindata/data_pytorch/remote_homology.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.104.221\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.104.221|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43581262 (42M) [application/x-tar]\n",
            "Saving to: ‘remote_homology.tar.gz’\n",
            "\n",
            "remote_homology.tar 100%[===================>]  41.56M  31.9MB/s    in 1.3s    \n",
            "\n",
            "2020-12-06 14:41:00 (31.9 MB/s) - ‘remote_homology.tar.gz’ saved [43581262/43581262]\n",
            "\n",
            "--2020-12-06 14:41:10--  http://s3.amazonaws.com/proteindata/data_pytorch/secondary_structure.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.144.29\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.144.29|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 251794897 (240M) [application/x-tar]\n",
            "Saving to: ‘secondary_structure.tar.gz’\n",
            "\n",
            "secondary_structure 100%[===================>] 240.13M  40.6MB/s    in 6.1s    \n",
            "\n",
            "2020-12-06 14:41:16 (39.6 MB/s) - ‘secondary_structure.tar.gz’ saved [251794897/251794897]\n",
            "\n",
            "--2020-12-06 14:41:28--  http://s3.amazonaws.com/proteindata/data_pytorch/stability.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.8.238\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.8.238|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3116829 (3.0M) [application/x-tar]\n",
            "Saving to: ‘stability.tar.gz’\n",
            "\n",
            "stability.tar.gz    100%[===================>]   2.97M  6.50MB/s    in 0.5s    \n",
            "\n",
            "2020-12-06 14:41:29 (6.50 MB/s) - ‘stability.tar.gz’ saved [3116829/3116829]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUUCJPasfopg",
        "outputId": "f61c85d5-3056-46ee-b0cb-77c02611ea58"
      },
      "source": [
        "%%bash\n",
        "\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "cd apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-zqfots2_\n",
            "Created temporary directory: /tmp/pip-req-tracker-xbku54t1\n",
            "Created requirements tracker '/tmp/pip-req-tracker-xbku54t1'\n",
            "Created temporary directory: /tmp/pip-install-0_wdsdd3\n",
            "Processing /content/apex\n",
            "  Created temporary directory: /tmp/pip-req-build-qs8na37f\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-xbku54t1'\n",
            "    Running setup.py (path:/tmp/pip-req-build-qs8na37f/setup.py) egg_info for package from file:///content/apex\n",
            "  Source in /tmp/pip-req-build-qs8na37f has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-xbku54t1'\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-record-55oj5uz1\n",
            "    Running setup.py install for apex: started\n",
            "    Running setup.py install for apex: finished with status 'done'\n",
            "  Removing source in /tmp/pip-req-build-qs8na37f\n",
            "Successfully installed apex-0.1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-xbku54t1'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.4.0\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-qs8na37f/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-qs8na37f/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-qs8na37f/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-qs8na37f/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-qs8na37f/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-req-build-qs8na37f/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-qs8na37f/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-qs8na37f/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-qs8na37f/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-55oj5uz1/install-record.txt --single-version-externally-managed --compile\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.4.0\n",
            "\n",
            "\n",
            "    /tmp/pip-req-build-qs8na37f/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "    Compiling cuda extensions with\n",
            "    nvcc: NVIDIA (R) Cuda compiler driver\n",
            "    Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "    Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "    Cuda compilation tools, release 10.1, V10.1.243\n",
            "    from /usr/local/cuda/bin\n",
            "\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    creating build\n",
            "    creating build/lib.linux-x86_64-3.6\n",
            "    creating build/lib.linux-x86_64-3.6/apex\n",
            "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
            "    creating build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    running build_ext\n",
            "    building 'apex_C' extension\n",
            "    creating build/temp.linux-x86_64-3.6\n",
            "    creating build/temp.linux-x86_64-3.6/csrc\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'amp_C' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'syncbn' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'fused_layer_norm_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'mlp_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.6/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
            "    csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                        ^\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:116:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:31:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
            "    csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < inputs.size(); i++) {\n",
            "                       ~~^~~~~~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:116:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:31:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=sm_75 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(97): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(112): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(97): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(112): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/mlp.o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    running install_lib\n",
            "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
            "    running install_egg_info\n",
            "    running egg_info\n",
            "    creating apex.egg-info\n",
            "    writing apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to apex.egg-info/top_level.txt\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
            "    running install_scripts\n",
            "    writing list of installed files to '/tmp/pip-record-55oj5uz1/install-record.txt'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4l_OLNzfor7",
        "outputId": "18240c68-c3e4-4b66-dfef-1bd72f85a9f4"
      },
      "source": [
        "%%writefile /usr/local/lib/python3.6/dist-packages/tape/datasets.py\n",
        "\n",
        "from typing import Union, List, Tuple, Sequence, Dict, Any, Optional, Collection\n",
        "from copy import copy\n",
        "from pathlib import Path\n",
        "import pickle as pkl\n",
        "import logging\n",
        "import random\n",
        "\n",
        "import lmdb\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "from .tokenizers import TAPETokenizer\n",
        "from .registry import registry\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def dataset_factory(data_file: Union[str, Path], *args, **kwargs) -> Dataset:\n",
        "    data_file = Path(data_file)\n",
        "    if not data_file.exists():\n",
        "        raise FileNotFoundError(data_file)\n",
        "    if data_file.suffix == '.lmdb':\n",
        "        return LMDBDataset(data_file, *args, **kwargs)\n",
        "    elif data_file.suffix in {'.fasta', '.fna', '.ffn', '.faa', '.frn'}:\n",
        "        return FastaDataset(data_file, *args, **kwargs)\n",
        "    elif data_file.suffix == '.json':\n",
        "        return JSONDataset(data_file, *args, **kwargs)\n",
        "    elif data_file.is_dir():\n",
        "        return NPZDataset(data_file, *args, **kwargs)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized datafile type {data_file.suffix}\")\n",
        "\n",
        "\n",
        "def pad_sequences(sequences: Sequence, constant_value=0, dtype=None) -> np.ndarray:\n",
        "    batch_size = len(sequences)\n",
        "    shape = [batch_size] + np.max([seq.shape for seq in sequences], 0).tolist()\n",
        "\n",
        "    if dtype is None:\n",
        "        dtype = sequences[0].dtype\n",
        "\n",
        "    if isinstance(sequences[0], np.ndarray):\n",
        "        array = np.full(shape, constant_value, dtype=dtype)\n",
        "    elif isinstance(sequences[0], torch.Tensor):\n",
        "        array = torch.full(shape, constant_value, dtype=dtype)\n",
        "\n",
        "    for arr, seq in zip(array, sequences):\n",
        "        arrslice = tuple(slice(dim) for dim in seq.shape)\n",
        "        arr[arrslice] = seq\n",
        "\n",
        "    return array\n",
        "\n",
        "\n",
        "class FastaDataset(Dataset):\n",
        "    \"\"\"Creates a dataset from a fasta file.\n",
        "    Args:\n",
        "        data_file (Union[str, Path]): Path to fasta file.\n",
        "        in_memory (bool, optional): Whether to load the full dataset into memory.\n",
        "            Default: False.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_file: Union[str, Path],\n",
        "                 in_memory: bool = False):\n",
        "\n",
        "        from Bio import SeqIO\n",
        "        data_file = Path(data_file)\n",
        "        if not data_file.exists():\n",
        "            raise FileNotFoundError(data_file)\n",
        "\n",
        "        # if in_memory:\n",
        "        cache = list(SeqIO.parse(str(data_file), 'fasta'))\n",
        "        num_examples = len(cache)\n",
        "        self._cache = cache\n",
        "        # else:\n",
        "            # records = SeqIO.index(str(data_file), 'fasta')\n",
        "            # num_examples = len(records)\n",
        "#\n",
        "            # if num_examples < 10000:\n",
        "                # logger.info(\"Reading full fasta file into memory because number of examples \"\n",
        "                            # \"is very low. This loads data approximately 20x faster.\")\n",
        "                # in_memory = True\n",
        "                # cache = list(records.values())\n",
        "                # self._cache = cache\n",
        "            # else:\n",
        "                # self._records = records\n",
        "                # self._keys = list(records.keys())\n",
        "\n",
        "        self._in_memory = in_memory\n",
        "        self._num_examples = num_examples\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self._num_examples\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        if not 0 <= index < self._num_examples:\n",
        "            raise IndexError(index)\n",
        "\n",
        "        # if self._in_memory and self._cache[index] is not None:\n",
        "        record = self._cache[index]\n",
        "        # else:\n",
        "            # key = self._keys[index]\n",
        "            # record = self._records[key]\n",
        "            # if self._in_memory:\n",
        "                # self._cache[index] = record\n",
        "\n",
        "        item = {'id': record.id,\n",
        "                'primary': str(record.seq),\n",
        "                'protein_length': len(record.seq)}\n",
        "        return item\n",
        "\n",
        "\n",
        "class LMDBDataset(Dataset):\n",
        "    \"\"\"Creates a dataset from an lmdb file.\n",
        "    Args:\n",
        "        data_file (Union[str, Path]): Path to lmdb file.\n",
        "        in_memory (bool, optional): Whether to load the full dataset into memory.\n",
        "            Default: False.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_file: Union[str, Path],\n",
        "                 in_memory: bool = False):\n",
        "\n",
        "        data_file = Path(data_file)\n",
        "        if not data_file.exists():\n",
        "            raise FileNotFoundError(data_file)\n",
        "\n",
        "        env = lmdb.open(str(data_file), max_readers=1, readonly=True,\n",
        "                        lock=False, readahead=False, meminit=False)\n",
        "\n",
        "        with env.begin(write=False) as txn:\n",
        "            num_examples = pkl.loads(txn.get(b'num_examples'))\n",
        "\n",
        "        if in_memory:\n",
        "            cache = [None] * num_examples\n",
        "            self._cache = cache\n",
        "\n",
        "        self._env = env\n",
        "        self._in_memory = in_memory\n",
        "        self._num_examples = num_examples\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self._num_examples\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        if not 0 <= index < self._num_examples:\n",
        "            raise IndexError(index)\n",
        "\n",
        "        if self._in_memory and self._cache[index] is not None:\n",
        "            item = self._cache[index]\n",
        "        else:\n",
        "            with self._env.begin(write=False) as txn:\n",
        "                item = pkl.loads(txn.get(str(index).encode()))\n",
        "                if 'id' not in item:\n",
        "                    item['id'] = str(index)\n",
        "                if self._in_memory:\n",
        "                    self._cache[index] = item\n",
        "        return item\n",
        "\n",
        "\n",
        "class JSONDataset(Dataset):\n",
        "    \"\"\"Creates a dataset from a json file. Assumes that data is\n",
        "       a JSON serialized list of record, where each record is\n",
        "       a dictionary.\n",
        "    Args:\n",
        "        data_file (Union[str, Path]): Path to json file.\n",
        "        in_memory (bool): Dummy variable to match API of other datasets\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_file: Union[str, Path], in_memory: bool = True):\n",
        "        import json\n",
        "        data_file = Path(data_file)\n",
        "        if not data_file.exists():\n",
        "            raise FileNotFoundError(data_file)\n",
        "        records = json.loads(data_file.read_text())\n",
        "\n",
        "        if not isinstance(records, list):\n",
        "            raise TypeError(f\"TAPE JSONDataset requires a json serialized list, \"\n",
        "                            f\"received {type(records)}\")\n",
        "        self._records = records\n",
        "        self._num_examples = len(records)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self._num_examples\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        if not 0 <= index < self._num_examples:\n",
        "            raise IndexError(index)\n",
        "\n",
        "        item = self._records[index]\n",
        "        if not isinstance(item, dict):\n",
        "            raise TypeError(f\"Expected dataset to contain a list of dictionary \"\n",
        "                            f\"records, received record of type {type(item)}\")\n",
        "        if 'id' not in item:\n",
        "            item['id'] = str(index)\n",
        "        return item\n",
        "\n",
        "\n",
        "class NPZDataset(Dataset):\n",
        "    \"\"\"Creates a dataset from a directory of npz files.\n",
        "    Args:\n",
        "        data_file (Union[str, Path]): Path to directory of npz files\n",
        "        in_memory (bool): Dummy variable to match API of other datasets\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_file: Union[str, Path],\n",
        "                 in_memory: bool = True,\n",
        "                 split_files: Optional[Collection[str]] = None):\n",
        "        data_file = Path(data_file)\n",
        "        if not data_file.exists():\n",
        "            raise FileNotFoundError(data_file)\n",
        "        if not data_file.is_dir():\n",
        "            raise NotADirectoryError(data_file)\n",
        "        file_glob = data_file.glob('*.npz')\n",
        "        if split_files is None:\n",
        "            file_list = list(file_glob)\n",
        "        else:\n",
        "            split_files = set(split_files)\n",
        "            if len(split_files) == 0:\n",
        "                raise ValueError(\"Passed an empty split file set\")\n",
        "\n",
        "            file_list = [f for f in file_glob if f.name in split_files]\n",
        "            if len(file_list) != len(split_files):\n",
        "                num_missing = len(split_files) - len(file_list)\n",
        "                raise FileNotFoundError(\n",
        "                    f\"{num_missing} specified split files not found in directory\")\n",
        "\n",
        "        if len(file_list) == 0:\n",
        "            raise FileNotFoundError(f\"No .npz files found in {data_file}\")\n",
        "\n",
        "        self._file_list = file_list\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._file_list)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        if not 0 <= index < len(self):\n",
        "            raise IndexError(index)\n",
        "\n",
        "        item = dict(np.load(self._file_list[index]))\n",
        "        if not isinstance(item, dict):\n",
        "            raise TypeError(f\"Expected dataset to contain a list of dictionary \"\n",
        "                            f\"records, received record of type {type(item)}\")\n",
        "        if 'id' not in item:\n",
        "            item['id'] = self._file_list[index].stem\n",
        "        return item\n",
        "\n",
        "\n",
        "@registry.register_task('embed')\n",
        "class EmbedDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_file: Union[str, Path],\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False,\n",
        "                 convert_tokens_to_ids: bool = True):\n",
        "        super().__init__()\n",
        "\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataset_factory(data_file)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        item = self.data[index]\n",
        "        token_ids = self.tokenizer.encode(item['primary'])\n",
        "        input_mask = np.ones_like(token_ids)\n",
        "        return item['id'], token_ids, input_mask\n",
        "\n",
        "    def collate_fn(self, batch: List[Tuple[Any, ...]]) -> Dict[str, torch.Tensor]:\n",
        "        ids, tokens, input_mask = zip(*batch)\n",
        "        ids = list(ids)\n",
        "        tokens = torch.from_numpy(pad_sequences(tokens))\n",
        "        input_mask = torch.from_numpy(pad_sequences(input_mask))\n",
        "        return {'ids': ids, 'input_ids': tokens, 'input_mask': input_mask}  # type: ignore\n",
        "\n",
        "\n",
        "@registry.register_task('masked_language_modeling')\n",
        "class MaskedLanguageModelingDataset(Dataset):\n",
        "    \"\"\"Creates the Masked Language Modeling Pfam Dataset\n",
        "    Args:\n",
        "        data_path (Union[str, Path]): Path to tape data root.\n",
        "        split (str): One of ['train', 'valid', 'holdout'], specifies which data file to load.\n",
        "        in_memory (bool, optional): Whether to load the full dataset into memory.\n",
        "            Default: False.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_path: Union[str, Path],\n",
        "                 split: str,\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False):\n",
        "        super().__init__()\n",
        "        if split not in ('train', 'valid', 'holdout'):\n",
        "            raise ValueError(\n",
        "                f\"Unrecognized split: {split}. \"\n",
        "                f\"Must be one of ['train', 'valid', 'holdout']\")\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        data_path = Path(data_path)\n",
        "        data_file = f'pfam/pfam_{split}.lmdb'\n",
        "        self.data = dataset_factory(data_path / data_file, in_memory)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        tokens = self.tokenizer.tokenize(item['primary'])\n",
        "        tokens = self.tokenizer.add_special_tokens(tokens)\n",
        "        masked_tokens, labels = self._apply_bert_mask(tokens)\n",
        "        masked_token_ids = np.array(\n",
        "            self.tokenizer.convert_tokens_to_ids(masked_tokens), np.int64)\n",
        "        input_mask = np.ones_like(masked_token_ids)\n",
        "\n",
        "        masked_token_ids = np.array(\n",
        "            self.tokenizer.convert_tokens_to_ids(masked_tokens), np.int64)\n",
        "\n",
        "        return masked_token_ids, input_mask, labels, item['clan'], item['family']\n",
        "\n",
        "    def collate_fn(self, batch: List[Any]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, input_mask, lm_label_ids, clan, family = tuple(zip(*batch))\n",
        "\n",
        "        input_ids = torch.from_numpy(pad_sequences(input_ids, 0))\n",
        "        input_mask = torch.from_numpy(pad_sequences(input_mask, 0))\n",
        "        # ignore_index is -1\n",
        "        lm_label_ids = torch.from_numpy(pad_sequences(lm_label_ids, -1))\n",
        "        clan = torch.LongTensor(clan)  # type: ignore\n",
        "        family = torch.LongTensor(family)  # type: ignore\n",
        "\n",
        "        return {'input_ids': input_ids,\n",
        "                'input_mask': input_mask,\n",
        "                'targets': lm_label_ids}\n",
        "\n",
        "    def _apply_bert_mask(self, tokens: List[str]) -> Tuple[List[str], List[int]]:\n",
        "        masked_tokens = copy(tokens)\n",
        "        labels = np.zeros([len(tokens)], np.int64) - 1\n",
        "\n",
        "        for i, token in enumerate(tokens):\n",
        "            # Tokens begin and end with start_token and stop_token, ignore these\n",
        "            if token in (self.tokenizer.start_token, self.tokenizer.stop_token):\n",
        "                pass\n",
        "\n",
        "            prob = random.random()\n",
        "            if prob < 0.15:\n",
        "                prob /= 0.15\n",
        "                labels[i] = self.tokenizer.convert_token_to_id(token)\n",
        "\n",
        "                if prob < 0.8:\n",
        "                    # 80% random change to mask token\n",
        "                    token = self.tokenizer.mask_token\n",
        "                elif prob < 0.9:\n",
        "                    # 10% chance to change to random token\n",
        "                    token = self.tokenizer.convert_id_to_token(\n",
        "                        random.randint(0, self.tokenizer.vocab_size - 1))\n",
        "                else:\n",
        "                    # 10% chance to keep current token\n",
        "                    pass\n",
        "\n",
        "                masked_tokens[i] = token\n",
        "\n",
        "        return masked_tokens, labels\n",
        "\n",
        "\n",
        "@registry.register_task('language_modeling')\n",
        "class LanguageModelingDataset(Dataset):\n",
        "    \"\"\"Creates the Language Modeling Pfam Dataset\n",
        "    Args:\n",
        "        data_path (Union[str, Path]): Path to tape data root.\n",
        "        split (str): One of ['train', 'valid', 'holdout'], specifies which data file to load.\n",
        "        in_memory (bool, optional): Whether to load the full dataset into memory.\n",
        "            Default: False.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_path: Union[str, Path],\n",
        "                 split: str,\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False):\n",
        "        super().__init__()\n",
        "        if split not in ('train', 'valid', 'holdout'):\n",
        "            raise ValueError(\n",
        "                f\"Unrecognized split: {split}. \"\n",
        "                f\"Must be one of ['train', 'valid', 'holdout']\")\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        data_path = Path(data_path)\n",
        "        data_file = f'pfam/pfam_{split}.lmdb'\n",
        "        self.data = dataset_factory(data_path / data_file, in_memory)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        token_ids = self.tokenizer.encode(item['primary'])\n",
        "        input_mask = np.ones_like(token_ids)\n",
        "\n",
        "        return token_ids, input_mask, item['clan'], item['family']\n",
        "\n",
        "    def collate_fn(self, batch: List[Any]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, input_mask, clan, family = tuple(zip(*batch))\n",
        "\n",
        "        torch_inputs = torch.from_numpy(pad_sequences(input_ids, 0))\n",
        "        input_mask = torch.from_numpy(pad_sequences(input_mask, 0))\n",
        "        # ignore_index is -1\n",
        "        torch_labels = torch.from_numpy(pad_sequences(input_ids, -1))\n",
        "        clan = torch.LongTensor(clan)  # type: ignore\n",
        "        family = torch.LongTensor(family)  # type: ignore\n",
        "\n",
        "        return {'input_ids': torch_inputs,\n",
        "                'input_mask': input_mask,\n",
        "                'targets': torch_labels}\n",
        "\n",
        "\n",
        "@registry.register_task('fluorescence')\n",
        "class FluorescenceDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_path: Union[str, Path],\n",
        "                 split: str,\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False):\n",
        "\n",
        "        if split not in ('train', 'valid', 'test'):\n",
        "            raise ValueError(f\"Unrecognized split: {split}. \"\n",
        "                             f\"Must be one of ['train', 'valid', 'test']\")\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        data_path = Path(data_path)\n",
        "        data_file = f'fluorescence/fluorescence_{split}.lmdb'\n",
        "        self.data = dataset_factory(data_path / data_file, in_memory)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "        # return int(len(self.data) / 4)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        item = self.data[index]\n",
        "        token_ids = self.tokenizer.encode(item['primary'])\n",
        "        input_mask = np.ones_like(token_ids)\n",
        "        return token_ids, input_mask, float(item['log_fluorescence'][0])\n",
        "\n",
        "    def collate_fn(self, batch: List[Tuple[Any, ...]]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, input_mask, fluorescence_true_value = tuple(zip(*batch))\n",
        "        input_ids = torch.from_numpy(pad_sequences(input_ids, 0))\n",
        "        input_mask = torch.from_numpy(pad_sequences(input_mask, 0))\n",
        "        fluorescence_true_value = torch.FloatTensor(fluorescence_true_value)  # type: ignore\n",
        "        fluorescence_true_value = fluorescence_true_value.unsqueeze(1)\n",
        "\n",
        "        return {'input_ids': input_ids,\n",
        "                'input_mask': input_mask,\n",
        "                'targets': fluorescence_true_value}\n",
        "\n",
        "\n",
        "@registry.register_task('stability')\n",
        "class StabilityDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_path: Union[str, Path],\n",
        "                 split: str,\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False):\n",
        "\n",
        "        if split not in ('train', 'valid', 'test'):\n",
        "            raise ValueError(f\"Unrecognized split: {split}. \"\n",
        "                             f\"Must be one of ['train', 'valid', 'test']\")\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        data_path = Path(data_path)\n",
        "        data_file = f'stability/stability_{split}.lmdb'\n",
        "\n",
        "        self.data = dataset_factory(data_path / data_file, in_memory)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "        # return int(len(self.data) / 4)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        item = self.data[index]\n",
        "        token_ids = self.tokenizer.encode(item['primary'])\n",
        "        input_mask = np.ones_like(token_ids)\n",
        "        return token_ids, input_mask, float(item['stability_score'][0])\n",
        "\n",
        "    def collate_fn(self, batch: List[Tuple[Any, ...]]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, input_mask, stability_true_value = tuple(zip(*batch))\n",
        "        input_ids = torch.from_numpy(pad_sequences(input_ids, 0))\n",
        "        input_mask = torch.from_numpy(pad_sequences(input_mask, 0))\n",
        "        stability_true_value = torch.FloatTensor(stability_true_value)  # type: ignore\n",
        "        stability_true_value = stability_true_value.unsqueeze(1)\n",
        "\n",
        "        return {'input_ids': input_ids,\n",
        "                'input_mask': input_mask,\n",
        "                'targets': stability_true_value}\n",
        "\n",
        "\n",
        "@registry.register_task('remote_homology', num_labels=1195)\n",
        "class RemoteHomologyDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_path: Union[str, Path],\n",
        "                 split: str,\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False):\n",
        "\n",
        "        if split not in ('train', 'valid', 'test_fold_holdout',\n",
        "                         'test_family_holdout', 'test_superfamily_holdout'):\n",
        "            raise ValueError(f\"Unrecognized split: {split}. Must be one of \"\n",
        "                             f\"['train', 'valid', 'test_fold_holdout', \"\n",
        "                             f\"'test_family_holdout', 'test_superfamily_holdout']\")\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        data_path = Path(data_path)\n",
        "        data_file = f'remote_homology/remote_homology_{split}.lmdb'\n",
        "        self.data = dataset_factory(data_path / data_file, in_memory)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "        # return int(len(self.data) / 4)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        item = self.data[index]\n",
        "        token_ids = self.tokenizer.encode(item['primary'])\n",
        "        input_mask = np.ones_like(token_ids)\n",
        "        return token_ids, input_mask, item['fold_label']\n",
        "\n",
        "    def collate_fn(self, batch: List[Tuple[Any, ...]]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, input_mask, fold_label = tuple(zip(*batch))\n",
        "        input_ids = torch.from_numpy(pad_sequences(input_ids, 0))\n",
        "        input_mask = torch.from_numpy(pad_sequences(input_mask, 0))\n",
        "        fold_label = torch.LongTensor(fold_label)  # type: ignore\n",
        "\n",
        "        return {'input_ids': input_ids,\n",
        "                'input_mask': input_mask,\n",
        "                'targets': fold_label}\n",
        "\n",
        "\n",
        "@registry.register_task('contact_prediction')\n",
        "class ProteinnetDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_path: Union[str, Path],\n",
        "                 split: str,\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False):\n",
        "\n",
        "        if split not in ('train', 'train_unfiltered', 'valid', 'test'):\n",
        "            raise ValueError(f\"Unrecognized split: {split}. Must be one of \"\n",
        "                             f\"['train', 'train_unfiltered', 'valid', 'test']\")\n",
        "\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        data_path = Path(data_path)\n",
        "        data_file = f'proteinnet/proteinnet_{split}.lmdb'\n",
        "        self.data = dataset_factory(data_path / data_file, in_memory)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        # return len(self.data)\n",
        "        return int(len(self.data) / 4)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        item = self.data[index]\n",
        "        protein_length = len(item['primary'])\n",
        "        token_ids = self.tokenizer.encode(item['primary'])\n",
        "        input_mask = np.ones_like(token_ids)\n",
        "\n",
        "        valid_mask = item['valid_mask']\n",
        "        contact_map = np.less(squareform(pdist(item['tertiary'])), 8.0).astype(np.int64)\n",
        "\n",
        "        yind, xind = np.indices(contact_map.shape)\n",
        "        invalid_mask = ~(valid_mask[:, None] & valid_mask[None, :])\n",
        "        invalid_mask |= np.abs(yind - xind) < 6\n",
        "        contact_map[invalid_mask] = -1\n",
        "\n",
        "        return token_ids, input_mask, contact_map, protein_length\n",
        "\n",
        "    def collate_fn(self, batch: List[Tuple[Any, ...]]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, input_mask, contact_labels, protein_length = tuple(zip(*batch))\n",
        "        input_ids = torch.from_numpy(pad_sequences(input_ids, 0))\n",
        "        input_mask = torch.from_numpy(pad_sequences(input_mask, 0))\n",
        "        contact_labels = torch.from_numpy(pad_sequences(contact_labels, -1))\n",
        "        protein_length = torch.LongTensor(protein_length)  # type: ignore\n",
        "\n",
        "        return {'input_ids': input_ids,\n",
        "                'input_mask': input_mask,\n",
        "                'targets': contact_labels,\n",
        "                'protein_length': protein_length}\n",
        "\n",
        "\n",
        "@registry.register_task('secondary_structure', num_labels=3)\n",
        "class SecondaryStructureDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_path: Union[str, Path],\n",
        "                 split: str,\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False):\n",
        "\n",
        "        if split not in ('train', 'valid', 'casp12', 'ts115', 'cb513'):\n",
        "            raise ValueError(f\"Unrecognized split: {split}. Must be one of \"\n",
        "                             f\"['train', 'valid', 'casp12', \"\n",
        "                             f\"'ts115', 'cb513']\")\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        data_path = Path(data_path)\n",
        "        data_file = f'secondary_structure/secondary_structure_{split}.lmdb'\n",
        "        self.data = dataset_factory(data_path / data_file, in_memory)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "        # return int(len(self.data) / 4)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        item = self.data[index]\n",
        "        token_ids = self.tokenizer.encode(item['primary'])\n",
        "        input_mask = np.ones_like(token_ids)\n",
        "\n",
        "        # pad with -1s because of cls/sep tokens\n",
        "        labels = np.asarray(item['ss3'], np.int64)\n",
        "        labels = np.pad(labels, (1, 1), 'constant', constant_values=-1)\n",
        "\n",
        "        return token_ids, input_mask, labels\n",
        "\n",
        "    def collate_fn(self, batch: List[Tuple[Any, ...]]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, input_mask, ss_label = tuple(zip(*batch))\n",
        "        input_ids = torch.from_numpy(pad_sequences(input_ids, 0))\n",
        "        input_mask = torch.from_numpy(pad_sequences(input_mask, 0))\n",
        "        ss_label = torch.from_numpy(pad_sequences(ss_label, -1))\n",
        "\n",
        "        output = {'input_ids': input_ids,\n",
        "                  'input_mask': input_mask,\n",
        "                  'targets': ss_label}\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "@registry.register_task('trrosetta')\n",
        "class TRRosettaDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_path: Union[str, Path],\n",
        "                 split: str,\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False,\n",
        "                 max_seqlen: int = 300):\n",
        "        if split not in ('train', 'valid'):\n",
        "            raise ValueError(\n",
        "                f\"Unrecognized split: {split}. \"\n",
        "                f\"Must be one of ['train', 'valid']\")\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        data_path = Path(data_path)\n",
        "        data_path = data_path / 'trrosetta'\n",
        "        split_files = (data_path / f'{split}_files.txt').read_text().split()\n",
        "        self.data = NPZDataset(data_path / 'npz', in_memory, split_files=split_files)\n",
        "\n",
        "        self._dist_bins = np.arange(2, 20.1, 0.5)\n",
        "        self._dihedral_bins = (15 + np.arange(-180, 180, 15)) / 180 * np.pi\n",
        "        self._planar_bins = (15 + np.arange(0, 180, 15)) / 180 * np.pi\n",
        "        self._split = split\n",
        "        self.max_seqlen = max_seqlen\n",
        "        self.msa_cutoff = 0.8\n",
        "        self.penalty_coeff = 4.5\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        # return len(self.data)\n",
        "        return int(len(self.data) / 4)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "\n",
        "        msa = item['msa']\n",
        "        dist = item['dist6d']\n",
        "        omega = item['omega6d']\n",
        "        theta = item['theta6d']\n",
        "        phi = item['phi6d']\n",
        "\n",
        "        if self._split == 'train':\n",
        "            msa = self._subsample_msa(msa)\n",
        "        elif self._split == 'valid':\n",
        "            msa = msa[:20000]  # runs out of memory if msa is way too big\n",
        "        msa, dist, omega, theta, phi = self._slice_long_sequences(\n",
        "            msa, dist, omega, theta, phi)\n",
        "\n",
        "        mask = dist == 0\n",
        "\n",
        "        dist_bins = np.digitize(dist, self._dist_bins)\n",
        "        omega_bins = np.digitize(omega, self._dihedral_bins) + 1\n",
        "        theta_bins = np.digitize(theta, self._dihedral_bins) + 1\n",
        "        phi_bins = np.digitize(phi, self._planar_bins) + 1\n",
        "\n",
        "        dist_bins[mask] = 0\n",
        "        omega_bins[mask] = 0\n",
        "        theta_bins[mask] = 0\n",
        "        phi_bins[mask] = 0\n",
        "\n",
        "        dist_bins[np.diag_indices_from(dist_bins)] = -1\n",
        "\n",
        "        # input_mask = np.ones_like(msa[0])\n",
        "\n",
        "        return msa, dist_bins, omega_bins, theta_bins, phi_bins\n",
        "\n",
        "    def _slice_long_sequences(self, msa, dist, omega, theta, phi):\n",
        "        seqlen = msa.shape[1]\n",
        "        if self.max_seqlen > 0 and seqlen > self.max_seqlen:\n",
        "            start = np.random.randint(seqlen - self.max_seqlen + 1)\n",
        "            end = start + self.max_seqlen\n",
        "\n",
        "            msa = msa[:, start:end]\n",
        "            dist = dist[start:end, start:end]\n",
        "            omega = omega[start:end, start:end]\n",
        "            theta = theta[start:end, start:end]\n",
        "            phi = phi[start:end, start:end]\n",
        "\n",
        "        return msa, dist, omega, theta, phi\n",
        "\n",
        "    def _subsample_msa(self, msa):\n",
        "        num_alignments, seqlen = msa.shape\n",
        "\n",
        "        if num_alignments < 10:\n",
        "            return msa\n",
        "\n",
        "        num_sample = int(10 ** np.random.uniform(np.log10(num_alignments)) - 10)\n",
        "\n",
        "        if num_sample <= 0:\n",
        "            return msa[0][None, :]\n",
        "        elif num_sample > 20000:\n",
        "            num_sample = 20000\n",
        "\n",
        "        indices = np.random.choice(\n",
        "            msa.shape[0] - 1, size=num_sample, replace=False) + 1\n",
        "        indices = np.pad(indices, [1, 0], 'constant')  # add the sequence back in\n",
        "        return msa[indices]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        msa, dist_bins, omega_bins, theta_bins, phi_bins = tuple(zip(*batch))\n",
        "        # features = pad_sequences([self.featurize(msa_) for msa_ in msa], 0)\n",
        "        msa1hot = pad_sequences(\n",
        "            [F.one_hot(torch.LongTensor(msa_), 21) for msa_ in msa], 0, torch.float)\n",
        "        # input_mask = torch.FloatTensor(pad_sequences(input_mask, 0))\n",
        "        dist_bins = torch.LongTensor(pad_sequences(dist_bins, -1))\n",
        "        omega_bins = torch.LongTensor(pad_sequences(omega_bins, 0))\n",
        "        theta_bins = torch.LongTensor(pad_sequences(theta_bins, 0))\n",
        "        phi_bins = torch.LongTensor(pad_sequences(phi_bins, 0))\n",
        "\n",
        "        return {'msa1hot': msa1hot,\n",
        "                # 'input_mask': input_mask,\n",
        "                'dist': dist_bins,\n",
        "                'omega': omega_bins,\n",
        "                'theta': theta_bins,\n",
        "                'phi': phi_bins}\n",
        "\n",
        "    def featurize(self, msa):\n",
        "        msa = torch.LongTensor(msa)\n",
        "        msa1hot = F.one_hot(msa, 21).float()\n",
        "\n",
        "        seqlen = msa1hot.size(1)\n",
        "\n",
        "        weights = self.reweight(msa1hot)\n",
        "        features_1d = self.extract_features_1d(msa1hot, weights)\n",
        "        features_2d = self.extract_features_2d(msa1hot, weights)\n",
        "\n",
        "        features = torch.cat((\n",
        "            features_1d.unsqueeze(1).repeat(1, seqlen, 1),\n",
        "            features_1d.unsqueeze(0).repeat(seqlen, 1, 1),\n",
        "            features_2d), -1)\n",
        "\n",
        "        features = features.permute(2, 0, 1)\n",
        "\n",
        "        return features\n",
        "\n",
        "    def reweight(self, msa1hot):\n",
        "        # Reweight\n",
        "        seqlen = msa1hot.size(1)\n",
        "        id_min = seqlen * self.msa_cutoff\n",
        "        id_mtx = torch.tensordot(msa1hot, msa1hot, [[1, 2], [1, 2]])\n",
        "        id_mask = id_mtx > id_min\n",
        "        weights = 1.0 / id_mask.float().sum(-1)\n",
        "        return weights\n",
        "\n",
        "    def extract_features_1d(self, msa1hot, weights):\n",
        "        # 1D Features\n",
        "        seqlen = msa1hot.size(1)\n",
        "        f1d_seq = msa1hot[0, :, :20]\n",
        "\n",
        "        # msa2pssm\n",
        "        beff = weights.sum()\n",
        "        f_i = (weights[:, None, None] * msa1hot).sum(0) / beff + 1e-9\n",
        "        h_i = (-f_i * f_i.log()).sum(1, keepdims=True)\n",
        "        f1d_pssm = torch.cat((f_i, h_i), dim=1)\n",
        "\n",
        "        f1d = torch.cat((f1d_seq, f1d_pssm), dim=1)\n",
        "        f1d = f1d.view(seqlen, 42)\n",
        "        return f1d\n",
        "\n",
        "    def extract_features_2d(self, msa1hot, weights):\n",
        "        # 2D Features\n",
        "        num_alignments = msa1hot.size(0)\n",
        "        seqlen = msa1hot.size(1)\n",
        "        num_symbols = 21\n",
        "        if num_alignments == 1:\n",
        "            # No alignments, predict from sequence alone\n",
        "            f2d_dca = torch.zeros(seqlen, seqlen, 442, dtype=torch.float)\n",
        "        else:\n",
        "            # fast_dca\n",
        "\n",
        "            # covariance\n",
        "            x = msa1hot.view(num_alignments, seqlen * num_symbols)\n",
        "            num_points = weights.sum() - weights.mean().sqrt()\n",
        "            mean = (x * weights[:, None]).sum(0, keepdims=True) / num_points\n",
        "            x = (x - mean) * weights[:, None].sqrt()\n",
        "            cov = torch.matmul(x.transpose(-1, -2), x) / num_points\n",
        "\n",
        "            # inverse covariance\n",
        "            reg = torch.eye(seqlen * num_symbols) * self.penalty_coeff / weights.sum().sqrt()\n",
        "            cov_reg = cov + reg\n",
        "            inv_cov = torch.inverse(cov_reg)\n",
        "\n",
        "            x1 = inv_cov.view(seqlen, num_symbols, seqlen, num_symbols)\n",
        "            x2 = x1.permute(0, 2, 1, 3)\n",
        "            features = x2.reshape(seqlen, seqlen, num_symbols * num_symbols)\n",
        "\n",
        "            x3 = (x1[:, :-1, :, :-1] ** 2).sum((1, 3)).sqrt() * (1 - torch.eye(seqlen))\n",
        "            apc = x3.sum(0, keepdims=True) * x3.sum(1, keepdims=True) / x3.sum()\n",
        "            contacts = (x3 - apc) * (1 - torch.eye(seqlen))\n",
        "\n",
        "            f2d_dca = torch.cat([features, contacts[:, :, None]], axis=2)\n",
        "\n",
        "        return f2d_dca\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /usr/local/lib/python3.6/dist-packages/tape/datasets.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5rSuCxsfovZ",
        "outputId": "4659847d-e230-424c-8a2a-63cd444fb949"
      },
      "source": [
        "%%writefile /usr/local/lib/python3.6/dist-packages/tape/models/modeling_resnet.py\n",
        "\n",
        "import typing\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from .modeling_utils import ProteinConfig\n",
        "from .modeling_utils import ProteinModel\n",
        "from .modeling_utils import get_activation_fn\n",
        "from .modeling_utils import MLMHead\n",
        "from .modeling_utils import LayerNorm\n",
        "from .modeling_utils import ValuePredictionHead\n",
        "from .modeling_utils import SequenceClassificationHead\n",
        "from .modeling_utils import SequenceToSequenceClassificationHead\n",
        "from .modeling_utils import PairwiseContactPredictionHead\n",
        "from ..registry import registry\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "RESNET_PRETRAINED_CONFIG_ARCHIVE_MAP: typing.Dict[str, str] = {}\n",
        "RESNET_PRETRAINED_MODEL_ARCHIVE_MAP: typing.Dict[str, str] = {}\n",
        "\n",
        "\n",
        "class ProteinResNetConfig(ProteinConfig):\n",
        "    pretrained_config_archive_map = RESNET_PRETRAINED_CONFIG_ARCHIVE_MAP\n",
        "\n",
        "    def __init__(self,\n",
        "                 vocab_size: int = 30,\n",
        "                 hidden_size: int = 32, # hidden_size: int = 512,\n",
        "                 num_hidden_layers: int = 3, #num_hidden_layers: int = 30,\n",
        "                 hidden_act: str = \"gelu\",\n",
        "                 hidden_dropout_prob: float = 0.1,\n",
        "                 initializer_range: float = 0.02,\n",
        "                 layer_norm_eps: float = 1e-12,\n",
        "                 **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.vocab_size = vocab_size\n",
        "        self.num_hidden_layers = num_hidden_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_act = hidden_act\n",
        "        self.hidden_dropout_prob = hidden_dropout_prob\n",
        "        self.initializer_range = initializer_range\n",
        "        self.layer_norm_eps = layer_norm_eps\n",
        "\n",
        "\n",
        "class MaskedConv1d(nn.Conv1d):\n",
        "\n",
        "    def forward(self, x, input_mask=None):\n",
        "        if input_mask is not None:\n",
        "            x = x * input_mask\n",
        "        return super().forward(x)\n",
        "\n",
        "\n",
        "class ProteinResNetLayerNorm(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.norm = LayerNorm(config.hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.norm(x.transpose(1, 2)).transpose(1, 2)\n",
        "\n",
        "\n",
        "class ProteinResNetBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.conv1 = MaskedConv1d(\n",
        "            config.hidden_size, config.hidden_size, 3, padding=1, bias=False)\n",
        "        # self.bn1 = nn.BatchNorm1d(config.hidden_size)\n",
        "        self.bn1 = ProteinResNetLayerNorm(config)\n",
        "        self.conv2 = MaskedConv1d(\n",
        "            config.hidden_size, config.hidden_size, 3, padding=1, bias=False)\n",
        "        # self.bn2 = nn.BatchNorm1d(config.hidden_size)\n",
        "        self.bn2 = ProteinResNetLayerNorm(config)\n",
        "        self.activation_fn = get_activation_fn(config.hidden_act)\n",
        "\n",
        "    def forward(self, x, input_mask=None):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x, input_mask)\n",
        "        out = self.bn1(out)\n",
        "        out = self.activation_fn(out)\n",
        "\n",
        "        out = self.conv2(out, input_mask)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.activation_fn(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ProteinResNetEmbeddings(nn.Module):\n",
        "    \"\"\"Construct the embeddings from word, position and token_type embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        embed_dim = config.hidden_size\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, embed_dim, padding_idx=0)\n",
        "        inverse_frequency = 1 / (10000 ** (torch.arange(0.0, embed_dim, 2.0) / embed_dim))\n",
        "        self.register_buffer('inverse_frequency', inverse_frequency)\n",
        "\n",
        "        self.layer_norm = LayerNorm(embed_dim, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        words_embeddings = self.word_embeddings(input_ids)\n",
        "\n",
        "        seq_length = input_ids.size(1)\n",
        "        position_ids = torch.arange(\n",
        "            seq_length - 1, -1, -1.0,\n",
        "            dtype=words_embeddings.dtype,\n",
        "            device=words_embeddings.device)\n",
        "        sinusoidal_input = torch.ger(position_ids, self.inverse_frequency)\n",
        "        position_embeddings = torch.cat([sinusoidal_input.sin(), sinusoidal_input.cos()], -1)\n",
        "        position_embeddings = position_embeddings.unsqueeze(0)\n",
        "\n",
        "        embeddings = words_embeddings + position_embeddings\n",
        "        embeddings = self.layer_norm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class ProteinResNetPooler(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.attention_weights = nn.Linear(config.hidden_size, 1)\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states, mask=None):\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        attention_scores = self.attention_weights(hidden_states)\n",
        "        if mask is not None:\n",
        "            attention_scores += -10000. * (1 - mask)\n",
        "        attention_weights = torch.softmax(attention_scores, -1)\n",
        "        weighted_mean_embedding = torch.matmul(\n",
        "            hidden_states.transpose(1, 2), attention_weights).squeeze(2)\n",
        "        pooled_output = self.dense(weighted_mean_embedding)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        return pooled_output\n",
        "\n",
        "\n",
        "class ResNetEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.output_hidden_states = config.output_hidden_states\n",
        "        self.layer = nn.ModuleList(\n",
        "            [ProteinResNetBlock(config) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "    def forward(self, hidden_states, input_mask=None):\n",
        "        all_hidden_states = ()\n",
        "        for layer_module in self.layer:\n",
        "            if self.output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "            hidden_states = layer_module(hidden_states, input_mask)\n",
        "\n",
        "        if self.output_hidden_states:\n",
        "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "        outputs = (hidden_states,)\n",
        "        if self.output_hidden_states:\n",
        "            outputs = outputs + (all_hidden_states,)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class ProteinResNetAbstractModel(ProteinModel):\n",
        "    \"\"\" An abstract class to handle weights initialization and\n",
        "        a simple interface for dowloading and loading pretrained models.\n",
        "    \"\"\"\n",
        "    config_class = ProteinResNetConfig\n",
        "    pretrained_model_archive_map = RESNET_PRETRAINED_MODEL_ARCHIVE_MAP\n",
        "    base_model_prefix = \"resnet\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        \"\"\" Initialize the weights \"\"\"\n",
        "        if isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "        elif isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Conv1d):\n",
        "            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        # elif isinstance(module, ProteinResNetBlock):\n",
        "            # nn.init.constant_(module.bn2.weight, 0)\n",
        "\n",
        "\n",
        "@registry.register_task_model('embed', 'resnet')\n",
        "class ProteinResNetModel(ProteinResNetAbstractModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.embeddings = ProteinResNetEmbeddings(config)\n",
        "        self.encoder = ResNetEncoder(config)\n",
        "        self.pooler = ProteinResNetPooler(config)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self,\n",
        "                input_ids,\n",
        "                input_mask=None):\n",
        "        if input_mask is not None and torch.any(input_mask != 1):\n",
        "            extended_input_mask = input_mask.unsqueeze(2)\n",
        "            # fp16 compatibility\n",
        "            extended_input_mask = extended_input_mask.to(\n",
        "                dtype=next(self.parameters()).dtype)\n",
        "        else:\n",
        "            extended_input_mask = None\n",
        "\n",
        "        embedding_output = self.embeddings(input_ids)\n",
        "        embedding_output = embedding_output.transpose(1, 2)\n",
        "        if extended_input_mask is not None:\n",
        "            extended_input_mask = extended_input_mask.transpose(1, 2)\n",
        "        encoder_outputs = self.encoder(embedding_output, extended_input_mask)\n",
        "        sequence_output = encoder_outputs[0]\n",
        "        sequence_output = sequence_output.transpose(1, 2).contiguous()\n",
        "        # sequence_output = encoder_outputs[0]\n",
        "        if extended_input_mask is not None:\n",
        "            extended_input_mask = extended_input_mask.transpose(1, 2)\n",
        "        pooled_output = self.pooler(sequence_output, extended_input_mask)\n",
        "\n",
        "        # add hidden_states and attentions if they are here\n",
        "        outputs = (sequence_output, pooled_output,) + encoder_outputs[1:]\n",
        "        return outputs  # sequence_output, pooled_output, (hidden_states)\n",
        "\n",
        "\n",
        "@registry.register_task_model('masked_language_modeling', 'resnet')\n",
        "class ProteinResNetForMaskedLM(ProteinResNetAbstractModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.resnet = ProteinResNetModel(config)\n",
        "        self.mlm = MLMHead(\n",
        "            config.hidden_size, config.vocab_size, config.hidden_act, config.layer_norm_eps,\n",
        "            ignore_index=-1)\n",
        "\n",
        "        self.init_weights()\n",
        "        self.tie_weights()\n",
        "\n",
        "    def tie_weights(self):\n",
        "        \"\"\" Make sure we are sharing the input and output embeddings.\n",
        "            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n",
        "        \"\"\"\n",
        "        self._tie_or_clone_weights(self.mlm.decoder,\n",
        "                                   self.resnet.embeddings.word_embeddings)\n",
        "\n",
        "    def forward(self,\n",
        "                input_ids,\n",
        "                input_mask=None,\n",
        "                targets=None):\n",
        "\n",
        "        outputs = self.resnet(input_ids, input_mask=input_mask)\n",
        "\n",
        "        sequence_output, pooled_output = outputs[:2]\n",
        "        outputs = self.mlm(sequence_output, targets) + outputs[2:]\n",
        "        # (loss), prediction_scores, (hidden_states), (attentions)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "@registry.register_task_model('fluorescence', 'resnet')\n",
        "@registry.register_task_model('stability', 'resnet')\n",
        "class ProteinResNetForValuePrediction(ProteinResNetAbstractModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.resnet = ProteinResNetModel(config)\n",
        "        self.predict = ValuePredictionHead(config.hidden_size)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids, input_mask=None, targets=None):\n",
        "\n",
        "        outputs = self.resnet(input_ids, input_mask=input_mask)\n",
        "\n",
        "        sequence_output, pooled_output = outputs[:2]\n",
        "        outputs = self.predict(pooled_output, targets) + outputs[2:]\n",
        "        # (loss), prediction_scores, (hidden_states), (attentions)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "@registry.register_task_model('remote_homology', 'resnet')\n",
        "class ProteinResNetForSequenceClassification(ProteinResNetAbstractModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.resnet = ProteinResNetModel(config)\n",
        "        self.classify = SequenceClassificationHead(config.hidden_size, config.num_labels)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids, input_mask=None, targets=None):\n",
        "\n",
        "        outputs = self.resnet(input_ids, input_mask=input_mask)\n",
        "\n",
        "        sequence_output, pooled_output = outputs[:2]\n",
        "        outputs = self.classify(pooled_output, targets) + outputs[2:]\n",
        "        # (loss), prediction_scores, (hidden_states), (attentions)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "@registry.register_task_model('secondary_structure', 'resnet')\n",
        "class ProteinResNetForSequenceToSequenceClassification(ProteinResNetAbstractModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.resnet = ProteinResNetModel(config)\n",
        "        self.classify = SequenceToSequenceClassificationHead(\n",
        "            config.hidden_size, config.num_labels, ignore_index=-1)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids, input_mask=None, targets=None):\n",
        "\n",
        "        outputs = self.resnet(input_ids, input_mask=input_mask)\n",
        "\n",
        "        sequence_output, pooled_output = outputs[:2]\n",
        "        outputs = self.classify(sequence_output, targets) + outputs[2:]\n",
        "        # (loss), prediction_scores, (hidden_states), (attentions)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "@registry.register_task_model('contact_prediction', 'resnet')\n",
        "class ProteinResNetForContactPrediction(ProteinResNetAbstractModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.resnet = ProteinResNetModel(config)\n",
        "        self.predict = PairwiseContactPredictionHead(config.hidden_size, ignore_index=-1)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids, protein_length, input_mask=None, targets=None):\n",
        "\n",
        "        outputs = self.resnet(input_ids, input_mask=input_mask)\n",
        "\n",
        "        sequence_output, pooled_output = outputs[:2]\n",
        "        outputs = self.predict(sequence_output, protein_length, targets) + outputs[2:]\n",
        "        # (loss), prediction_scores, (hidden_states), (attentions)\n",
        "        return outputs\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /usr/local/lib/python3.6/dist-packages/tape/models/modeling_resnet.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR3SWU_uclI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b86b378c-8073-4ff2-ea50-0ada8d7c3e4c"
      },
      "source": [
        "!tape-train-distributed resnet contact_prediction --model_config_file /content/results/baseline_resnet/config.json --from_pretrained /content/results/pretrained_transformer_sincos --batch_size 150 --learning_rate 5e-4 --num_train_epochs 10 --warmup_steps 2 --gradient_accumulation_steps 100 --seed 1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/12/06 14:52:14 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/pretrained_transformer_sincos/config.json\n",
            "20/12/06 14:52:14 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": -1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/12/06 14:52:14 - INFO - tape.models.modeling_utils -   loading weights file /content/results/pretrained_transformer_sincos/pytorch_model.bin\n",
            "20/12/06 14:52:14 - INFO - tape.models.modeling_utils -   Weights of ProteinResNetForContactPrediction not initialized from pretrained model: ['embeddings.inverse_frequency', 'embeddings.word_embeddings.weight', 'embeddings.layer_norm.weight', 'embeddings.layer_norm.bias', 'encoder.layer.0.conv1.weight', 'encoder.layer.0.bn1.norm.weight', 'encoder.layer.0.bn1.norm.bias', 'encoder.layer.0.conv2.weight', 'encoder.layer.0.bn2.norm.weight', 'encoder.layer.0.bn2.norm.bias', 'encoder.layer.1.conv1.weight', 'encoder.layer.1.bn1.norm.weight', 'encoder.layer.1.bn1.norm.bias', 'encoder.layer.1.conv2.weight', 'encoder.layer.1.bn2.norm.weight', 'encoder.layer.1.bn2.norm.bias', 'encoder.layer.2.conv1.weight', 'encoder.layer.2.bn1.norm.weight', 'encoder.layer.2.bn1.norm.bias', 'encoder.layer.2.conv2.weight', 'encoder.layer.2.bn2.norm.weight', 'encoder.layer.2.bn2.norm.bias', 'pooler.attention_weights.weight', 'pooler.attention_weights.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "20/12/06 14:52:14 - INFO - tape.models.modeling_utils -   Weights from pretrained model not used in ProteinResNetForContactPrediction: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n",
            "20/12/06 14:52:14 - INFO - tape.visualization -   tensorboard file at: logs/contact_prediction_resnet_20-12-06-14-52-10_768266\n",
            "20/12/06 14:52:14 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/06 14:52:14 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/06 14:52:14 - WARNING - tape.visualization -   Cannot watch models when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/06 14:52:14 - INFO - tape.training -   device: cuda:0 n_gpu: 1, distributed_training: True, 16-bits training: False\n",
            "20/12/06 14:52:14 - INFO - tape.training -   ***** Running training *****\n",
            "20/12/06 14:52:14 - INFO - tape.training -     Num examples = 6324\n",
            "20/12/06 14:52:14 - INFO - tape.training -     Batch size = 150\n",
            "20/12/06 14:52:14 - INFO - tape.training -     Num epochs = 10\n",
            "20/12/06 14:52:14 - INFO - tape.training -     Num train steps = 421\n",
            "20/12/06 14:52:14 - INFO - tape.training -     Num parameters = 21059\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "20/12/06 14:52:53 - INFO - tape.training -   [Ep: 0.32][Iter: 20][Time: 39.02s][Loss: 0.32379][Precision_at_l5: 0.019672][LR: 0.00047852]\n",
            "20/12/06 14:53:29 - INFO - tape.training -   [Ep: 0.63][Iter: 40][Time: 36.08s][Loss: 0.20452][Precision_at_l5: 0.021428][LR: 0.00045465]\n",
            "20/12/06 14:54:04 - INFO - tape.training -   [Ep: 0.95][Iter: 60][Time: 34.85s][Loss: 0.14992][Precision_at_l5: 0.020342][LR: 0.00043079]\n",
            "20/12/06 14:54:11 - INFO - tape.training -   Train: [Loss: 0.1704][Precision_at_l5: 0.021151]\n",
            "20/12/06 14:54:12 - INFO - tape.training -   Evaluation: [Loss: 0.12772][Precision_at_l5: 0.015786]\n",
            "20/12/06 14:54:12 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 14:54:12 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-06-14-52-10_768266\n",
            "20/12/06 14:54:47 - INFO - tape.training -   [Ep: 1.27][Iter: 80][Time: 34.14s][Loss: 0.12452][Precision_at_l5: 0.021553][LR: 0.00040692]\n",
            "20/12/06 14:55:27 - INFO - tape.training -   [Ep: 1.58][Iter: 100][Time: 40.13s][Loss: 0.12302][Precision_at_l5: 0.021588][LR: 0.00038305]\n",
            "20/12/06 14:56:04 - INFO - tape.training -   [Ep: 1.90][Iter: 120][Time: 36.90s][Loss: 0.11796][Precision_at_l5: 0.021013][LR: 0.00035919]\n",
            "20/12/06 14:56:16 - INFO - tape.training -   Train: [Loss: 0.12082][Precision_at_l5: 0.021766]\n",
            "20/12/06 14:56:17 - INFO - tape.training -   Evaluation: [Loss: 0.11817][Precision_at_l5: 0.027396]\n",
            "20/12/06 14:56:17 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 14:56:17 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-06-14-52-10_768266\n",
            "20/12/06 14:56:45 - INFO - tape.training -   [Ep: 2.22][Iter: 140][Time: 27.76s][Loss: 0.11866][Precision_at_l5: 0.024211][LR: 0.00033532]\n",
            "20/12/06 14:57:25 - INFO - tape.training -   [Ep: 2.54][Iter: 160][Time: 39.69s][Loss: 0.1207][Precision_at_l5: 0.023458][LR: 0.00031146]\n",
            "20/12/06 14:58:03 - INFO - tape.training -   [Ep: 2.85][Iter: 180][Time: 38.48s][Loss: 0.11744][Precision_at_l5: 0.022647][LR: 0.00028759]\n",
            "20/12/06 14:58:21 - INFO - tape.training -   Train: [Loss: 0.11773][Precision_at_l5: 0.02319]\n",
            "20/12/06 14:58:22 - INFO - tape.training -   Evaluation: [Loss: 0.11662][Precision_at_l5: 0.035894]\n",
            "20/12/06 14:58:22 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 14:58:22 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-06-14-52-10_768266\n",
            "20/12/06 14:58:45 - INFO - tape.training -   [Ep: 3.17][Iter: 200][Time: 22.49s][Loss: 0.11529][Precision_at_l5: 0.024589][LR: 0.00026372]\n",
            "20/12/06 14:59:25 - INFO - tape.training -   [Ep: 3.49][Iter: 220][Time: 39.89s][Loss: 0.11782][Precision_at_l5: 0.023771][LR: 0.00023986]\n",
            "20/12/06 15:00:03 - INFO - tape.training -   [Ep: 3.81][Iter: 240][Time: 38.08s][Loss: 0.11699][Precision_at_l5: 0.022579][LR: 0.00021599]\n",
            "20/12/06 15:00:27 - INFO - tape.training -   Train: [Loss: 0.11661][Precision_at_l5: 0.023642]\n",
            "20/12/06 15:00:28 - INFO - tape.training -   Evaluation: [Loss: 0.12129][Precision_at_l5: 0.037518]\n",
            "20/12/06 15:00:28 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:00:28 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-06-14-52-10_768266\n",
            "20/12/06 15:00:44 - INFO - tape.training -   [Ep: 4.13][Iter: 260][Time: 16.24s][Loss: 0.11747][Precision_at_l5: 0.028338][LR: 0.00019212]\n",
            "20/12/06 15:01:25 - INFO - tape.training -   [Ep: 4.44][Iter: 280][Time: 40.79s][Loss: 0.11757][Precision_at_l5: 0.025953][LR: 0.00016826]\n",
            "20/12/06 15:02:04 - INFO - tape.training -   [Ep: 4.76][Iter: 300][Time: 38.65s][Loss: 0.11624][Precision_at_l5: 0.022879][LR: 0.00014439]\n",
            "20/12/06 15:02:33 - INFO - tape.training -   Train: [Loss: 0.11576][Precision_at_l5: 0.023777]\n",
            "20/12/06 15:02:35 - INFO - tape.training -   Evaluation: [Loss: 0.11834][Precision_at_l5: 0.033362]\n",
            "20/12/06 15:02:35 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:02:35 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-06-14-52-10_768266\n",
            "20/12/06 15:02:45 - INFO - tape.training -   [Ep: 5.08][Iter: 320][Time: 10.21s][Loss: 0.11371][Precision_at_l5: 0.031643][LR: 0.00012053]\n",
            "20/12/06 15:03:24 - INFO - tape.training -   [Ep: 5.40][Iter: 340][Time: 39.06s][Loss: 0.11577][Precision_at_l5: 0.026651][LR: 9.6659e-05]\n",
            "20/12/06 15:04:01 - INFO - tape.training -   [Ep: 5.71][Iter: 360][Time: 36.96s][Loss: 0.11485][Precision_at_l5: 0.025204][LR: 7.2792e-05]\n",
            "20/12/06 15:04:36 - INFO - tape.training -   Train: [Loss: 0.11493][Precision_at_l5: 0.024329]\n",
            "20/12/06 15:04:38 - INFO - tape.training -   Evaluation: [Loss: 0.11468][Precision_at_l5: 0.036812]\n",
            "20/12/06 15:04:38 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:04:38 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-06-14-52-10_768266\n",
            "20/12/06 15:04:42 - INFO - tape.training -   [Ep: 6.03][Iter: 380][Time:  4.24s][Loss: 0.11123][Precision_at_l5: 0.020382][LR: 4.8926e-05]\n",
            "20/12/06 15:05:23 - INFO - tape.training -   [Ep: 6.35][Iter: 400][Time: 41.49s][Loss: 0.11382][Precision_at_l5: 0.022803][LR: 2.506e-05]\n",
            "20/12/06 15:06:02 - INFO - tape.training -   [Ep: 6.66][Iter: 420][Time: 38.31s][Loss: 0.11505][Precision_at_l5: 0.02411][LR: 1.1933e-06]\n",
            "20/12/06 15:06:39 - INFO - tape.training -   [Ep: 6.98][Iter: 440][Time: 37.19s][Loss: 0.11159][Precision_at_l5: 0.024259][LR: 0]\n",
            "20/12/06 15:06:42 - INFO - tape.training -   Train: [Loss: 0.1137][Precision_at_l5: 0.02456]\n",
            "20/12/06 15:06:43 - INFO - tape.training -   Evaluation: [Loss: 0.11535][Precision_at_l5: 0.036268]\n",
            "20/12/06 15:06:43 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:06:43 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-06-14-52-10_768266\n",
            "20/12/06 15:07:21 - INFO - tape.training -   [Ep: 7.30][Iter: 460][Time: 37.61s][Loss: 0.11315][Precision_at_l5: 0.027068][LR: 0]\n",
            "20/12/06 15:07:59 - INFO - tape.training -   [Ep: 7.62][Iter: 480][Time: 38.09s][Loss: 0.11564][Precision_at_l5: 0.026456][LR: 0]\n",
            "20/12/06 15:08:37 - INFO - tape.training -   [Ep: 7.93][Iter: 500][Time: 37.75s][Loss: 0.11147][Precision_at_l5: 0.024352][LR: 0]\n",
            "20/12/06 15:08:45 - INFO - tape.training -   Train: [Loss: 0.11378][Precision_at_l5: 0.025575]\n",
            "20/12/06 15:08:47 - INFO - tape.training -   Evaluation: [Loss: 0.11535][Precision_at_l5: 0.036268]\n",
            "20/12/06 15:08:47 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:08:47 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-06-14-52-10_768266\n",
            "20/12/06 15:09:18 - INFO - tape.training -   [Ep: 8.25][Iter: 520][Time: 31.54s][Loss: 0.11347][Precision_at_l5: 0.027813][LR: 0]\n",
            "20/12/06 15:09:59 - INFO - tape.training -   [Ep: 8.57][Iter: 540][Time: 40.66s][Loss: 0.11591][Precision_at_l5: 0.025286][LR: 0]\n",
            "20/12/06 15:10:37 - INFO - tape.training -   [Ep: 8.89][Iter: 560][Time: 38.17s][Loss: 0.11179][Precision_at_l5: 0.023897][LR: 0]\n",
            "20/12/06 15:10:51 - INFO - tape.training -   Train: [Loss: 0.11373][Precision_at_l5: 0.024577]\n",
            "20/12/06 15:10:53 - INFO - tape.training -   Evaluation: [Loss: 0.11535][Precision_at_l5: 0.036268]\n",
            "20/12/06 15:10:53 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:10:53 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-06-14-52-10_768266\n",
            "20/12/06 15:11:19 - INFO - tape.training -   [Ep: 9.21][Iter: 580][Time: 26.89s][Loss: 0.11301][Precision_at_l5: 0.02477][LR: 0]\n",
            "20/12/06 15:11:59 - INFO - tape.training -   [Ep: 9.52][Iter: 600][Time: 39.98s][Loss: 0.11555][Precision_at_l5: 0.024846][LR: 0]\n",
            "20/12/06 15:12:39 - INFO - tape.training -   [Ep: 9.84][Iter: 620][Time: 40.05s][Loss: 0.11345][Precision_at_l5: 0.024452][LR: 0]\n",
            "20/12/06 15:13:00 - INFO - tape.training -   Train: [Loss: 0.11382][Precision_at_l5: 0.02479]\n",
            "20/12/06 15:13:02 - INFO - tape.training -   Evaluation: [Loss: 0.11535][Precision_at_l5: 0.036268]\n",
            "20/12/06 15:13:02 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:13:02 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-06-14-52-10_768266\n",
            "20/12/06 15:13:02 - INFO - tape.training -   Finished training after 10 epochs.\n",
            "20/12/06 15:13:02 - Level 35 - tape.training -   Best Val Loss: 0.11468322575092316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLJBAn-qfDjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80c794ab-a8a0-425d-f192-e05bdeea8f05"
      },
      "source": [
        "!tape-eval resnet contact_prediction /content/results/contact_prediction_resnet_20-12-06-14-52-10_768266 --metrics accuracy "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/12/06 15:13:52 - INFO - tape.training -   device: cuda n_gpu: 1\n",
            "20/12/06 15:13:52 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/contact_prediction_resnet_20-12-06-14-52-10_768266/config.json\n",
            "20/12/06 15:13:52 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": -1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/12/06 15:13:52 - INFO - tape.models.modeling_utils -   loading weights file /content/results/contact_prediction_resnet_20-12-06-14-52-10_768266/pytorch_model.bin\n",
            "Evaluation: 100% 1/1 [00:00<00:00,  1.57it/s]\n",
            "20/12/06 15:13:57 - INFO - tape.training -   accuracy: 0.985771855221519\n",
            "{'accuracy': 0.985771855221519}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwqwkYKBclLT",
        "outputId": "d04d31c9-fd72-4a95-e0ca-4c3909ace9de"
      },
      "source": [
        "!tape-train-distributed resnet fluorescence --model_config_file /content/results/baseline_resnet/config.json --from_pretrained /content/results/pretrained_transformer_sincos --batch_size 150 --learning_rate 5e-4 --num_train_epochs 10 --warmup_steps 2 --gradient_accumulation_steps 50 --seed 1"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/12/06 15:14:32 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/pretrained_transformer_sincos/config.json\n",
            "20/12/06 15:14:32 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": -1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/12/06 15:14:32 - INFO - tape.models.modeling_utils -   loading weights file /content/results/pretrained_transformer_sincos/pytorch_model.bin\n",
            "20/12/06 15:14:32 - INFO - tape.models.modeling_utils -   Weights of ProteinResNetForValuePrediction not initialized from pretrained model: ['embeddings.inverse_frequency', 'embeddings.word_embeddings.weight', 'embeddings.layer_norm.weight', 'embeddings.layer_norm.bias', 'encoder.layer.0.conv1.weight', 'encoder.layer.0.bn1.norm.weight', 'encoder.layer.0.bn1.norm.bias', 'encoder.layer.0.conv2.weight', 'encoder.layer.0.bn2.norm.weight', 'encoder.layer.0.bn2.norm.bias', 'encoder.layer.1.conv1.weight', 'encoder.layer.1.bn1.norm.weight', 'encoder.layer.1.bn1.norm.bias', 'encoder.layer.1.conv2.weight', 'encoder.layer.1.bn2.norm.weight', 'encoder.layer.1.bn2.norm.bias', 'encoder.layer.2.conv1.weight', 'encoder.layer.2.bn1.norm.weight', 'encoder.layer.2.bn1.norm.bias', 'encoder.layer.2.conv2.weight', 'encoder.layer.2.bn2.norm.weight', 'encoder.layer.2.bn2.norm.bias', 'pooler.attention_weights.weight', 'pooler.attention_weights.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "20/12/06 15:14:32 - INFO - tape.models.modeling_utils -   Weights from pretrained model not used in ProteinResNetForValuePrediction: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n",
            "20/12/06 15:14:32 - INFO - tape.visualization -   tensorboard file at: logs/fluorescence_resnet_20-12-06-15-14-28_431319\n",
            "20/12/06 15:14:32 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/06 15:14:32 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/06 15:14:32 - WARNING - tape.visualization -   Cannot watch models when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/06 15:14:32 - INFO - tape.training -   device: cuda:0 n_gpu: 1, distributed_training: True, 16-bits training: False\n",
            "20/12/06 15:14:32 - INFO - tape.training -   ***** Running training *****\n",
            "20/12/06 15:14:32 - INFO - tape.training -     Num examples = 21446\n",
            "20/12/06 15:14:32 - INFO - tape.training -     Batch size = 150\n",
            "20/12/06 15:14:32 - INFO - tape.training -     Num epochs = 10\n",
            "20/12/06 15:14:32 - INFO - tape.training -     Num train steps = 1429\n",
            "20/12/06 15:14:32 - INFO - tape.training -     Num parameters = 38340\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "20/12/06 15:14:44 - INFO - tape.training -   [Ep: 0.14][Iter: 20][Time: 12.15s][Loss: 8.2659][LR: 0.00049369]\n",
            "20/12/06 15:14:55 - INFO - tape.training -   [Ep: 0.28][Iter: 40][Time: 10.86s][Loss: 3.5104][LR: 0.00048669]\n",
            "20/12/06 15:15:06 - INFO - tape.training -   [Ep: 0.42][Iter: 60][Time: 11.20s][Loss: 1.7061][LR: 0.00047968]\n",
            "20/12/06 15:15:18 - INFO - tape.training -   [Ep: 0.56][Iter: 80][Time: 11.66s][Loss: 1.0862][LR: 0.00047267]\n",
            "20/12/06 15:15:29 - INFO - tape.training -   [Ep: 0.70][Iter: 100][Time: 10.93s][Loss: 0.82968][LR: 0.00046566]\n",
            "20/12/06 15:15:39 - INFO - tape.training -   [Ep: 0.84][Iter: 120][Time: 10.80s][Loss: 0.73385][LR: 0.00045865]\n",
            "20/12/06 15:15:51 - INFO - tape.training -   [Ep: 0.98][Iter: 140][Time: 11.19s][Loss: 0.73432][LR: 0.00045165]\n",
            "20/12/06 15:15:52 - INFO - tape.training -   Train: [Loss: 1.5709]\n",
            "20/12/06 15:16:03 - INFO - tape.training -   Evaluation: [Loss: 0.73678]\n",
            "20/12/06 15:16:03 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:16:03 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-06-15-14-28_431319\n",
            "20/12/06 15:16:13 - INFO - tape.training -   [Ep: 1.13][Iter: 160][Time: 10.35s][Loss: 0.75656][LR: 0.00044464]\n",
            "20/12/06 15:16:23 - INFO - tape.training -   [Ep: 1.27][Iter: 180][Time: 10.29s][Loss: 0.73281][LR: 0.00043763]\n",
            "20/12/06 15:16:33 - INFO - tape.training -   [Ep: 1.41][Iter: 200][Time: 10.15s][Loss: 0.69747][LR: 0.00043062]\n",
            "20/12/06 15:16:44 - INFO - tape.training -   [Ep: 1.55][Iter: 220][Time: 10.41s][Loss: 0.73043][LR: 0.00042362]\n",
            "20/12/06 15:16:55 - INFO - tape.training -   [Ep: 1.69][Iter: 240][Time: 11.07s][Loss: 0.70359][LR: 0.00041661]\n",
            "20/12/06 15:17:06 - INFO - tape.training -   [Ep: 1.83][Iter: 260][Time: 10.98s][Loss: 0.68626][LR: 0.0004096]\n",
            "20/12/06 15:17:17 - INFO - tape.training -   [Ep: 1.97][Iter: 280][Time: 10.94s][Loss: 0.69683][LR: 0.00040259]\n",
            "20/12/06 15:17:20 - INFO - tape.training -   Train: [Loss: 0.70656]\n",
            "20/12/06 15:17:30 - INFO - tape.training -   Evaluation: [Loss: 0.74854]\n",
            "20/12/06 15:17:30 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:17:30 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-06-15-14-28_431319\n",
            "20/12/06 15:17:39 - INFO - tape.training -   [Ep: 2.11][Iter: 300][Time:  8.63s][Loss: 0.70334][LR: 0.00039559]\n",
            "20/12/06 15:17:49 - INFO - tape.training -   [Ep: 2.25][Iter: 320][Time: 10.56s][Loss: 0.71798][LR: 0.00038858]\n",
            "20/12/06 15:18:00 - INFO - tape.training -   [Ep: 2.39][Iter: 340][Time: 10.48s][Loss: 0.70974][LR: 0.00038157]\n",
            "20/12/06 15:18:10 - INFO - tape.training -   [Ep: 2.53][Iter: 360][Time: 10.51s][Loss: 0.7392][LR: 0.00037456]\n",
            "20/12/06 15:18:21 - INFO - tape.training -   [Ep: 2.67][Iter: 380][Time: 10.73s][Loss: 0.71027][LR: 0.00036755]\n",
            "20/12/06 15:18:32 - INFO - tape.training -   [Ep: 2.81][Iter: 400][Time: 10.72s][Loss: 0.69595][LR: 0.00036055]\n",
            "20/12/06 15:18:42 - INFO - tape.training -   [Ep: 2.95][Iter: 420][Time: 10.18s][Loss: 0.70747][LR: 0.00035354]\n",
            "20/12/06 15:18:45 - INFO - tape.training -   Train: [Loss: 0.71281]\n",
            "20/12/06 15:18:55 - INFO - tape.training -   Evaluation: [Loss: 0.72377]\n",
            "20/12/06 15:18:55 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:18:55 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-06-15-14-28_431319\n",
            "20/12/06 15:19:03 - INFO - tape.training -   [Ep: 3.10][Iter: 440][Time:  7.51s][Loss: 0.72881][LR: 0.00034653]\n",
            "20/12/06 15:19:14 - INFO - tape.training -   [Ep: 3.24][Iter: 460][Time: 10.72s][Loss: 0.72894][LR: 0.00033952]\n",
            "20/12/06 15:19:24 - INFO - tape.training -   [Ep: 3.38][Iter: 480][Time: 10.65s][Loss: 0.7088][LR: 0.00033252]\n",
            "20/12/06 15:19:34 - INFO - tape.training -   [Ep: 3.52][Iter: 500][Time: 10.14s][Loss: 0.71775][LR: 0.00032551]\n",
            "20/12/06 15:19:45 - INFO - tape.training -   [Ep: 3.66][Iter: 520][Time: 10.44s][Loss: 0.69651][LR: 0.0003185]\n",
            "20/12/06 15:19:55 - INFO - tape.training -   [Ep: 3.80][Iter: 540][Time: 10.39s][Loss: 0.69856][LR: 0.00031149]\n",
            "20/12/06 15:20:06 - INFO - tape.training -   [Ep: 3.94][Iter: 560][Time: 10.34s][Loss: 0.72383][LR: 0.00030448]\n",
            "20/12/06 15:20:10 - INFO - tape.training -   Train: [Loss: 0.70638]\n",
            "20/12/06 15:20:21 - INFO - tape.training -   Evaluation: [Loss: 0.70704]\n",
            "20/12/06 15:20:21 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:20:21 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-06-15-14-28_431319\n",
            "20/12/06 15:20:28 - INFO - tape.training -   [Ep: 4.08][Iter: 580][Time:  6.81s][Loss: 0.71037][LR: 0.00029748]\n",
            "20/12/06 15:20:39 - INFO - tape.training -   [Ep: 4.22][Iter: 600][Time: 10.69s][Loss: 0.71671][LR: 0.00029047]\n",
            "20/12/06 15:20:49 - INFO - tape.training -   [Ep: 4.36][Iter: 620][Time: 10.64s][Loss: 0.70546][LR: 0.00028346]\n",
            "20/12/06 15:20:59 - INFO - tape.training -   [Ep: 4.50][Iter: 640][Time: 10.26s][Loss: 0.71844][LR: 0.00027645]\n",
            "20/12/06 15:21:10 - INFO - tape.training -   [Ep: 4.64][Iter: 660][Time: 10.27s][Loss: 0.70146][LR: 0.00026945]\n",
            "20/12/06 15:21:20 - INFO - tape.training -   [Ep: 4.78][Iter: 680][Time: 10.61s][Loss: 0.70431][LR: 0.00026244]\n",
            "20/12/06 15:21:31 - INFO - tape.training -   [Ep: 4.92][Iter: 700][Time: 10.64s][Loss: 0.70517][LR: 0.00025543]\n",
            "20/12/06 15:21:37 - INFO - tape.training -   Train: [Loss: 0.70358]\n",
            "20/12/06 15:21:47 - INFO - tape.training -   Evaluation: [Loss: 0.71596]\n",
            "20/12/06 15:21:47 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:21:47 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-06-15-14-28_431319\n",
            "20/12/06 15:21:53 - INFO - tape.training -   [Ep: 5.07][Iter: 720][Time:  5.69s][Loss: 0.73449][LR: 0.00024842]\n",
            "20/12/06 15:22:03 - INFO - tape.training -   [Ep: 5.21][Iter: 740][Time: 10.65s][Loss: 0.71959][LR: 0.00024142]\n",
            "20/12/06 15:22:14 - INFO - tape.training -   [Ep: 5.35][Iter: 760][Time: 10.26s][Loss: 0.71009][LR: 0.00023441]\n",
            "20/12/06 15:22:24 - INFO - tape.training -   [Ep: 5.49][Iter: 780][Time: 10.22s][Loss: 0.72537][LR: 0.0002274]\n",
            "20/12/06 15:22:35 - INFO - tape.training -   [Ep: 5.63][Iter: 800][Time: 10.78s][Loss: 0.70133][LR: 0.00022039]\n",
            "20/12/06 15:22:45 - INFO - tape.training -   [Ep: 5.77][Iter: 820][Time: 10.85s][Loss: 0.71274][LR: 0.00021338]\n",
            "20/12/06 15:22:56 - INFO - tape.training -   [Ep: 5.91][Iter: 840][Time: 10.45s][Loss: 0.70163][LR: 0.00020638]\n",
            "20/12/06 15:23:03 - INFO - tape.training -   Train: [Loss: 0.70262]\n",
            "20/12/06 15:23:12 - INFO - tape.training -   Evaluation: [Loss: 0.70198]\n",
            "20/12/06 15:23:12 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:23:12 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-06-15-14-28_431319\n",
            "20/12/06 15:23:17 - INFO - tape.training -   [Ep: 6.06][Iter: 860][Time:  4.64s][Loss: 0.73531][LR: 0.00019937]\n",
            "20/12/06 15:23:28 - INFO - tape.training -   [Ep: 6.20][Iter: 880][Time: 10.92s][Loss: 0.71824][LR: 0.00019236]\n",
            "20/12/06 15:23:39 - INFO - tape.training -   [Ep: 6.34][Iter: 900][Time: 10.86s][Loss: 0.71273][LR: 0.00018535]\n",
            "20/12/06 15:23:49 - INFO - tape.training -   [Ep: 6.48][Iter: 920][Time: 10.37s][Loss: 0.71659][LR: 0.00017835]\n",
            "20/12/06 15:24:00 - INFO - tape.training -   [Ep: 6.62][Iter: 940][Time: 10.68s][Loss: 0.69916][LR: 0.00017134]\n",
            "20/12/06 15:24:10 - INFO - tape.training -   [Ep: 6.76][Iter: 960][Time: 10.70s][Loss: 0.70204][LR: 0.00016433]\n",
            "20/12/06 15:24:21 - INFO - tape.training -   [Ep: 6.90][Iter: 980][Time: 10.56s][Loss: 0.70722][LR: 0.00015732]\n",
            "20/12/06 15:24:29 - INFO - tape.training -   Train: [Loss: 0.70175]\n",
            "20/12/06 15:24:39 - INFO - tape.training -   Evaluation: [Loss: 0.7037]\n",
            "20/12/06 15:24:39 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:24:39 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-06-15-14-28_431319\n",
            "20/12/06 15:24:42 - INFO - tape.training -   [Ep: 7.04][Iter: 1000][Time:  3.67s][Loss: 0.75118][LR: 0.00015032]\n",
            "20/12/06 15:24:53 - INFO - tape.training -   [Ep: 7.18][Iter: 1020][Time: 10.49s][Loss: 0.71291][LR: 0.00014331]\n",
            "20/12/06 15:25:03 - INFO - tape.training -   [Ep: 7.32][Iter: 1040][Time: 10.16s][Loss: 0.72228][LR: 0.0001363]\n",
            "20/12/06 15:25:14 - INFO - tape.training -   [Ep: 7.46][Iter: 1060][Time: 10.51s][Loss: 0.70795][LR: 0.00012929]\n",
            "20/12/06 15:25:24 - INFO - tape.training -   [Ep: 7.60][Iter: 1080][Time: 10.29s][Loss: 0.6986][LR: 0.00012228]\n",
            "20/12/06 15:25:35 - INFO - tape.training -   [Ep: 7.74][Iter: 1100][Time: 11.10s][Loss: 0.69122][LR: 0.00011528]\n",
            "20/12/06 15:25:45 - INFO - tape.training -   [Ep: 7.88][Iter: 1120][Time: 10.40s][Loss: 0.69137][LR: 0.00010827]\n",
            "20/12/06 15:25:54 - INFO - tape.training -   Train: [Loss: 0.7001]\n",
            "20/12/06 15:26:04 - INFO - tape.training -   Evaluation: [Loss: 0.699]\n",
            "20/12/06 15:26:04 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:26:04 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-06-15-14-28_431319\n",
            "20/12/06 15:26:07 - INFO - tape.training -   [Ep: 8.03][Iter: 1140][Time:  2.47s][Loss: 0.77618][LR: 0.00010126]\n",
            "20/12/06 15:26:18 - INFO - tape.training -   [Ep: 8.17][Iter: 1160][Time: 11.20s][Loss: 0.72091][LR: 9.4254e-05]\n",
            "20/12/06 15:26:29 - INFO - tape.training -   [Ep: 8.31][Iter: 1180][Time: 11.02s][Loss: 0.71031][LR: 8.7246e-05]\n",
            "20/12/06 15:26:39 - INFO - tape.training -   [Ep: 8.45][Iter: 1200][Time: 10.41s][Loss: 0.693][LR: 8.0238e-05]\n",
            "20/12/06 15:26:50 - INFO - tape.training -   [Ep: 8.59][Iter: 1220][Time: 10.55s][Loss: 0.70271][LR: 7.3231e-05]\n",
            "20/12/06 15:27:01 - INFO - tape.training -   [Ep: 8.73][Iter: 1240][Time: 10.83s][Loss: 0.6854][LR: 6.6223e-05]\n",
            "20/12/06 15:27:12 - INFO - tape.training -   [Ep: 8.87][Iter: 1260][Time: 10.72s][Loss: 0.68098][LR: 5.9215e-05]\n",
            "20/12/06 15:27:22 - INFO - tape.training -   Train: [Loss: 0.698]\n",
            "20/12/06 15:27:32 - INFO - tape.training -   Evaluation: [Loss: 0.69853]\n",
            "20/12/06 15:27:32 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:27:32 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-06-15-14-28_431319\n",
            "20/12/06 15:27:34 - INFO - tape.training -   [Ep: 9.01][Iter: 1280][Time:  1.40s][Loss: 0.73106][LR: 5.2207e-05]\n",
            "20/12/06 15:27:44 - INFO - tape.training -   [Ep: 9.15][Iter: 1300][Time: 10.60s][Loss: 0.70748][LR: 4.52e-05]\n",
            "20/12/06 15:27:55 - INFO - tape.training -   [Ep: 9.29][Iter: 1320][Time: 10.58s][Loss: 0.70066][LR: 3.8192e-05]\n",
            "20/12/06 15:28:06 - INFO - tape.training -   [Ep: 9.43][Iter: 1340][Time: 11.25s][Loss: 0.68387][LR: 3.1184e-05]\n",
            "20/12/06 15:28:17 - INFO - tape.training -   [Ep: 9.57][Iter: 1360][Time: 10.88s][Loss: 0.71045][LR: 2.4177e-05]\n",
            "20/12/06 15:28:28 - INFO - tape.training -   [Ep: 9.71][Iter: 1380][Time: 11.28s][Loss: 0.68885][LR: 1.7169e-05]\n",
            "20/12/06 15:28:39 - INFO - tape.training -   [Ep: 9.85][Iter: 1400][Time: 10.22s][Loss: 0.66542][LR: 1.0161e-05]\n",
            "20/12/06 15:28:49 - INFO - tape.training -   [Ep: 9.99][Iter: 1420][Time: 10.56s][Loss: 0.69442][LR: 3.1535e-06]\n",
            "20/12/06 15:28:50 - INFO - tape.training -   Train: [Loss: 0.69705]\n",
            "20/12/06 15:29:00 - INFO - tape.training -   Evaluation: [Loss: 0.69849]\n",
            "20/12/06 15:29:00 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:29:00 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-06-15-14-28_431319\n",
            "20/12/06 15:29:00 - INFO - tape.training -   Finished training after 10 epochs.\n",
            "20/12/06 15:29:00 - Level 35 - tape.training -   Best Val Loss: 0.6984884142875671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRHQSKIyfD5T",
        "outputId": "e3686d2d-1006-435c-ed45-9d0c31c444fc"
      },
      "source": [
        "!tape-eval resnet fluorescence /content/results/fluorescence_resnet_20-12-06-15-14-28_431319 --metrics mse mae spearmanr  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/12/06 15:29:22 - INFO - tape.training -   device: cuda n_gpu: 1\n",
            "20/12/06 15:29:22 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/fluorescence_resnet_20-12-06-15-14-28_431319/config.json\n",
            "20/12/06 15:29:22 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": -1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/12/06 15:29:22 - INFO - tape.models.modeling_utils -   loading weights file /content/results/fluorescence_resnet_20-12-06-15-14-28_431319/pytorch_model.bin\n",
            "Evaluation: 100% 27/27 [00:06<00:00,  3.99it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[:, None]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[None, :]\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
            "  return (a < x) & (x < b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
            "  return (a < x) & (x < b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
            "  cond2 = cond0 & (x <= _a)\n",
            "20/12/06 15:29:33 - INFO - tape.training -   mse: 2.1691184043884277mae: 1.2992051839828491spearmanr: nan\n",
            "{'mse': 2.1691184, 'mae': 1.2992052, 'spearmanr': nan}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-faygRsAclNo",
        "outputId": "cfd4755d-c794-49c7-e9b9-5fab67e211bc"
      },
      "source": [
        "!tape-train-distributed resnet remote_homology --model_config_file /content/results/baseline_resnet/config.json --from_pretrained /content/results/pretrained_transformer_sincos --batch_size 150 --learning_rate 5e-4 --num_train_epochs 10 --warmup_steps 2 --gradient_accumulation_steps 50 --seed 1"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/12/06 15:30:37 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/pretrained_transformer_sincos/config.json\n",
            "20/12/06 15:30:37 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": 1195,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/12/06 15:30:37 - INFO - tape.models.modeling_utils -   loading weights file /content/results/pretrained_transformer_sincos/pytorch_model.bin\n",
            "20/12/06 15:30:37 - INFO - tape.models.modeling_utils -   Weights of ProteinResNetForSequenceClassification not initialized from pretrained model: ['embeddings.inverse_frequency', 'embeddings.word_embeddings.weight', 'embeddings.layer_norm.weight', 'embeddings.layer_norm.bias', 'encoder.layer.0.conv1.weight', 'encoder.layer.0.bn1.norm.weight', 'encoder.layer.0.bn1.norm.bias', 'encoder.layer.0.conv2.weight', 'encoder.layer.0.bn2.norm.weight', 'encoder.layer.0.bn2.norm.bias', 'encoder.layer.1.conv1.weight', 'encoder.layer.1.bn1.norm.weight', 'encoder.layer.1.bn1.norm.bias', 'encoder.layer.1.conv2.weight', 'encoder.layer.1.bn2.norm.weight', 'encoder.layer.1.bn2.norm.bias', 'encoder.layer.2.conv1.weight', 'encoder.layer.2.bn1.norm.weight', 'encoder.layer.2.bn1.norm.bias', 'encoder.layer.2.conv2.weight', 'encoder.layer.2.bn2.norm.weight', 'encoder.layer.2.bn2.norm.bias', 'pooler.attention_weights.weight', 'pooler.attention_weights.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "20/12/06 15:30:37 - INFO - tape.models.modeling_utils -   Weights from pretrained model not used in ProteinResNetForSequenceClassification: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n",
            "20/12/06 15:30:37 - INFO - tape.visualization -   tensorboard file at: logs/remote_homology_resnet_20-12-06-15-30-33_839325\n",
            "20/12/06 15:30:37 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/06 15:30:37 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/06 15:30:37 - WARNING - tape.visualization -   Cannot watch models when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/06 15:30:37 - INFO - tape.training -   device: cuda:0 n_gpu: 1, distributed_training: True, 16-bits training: False\n",
            "20/12/06 15:30:37 - INFO - tape.training -   ***** Running training *****\n",
            "20/12/06 15:30:37 - INFO - tape.training -     Num examples = 12312\n",
            "20/12/06 15:30:37 - INFO - tape.training -     Batch size = 150\n",
            "20/12/06 15:30:37 - INFO - tape.training -     Num epochs = 10\n",
            "20/12/06 15:30:37 - INFO - tape.training -     Num train steps = 820\n",
            "20/12/06 15:30:37 - INFO - tape.training -     Num parameters = 650862\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "20/12/06 15:30:49 - INFO - tape.training -   [Ep: 0.24][Iter: 20][Time: 12.72s][Loss: 6.7327][Accuracy: 0.039391][LR: 0.000489]\n",
            "20/12/06 15:31:01 - INFO - tape.training -   [Ep: 0.49][Iter: 40][Time: 11.72s][Loss: 6.1067][Accuracy: 0.066908][LR: 0.00047677]\n",
            "20/12/06 15:31:13 - INFO - tape.training -   [Ep: 0.73][Iter: 60][Time: 11.65s][Loss: 5.8295][Accuracy: 0.078251][LR: 0.00046455]\n",
            "20/12/06 15:31:25 - INFO - tape.training -   [Ep: 0.97][Iter: 80][Time: 11.77s][Loss: 5.6537][Accuracy: 0.09313][LR: 0.00045232]\n",
            "20/12/06 15:31:26 - INFO - tape.training -   Train: [Loss: 5.9085][Accuracy: 0.08122]\n",
            "20/12/06 15:31:28 - INFO - tape.training -   Evaluation: [Loss: 5.9827][Accuracy: 0.04065]\n",
            "20/12/06 15:31:28 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:31:28 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-06-15-30-33_839325\n",
            "20/12/06 15:31:39 - INFO - tape.training -   [Ep: 1.22][Iter: 100][Time: 10.80s][Loss: 5.4603][Accuracy: 0.096544][LR: 0.0004401]\n",
            "20/12/06 15:31:51 - INFO - tape.training -   [Ep: 1.46][Iter: 120][Time: 11.66s][Loss: 5.3947][Accuracy: 0.10957][LR: 0.00042787]\n",
            "20/12/06 15:32:02 - INFO - tape.training -   [Ep: 1.71][Iter: 140][Time: 11.10s][Loss: 5.3303][Accuracy: 0.1111][LR: 0.00041565]\n",
            "20/12/06 15:32:13 - INFO - tape.training -   [Ep: 1.95][Iter: 160][Time: 11.47s][Loss: 5.2747][Accuracy: 0.11618][LR: 0.00040342]\n",
            "20/12/06 15:32:16 - INFO - tape.training -   Train: [Loss: 5.3398][Accuracy: 0.11065]\n",
            "20/12/06 15:32:17 - INFO - tape.training -   Evaluation: [Loss: 5.8591][Accuracy: 0.04065]\n",
            "20/12/06 15:32:17 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:32:17 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-06-15-30-33_839325\n",
            "20/12/06 15:32:27 - INFO - tape.training -   [Ep: 2.19][Iter: 180][Time:  9.85s][Loss: 5.221][Accuracy: 0.10897][LR: 0.0003912]\n",
            "20/12/06 15:32:39 - INFO - tape.training -   [Ep: 2.44][Iter: 200][Time: 11.80s][Loss: 5.202][Accuracy: 0.12228][LR: 0.00037897]\n",
            "20/12/06 15:32:51 - INFO - tape.training -   [Ep: 2.68][Iter: 220][Time: 11.75s][Loss: 5.1606][Accuracy: 0.12404][LR: 0.00036675]\n",
            "20/12/06 15:33:02 - INFO - tape.training -   [Ep: 2.93][Iter: 240][Time: 11.48s][Loss: 5.1556][Accuracy: 0.12777][LR: 0.00035452]\n",
            "20/12/06 15:33:06 - INFO - tape.training -   Train: [Loss: 5.1773][Accuracy: 0.12]\n",
            "20/12/06 15:33:08 - INFO - tape.training -   Evaluation: [Loss: 5.796][Accuracy: 0.04336]\n",
            "20/12/06 15:33:08 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:33:08 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-06-15-30-33_839325\n",
            "20/12/06 15:33:17 - INFO - tape.training -   [Ep: 3.17][Iter: 260][Time:  8.90s][Loss: 5.1619][Accuracy: 0.11276][LR: 0.0003423]\n",
            "20/12/06 15:33:28 - INFO - tape.training -   [Ep: 3.41][Iter: 280][Time: 11.63s][Loss: 5.1247][Accuracy: 0.12505][LR: 0.00033007]\n",
            "20/12/06 15:33:40 - INFO - tape.training -   [Ep: 3.66][Iter: 300][Time: 11.88s][Loss: 5.065][Accuracy: 0.12897][LR: 0.00031785]\n",
            "20/12/06 15:33:52 - INFO - tape.training -   [Ep: 3.90][Iter: 320][Time: 11.41s][Loss: 5.0708][Accuracy: 0.12522][LR: 0.00030562]\n",
            "20/12/06 15:33:56 - INFO - tape.training -   Train: [Loss: 5.0768][Accuracy: 0.1274]\n",
            "20/12/06 15:33:58 - INFO - tape.training -   Evaluation: [Loss: 5.7303][Accuracy: 0.060976]\n",
            "20/12/06 15:33:58 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:33:58 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-06-15-30-33_839325\n",
            "20/12/06 15:34:05 - INFO - tape.training -   [Ep: 4.15][Iter: 340][Time:  7.07s][Loss: 5.1077][Accuracy: 0.11938][LR: 0.0002934]\n",
            "20/12/06 15:34:17 - INFO - tape.training -   [Ep: 4.39][Iter: 360][Time: 11.74s][Loss: 5.0465][Accuracy: 0.13255][LR: 0.00028117]\n",
            "20/12/06 15:34:28 - INFO - tape.training -   [Ep: 4.63][Iter: 380][Time: 11.20s][Loss: 5.0064][Accuracy: 0.1312][LR: 0.00026895]\n",
            "20/12/06 15:34:39 - INFO - tape.training -   [Ep: 4.88][Iter: 400][Time: 11.01s][Loss: 4.9913][Accuracy: 0.12934][LR: 0.00025672]\n",
            "20/12/06 15:34:45 - INFO - tape.training -   Train: [Loss: 4.9906][Accuracy: 0.13285]\n",
            "20/12/06 15:34:47 - INFO - tape.training -   Evaluation: [Loss: 5.7302][Accuracy: 0.058266]\n",
            "20/12/06 15:34:47 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:34:47 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-06-15-30-33_839325\n",
            "20/12/06 15:34:53 - INFO - tape.training -   [Ep: 5.12][Iter: 420][Time:  5.66s][Loss: 5.0664][Accuracy: 0.1271][LR: 0.0002445]\n",
            "20/12/06 15:35:04 - INFO - tape.training -   [Ep: 5.37][Iter: 440][Time: 11.62s][Loss: 5.0052][Accuracy: 0.13736][LR: 0.00023227]\n",
            "20/12/06 15:35:15 - INFO - tape.training -   [Ep: 5.61][Iter: 460][Time: 10.75s][Loss: 4.9632][Accuracy: 0.13881][LR: 0.00022005]\n",
            "20/12/06 15:35:26 - INFO - tape.training -   [Ep: 5.85][Iter: 480][Time: 10.66s][Loss: 4.9482][Accuracy: 0.13611][LR: 0.00020782]\n",
            "20/12/06 15:35:33 - INFO - tape.training -   Train: [Loss: 4.9378][Accuracy: 0.14146]\n",
            "20/12/06 15:35:34 - INFO - tape.training -   Evaluation: [Loss: 5.7054][Accuracy: 0.060976]\n",
            "20/12/06 15:35:34 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:35:34 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-06-15-30-33_839325\n",
            "20/12/06 15:35:39 - INFO - tape.training -   [Ep: 6.10][Iter: 500][Time:  4.83s][Loss: 5.1942][Accuracy: 0.11849][LR: 0.0001956]\n",
            "20/12/06 15:35:51 - INFO - tape.training -   [Ep: 6.34][Iter: 520][Time: 11.55s][Loss: 5.0223][Accuracy: 0.1314][LR: 0.00018337]\n",
            "20/12/06 15:36:02 - INFO - tape.training -   [Ep: 6.58][Iter: 540][Time: 11.50s][Loss: 4.9183][Accuracy: 0.13913][LR: 0.00017115]\n",
            "20/12/06 15:36:13 - INFO - tape.training -   [Ep: 6.83][Iter: 560][Time: 10.74s][Loss: 4.9088][Accuracy: 0.13846][LR: 0.00015892]\n",
            "20/12/06 15:36:21 - INFO - tape.training -   Train: [Loss: 4.8846][Accuracy: 0.14114]\n",
            "20/12/06 15:36:23 - INFO - tape.training -   Evaluation: [Loss: 5.6784][Accuracy: 0.059621]\n",
            "20/12/06 15:36:23 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:36:23 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-06-15-30-33_839325\n",
            "20/12/06 15:36:27 - INFO - tape.training -   [Ep: 7.07][Iter: 580][Time:  3.63s][Loss: 5.1396][Accuracy: 0.10532][LR: 0.0001467]\n",
            "20/12/06 15:36:38 - INFO - tape.training -   [Ep: 7.32][Iter: 600][Time: 10.87s][Loss: 4.9819][Accuracy: 0.12694][LR: 0.00013447]\n",
            "20/12/06 15:36:48 - INFO - tape.training -   [Ep: 7.56][Iter: 620][Time: 10.88s][Loss: 4.878][Accuracy: 0.14036][LR: 0.00012225]\n",
            "20/12/06 15:37:00 - INFO - tape.training -   [Ep: 7.80][Iter: 640][Time: 11.13s][Loss: 4.8757][Accuracy: 0.13846][LR: 0.00011002]\n",
            "20/12/06 15:37:09 - INFO - tape.training -   Train: [Loss: 4.8583][Accuracy: 0.14146]\n",
            "20/12/06 15:37:11 - INFO - tape.training -   Evaluation: [Loss: 5.6841][Accuracy: 0.060976]\n",
            "20/12/06 15:37:11 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:37:11 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-06-15-30-33_839325\n",
            "20/12/06 15:37:13 - INFO - tape.training -   [Ep: 8.05][Iter: 660][Time:  2.43s][Loss: 5.0529][Accuracy: 0.12575][LR: 9.78e-05]\n",
            "20/12/06 15:37:25 - INFO - tape.training -   [Ep: 8.29][Iter: 680][Time: 11.29s][Loss: 4.9248][Accuracy: 0.13835][LR: 8.5575e-05]\n",
            "20/12/06 15:37:36 - INFO - tape.training -   [Ep: 8.54][Iter: 700][Time: 10.89s][Loss: 4.8617][Accuracy: 0.14434][LR: 7.335e-05]\n",
            "20/12/06 15:37:47 - INFO - tape.training -   [Ep: 8.78][Iter: 720][Time: 11.11s][Loss: 4.8593][Accuracy: 0.14055][LR: 6.1125e-05]\n",
            "20/12/06 15:37:57 - INFO - tape.training -   Train: [Loss: 4.8387][Accuracy: 0.14268]\n",
            "20/12/06 15:37:59 - INFO - tape.training -   Evaluation: [Loss: 5.6639][Accuracy: 0.059621]\n",
            "20/12/06 15:37:59 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:37:59 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-06-15-30-33_839325\n",
            "20/12/06 15:38:00 - INFO - tape.training -   [Ep: 9.02][Iter: 740][Time:  1.49s][Loss: 4.9594][Accuracy: 0.14467][LR: 4.89e-05]\n",
            "20/12/06 15:38:11 - INFO - tape.training -   [Ep: 9.27][Iter: 760][Time: 11.30s][Loss: 4.888][Accuracy: 0.14336][LR: 3.6675e-05]\n",
            "20/12/06 15:38:22 - INFO - tape.training -   [Ep: 9.51][Iter: 780][Time: 11.11s][Loss: 4.8386][Accuracy: 0.14552][LR: 2.445e-05]\n",
            "20/12/06 15:38:34 - INFO - tape.training -   [Ep: 9.76][Iter: 800][Time: 11.20s][Loss: 4.8325][Accuracy: 0.14359][LR: 1.2225e-05]\n",
            "20/12/06 15:38:45 - INFO - tape.training -   [Ep: 10.00][Iter: 820][Time: 11.33s][Loss: 4.7958][Accuracy: 0.14884][LR: 0]\n",
            "20/12/06 15:38:45 - INFO - tape.training -   Train: [Loss: 4.8224][Accuracy: 0.14415]\n",
            "20/12/06 15:38:47 - INFO - tape.training -   Evaluation: [Loss: 5.6538][Accuracy: 0.059621]\n",
            "20/12/06 15:38:47 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:38:47 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-06-15-30-33_839325\n",
            "20/12/06 15:38:47 - INFO - tape.training -   Finished training after 10 epochs.\n",
            "20/12/06 15:38:47 - Level 35 - tape.training -   Best Val Loss: 5.653836727142334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbgTxvUifEUF"
      },
      "source": [
        "# !tape-eval resnet remote_homology /content/results/secondary_structure_transformer_20-11-16-15-36-39_069321 --metrics mse mae spearmanr "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9xC0m3CclQT",
        "outputId": "2528cd75-a60c-4fdd-bcdd-75d4be63f5dd"
      },
      "source": [
        "!tape-train-distributed resnet secondary_structure --model_config_file /content/results/baseline_resnet/config.json --from_pretrained /content/results/pretrained_transformer_sincos --batch_size 150 --learning_rate 5e-4 --num_train_epochs 10 --warmup_steps 2 --gradient_accumulation_steps 50 --seed 1"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/12/06 15:46:08 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/pretrained_transformer_sincos/config.json\n",
            "20/12/06 15:46:08 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": 3,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/12/06 15:46:08 - INFO - tape.models.modeling_utils -   loading weights file /content/results/pretrained_transformer_sincos/pytorch_model.bin\n",
            "20/12/06 15:46:08 - INFO - tape.models.modeling_utils -   Weights of ProteinResNetForSequenceToSequenceClassification not initialized from pretrained model: ['embeddings.inverse_frequency', 'embeddings.word_embeddings.weight', 'embeddings.layer_norm.weight', 'embeddings.layer_norm.bias', 'encoder.layer.0.conv1.weight', 'encoder.layer.0.bn1.norm.weight', 'encoder.layer.0.bn1.norm.bias', 'encoder.layer.0.conv2.weight', 'encoder.layer.0.bn2.norm.weight', 'encoder.layer.0.bn2.norm.bias', 'encoder.layer.1.conv1.weight', 'encoder.layer.1.bn1.norm.weight', 'encoder.layer.1.bn1.norm.bias', 'encoder.layer.1.conv2.weight', 'encoder.layer.1.bn2.norm.weight', 'encoder.layer.1.bn2.norm.bias', 'encoder.layer.2.conv1.weight', 'encoder.layer.2.bn1.norm.weight', 'encoder.layer.2.bn1.norm.bias', 'encoder.layer.2.conv2.weight', 'encoder.layer.2.bn2.norm.weight', 'encoder.layer.2.bn2.norm.bias', 'pooler.attention_weights.weight', 'pooler.attention_weights.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "20/12/06 15:46:08 - INFO - tape.models.modeling_utils -   Weights from pretrained model not used in ProteinResNetForSequenceToSequenceClassification: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n",
            "20/12/06 15:46:08 - INFO - tape.visualization -   tensorboard file at: logs/secondary_structure_resnet_20-12-06-15-46-03_063178\n",
            "20/12/06 15:46:08 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/06 15:46:08 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/06 15:46:08 - WARNING - tape.visualization -   Cannot watch models when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/06 15:46:08 - INFO - tape.training -   device: cuda:0 n_gpu: 1, distributed_training: True, 16-bits training: False\n",
            "20/12/06 15:46:08 - INFO - tape.training -   ***** Running training *****\n",
            "20/12/06 15:46:08 - INFO - tape.training -     Num examples = 8678\n",
            "20/12/06 15:46:08 - INFO - tape.training -     Batch size = 150\n",
            "20/12/06 15:46:08 - INFO - tape.training -     Num epochs = 10\n",
            "20/12/06 15:46:08 - INFO - tape.training -     Num train steps = 578\n",
            "20/12/06 15:46:08 - INFO - tape.training -     Num parameters = 108038\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "20/12/06 15:46:21 - INFO - tape.training -   [Ep: 0.35][Iter: 20][Time: 13.47s][Loss: 1.0892][Accuracy: 0.38809][LR: 0.00048437]\n",
            "20/12/06 15:46:33 - INFO - tape.training -   [Ep: 0.69][Iter: 40][Time: 11.97s][Loss: 1.0781][Accuracy: 0.40644][LR: 0.00046701]\n",
            "20/12/06 15:46:44 - INFO - tape.training -   Train: [Loss: 1.076][Accuracy: 0.40853]\n",
            "20/12/06 15:46:49 - INFO - tape.training -   Evaluation: [Loss: 1.0553][Accuracy: 0.43141]\n",
            "20/12/06 15:46:49 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:46:49 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-06-15-46-03_063178\n",
            "20/12/06 15:46:52 - INFO - tape.training -   [Ep: 1.05][Iter: 60][Time:  2.14s][Loss: 1.0581][Accuracy: 0.42533][LR: 0.00044965]\n",
            "20/12/06 15:47:04 - INFO - tape.training -   [Ep: 1.40][Iter: 80][Time: 12.48s][Loss: 1.0619][Accuracy: 0.41717][LR: 0.00043229]\n",
            "20/12/06 15:47:17 - INFO - tape.training -   [Ep: 1.74][Iter: 100][Time: 12.77s][Loss: 1.0574][Accuracy: 0.42109][LR: 0.00041493]\n",
            "20/12/06 15:47:26 - INFO - tape.training -   Train: [Loss: 1.0574][Accuracy: 0.4199]\n",
            "20/12/06 15:47:31 - INFO - tape.training -   Evaluation: [Loss: 1.0341][Accuracy: 0.45584]\n",
            "20/12/06 15:47:31 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:47:31 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-06-15-46-03_063178\n",
            "20/12/06 15:47:35 - INFO - tape.training -   [Ep: 2.10][Iter: 120][Time:  4.03s][Loss: 1.0494][Accuracy: 0.44426][LR: 0.00039757]\n",
            "20/12/06 15:47:48 - INFO - tape.training -   [Ep: 2.45][Iter: 140][Time: 12.42s][Loss: 1.0391][Accuracy: 0.45383][LR: 0.00038021]\n",
            "20/12/06 15:48:00 - INFO - tape.training -   [Ep: 2.79][Iter: 160][Time: 12.26s][Loss: 1.0166][Accuracy: 0.48384][LR: 0.00036285]\n",
            "20/12/06 15:48:07 - INFO - tape.training -   Train: [Loss: 1.0166][Accuracy: 0.48117]\n",
            "20/12/06 15:48:13 - INFO - tape.training -   Evaluation: [Loss: 0.97377][Accuracy: 0.54976]\n",
            "20/12/06 15:48:13 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:48:13 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-06-15-46-03_063178\n",
            "20/12/06 15:48:19 - INFO - tape.training -   [Ep: 3.16][Iter: 180][Time:  6.20s][Loss: 0.97254][Accuracy: 0.5269][LR: 0.00034549]\n",
            "20/12/06 15:48:31 - INFO - tape.training -   [Ep: 3.50][Iter: 200][Time: 12.29s][Loss: 0.96742][Accuracy: 0.53138][LR: 0.00032813]\n",
            "20/12/06 15:48:44 - INFO - tape.training -   [Ep: 3.85][Iter: 220][Time: 12.31s][Loss: 0.95939][Accuracy: 0.53751][LR: 0.00031076]\n",
            "20/12/06 15:48:49 - INFO - tape.training -   Train: [Loss: 0.96163][Accuracy: 0.53662]\n",
            "20/12/06 15:48:55 - INFO - tape.training -   Evaluation: [Loss: 0.91622][Accuracy: 0.57587]\n",
            "20/12/06 15:48:55 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:48:55 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-06-15-46-03_063178\n",
            "20/12/06 15:49:03 - INFO - tape.training -   [Ep: 4.21][Iter: 240][Time:  7.75s][Loss: 0.93781][Accuracy: 0.55562][LR: 0.0002934]\n",
            "20/12/06 15:49:15 - INFO - tape.training -   [Ep: 4.55][Iter: 260][Time: 12.70s][Loss: 0.92874][Accuracy: 0.56145][LR: 0.00027604]\n",
            "20/12/06 15:49:28 - INFO - tape.training -   [Ep: 4.90][Iter: 280][Time: 12.51s][Loss: 0.91856][Accuracy: 0.5675][LR: 0.00025868]\n",
            "20/12/06 15:49:32 - INFO - tape.training -   Train: [Loss: 0.92175][Accuracy: 0.5668]\n",
            "20/12/06 15:49:37 - INFO - tape.training -   Evaluation: [Loss: 0.8858][Accuracy: 0.60192]\n",
            "20/12/06 15:49:37 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:49:37 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-06-15-46-03_063178\n",
            "20/12/06 15:49:46 - INFO - tape.training -   [Ep: 5.26][Iter: 300][Time:  9.56s][Loss: 0.90881][Accuracy: 0.57712][LR: 0.00024132]\n",
            "20/12/06 15:49:58 - INFO - tape.training -   [Ep: 5.60][Iter: 320][Time: 12.09s][Loss: 0.8984][Accuracy: 0.58409][LR: 0.00022396]\n",
            "20/12/06 15:50:11 - INFO - tape.training -   [Ep: 5.95][Iter: 340][Time: 12.35s][Loss: 0.89401][Accuracy: 0.5866][LR: 0.0002066]\n",
            "20/12/06 15:50:13 - INFO - tape.training -   Train: [Loss: 0.8941][Accuracy: 0.58672]\n",
            "20/12/06 15:50:18 - INFO - tape.training -   Evaluation: [Loss: 0.87311][Accuracy: 0.6059]\n",
            "20/12/06 15:50:18 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:50:18 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-06-15-46-03_063178\n",
            "20/12/06 15:50:30 - INFO - tape.training -   [Ep: 6.31][Iter: 360][Time: 11.51s][Loss: 0.87669][Accuracy: 0.59924][LR: 0.00018924]\n",
            "20/12/06 15:50:42 - INFO - tape.training -   [Ep: 6.66][Iter: 380][Time: 12.58s][Loss: 0.87605][Accuracy: 0.59944][LR: 0.00017187]\n",
            "20/12/06 15:50:54 - INFO - tape.training -   Train: [Loss: 0.87788][Accuracy: 0.59727]\n",
            "20/12/06 15:51:00 - INFO - tape.training -   Evaluation: [Loss: 0.87795][Accuracy: 0.59212]\n",
            "20/12/06 15:51:00 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:51:00 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-06-15-46-03_063178\n",
            "20/12/06 15:51:01 - INFO - tape.training -   [Ep: 7.02][Iter: 400][Time:  0.94s][Loss: 0.87349][Accuracy: 0.60299][LR: 0.00015451]\n",
            "20/12/06 15:51:13 - INFO - tape.training -   [Ep: 7.36][Iter: 420][Time: 12.31s][Loss: 0.87004][Accuracy: 0.60358][LR: 0.00013715]\n",
            "20/12/06 15:51:26 - INFO - tape.training -   [Ep: 7.71][Iter: 440][Time: 12.89s][Loss: 0.86624][Accuracy: 0.60482][LR: 0.00011979]\n",
            "20/12/06 15:51:36 - INFO - tape.training -   Train: [Loss: 0.86478][Accuracy: 0.60584]\n",
            "20/12/06 15:51:41 - INFO - tape.training -   Evaluation: [Loss: 0.85715][Accuracy: 0.60955]\n",
            "20/12/06 15:51:41 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:51:41 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-06-15-46-03_063178\n",
            "20/12/06 15:51:44 - INFO - tape.training -   [Ep: 8.07][Iter: 460][Time:  2.91s][Loss: 0.85911][Accuracy: 0.61034][LR: 0.00010243]\n",
            "20/12/06 15:51:56 - INFO - tape.training -   [Ep: 8.41][Iter: 480][Time: 11.78s][Loss: 0.85782][Accuracy: 0.61064][LR: 8.5069e-05]\n",
            "20/12/06 15:52:08 - INFO - tape.training -   [Ep: 8.76][Iter: 500][Time: 11.83s][Loss: 0.85511][Accuracy: 0.6117][LR: 6.7708e-05]\n",
            "20/12/06 15:52:16 - INFO - tape.training -   Train: [Loss: 0.85469][Accuracy: 0.61237]\n",
            "20/12/06 15:52:21 - INFO - tape.training -   Evaluation: [Loss: 0.84924][Accuracy: 0.61628]\n",
            "20/12/06 15:52:21 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:52:21 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-06-15-46-03_063178\n",
            "20/12/06 15:52:26 - INFO - tape.training -   [Ep: 9.12][Iter: 520][Time:  4.67s][Loss: 0.85921][Accuracy: 0.61304][LR: 5.0347e-05]\n",
            "20/12/06 15:52:37 - INFO - tape.training -   [Ep: 9.47][Iter: 540][Time: 11.58s][Loss: 0.85384][Accuracy: 0.61444][LR: 3.2986e-05]\n",
            "20/12/06 15:52:50 - INFO - tape.training -   [Ep: 9.81][Iter: 560][Time: 12.20s][Loss: 0.84756][Accuracy: 0.61728][LR: 1.5625e-05]\n",
            "20/12/06 15:52:56 - INFO - tape.training -   Train: [Loss: 0.84687][Accuracy: 0.61754]\n",
            "20/12/06 15:53:02 - INFO - tape.training -   Evaluation: [Loss: 0.83833][Accuracy: 0.62406]\n",
            "20/12/06 15:53:02 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:53:02 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-06-15-46-03_063178\n",
            "20/12/06 15:53:02 - INFO - tape.training -   Finished training after 10 epochs.\n",
            "20/12/06 15:53:02 - Level 35 - tape.training -   Best Val Loss: 0.8383323550224304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmTVYN62fEwJ"
      },
      "source": [
        "# !tape-eval resnet secondary_structure /content/results/secondary_structure_transformer_20-11-16-15-36-39_069321 --metrics mse mae spearmanr accuracy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAsP4o9HclSs",
        "outputId": "b63dbbe5-f4ba-42d2-d0a4-f5e0a9180730"
      },
      "source": [
        "!tape-train-distributed resnet stability --model_config_file /content/results/baseline_resnet/config.json --from_pretrained /content/results/pretrained_transformer_sincos --batch_size 150 --learning_rate 5e-4 --num_train_epochs 10 --warmup_steps 2 --gradient_accumulation_steps 50 --seed 1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/12/06 15:53:07 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/pretrained_transformer_sincos/config.json\n",
            "20/12/06 15:53:07 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": -1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/12/06 15:53:07 - INFO - tape.models.modeling_utils -   loading weights file /content/results/pretrained_transformer_sincos/pytorch_model.bin\n",
            "20/12/06 15:53:07 - INFO - tape.models.modeling_utils -   Weights of ProteinResNetForValuePrediction not initialized from pretrained model: ['embeddings.inverse_frequency', 'embeddings.word_embeddings.weight', 'embeddings.layer_norm.weight', 'embeddings.layer_norm.bias', 'encoder.layer.0.conv1.weight', 'encoder.layer.0.bn1.norm.weight', 'encoder.layer.0.bn1.norm.bias', 'encoder.layer.0.conv2.weight', 'encoder.layer.0.bn2.norm.weight', 'encoder.layer.0.bn2.norm.bias', 'encoder.layer.1.conv1.weight', 'encoder.layer.1.bn1.norm.weight', 'encoder.layer.1.bn1.norm.bias', 'encoder.layer.1.conv2.weight', 'encoder.layer.1.bn2.norm.weight', 'encoder.layer.1.bn2.norm.bias', 'encoder.layer.2.conv1.weight', 'encoder.layer.2.bn1.norm.weight', 'encoder.layer.2.bn1.norm.bias', 'encoder.layer.2.conv2.weight', 'encoder.layer.2.bn2.norm.weight', 'encoder.layer.2.bn2.norm.bias', 'pooler.attention_weights.weight', 'pooler.attention_weights.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "20/12/06 15:53:07 - INFO - tape.models.modeling_utils -   Weights from pretrained model not used in ProteinResNetForValuePrediction: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n",
            "20/12/06 15:53:07 - INFO - tape.visualization -   tensorboard file at: logs/stability_resnet_20-12-06-15-53-03_313935\n",
            "20/12/06 15:53:07 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/06 15:53:07 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/06 15:53:07 - WARNING - tape.visualization -   Cannot watch models when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/06 15:53:07 - INFO - tape.training -   device: cuda:0 n_gpu: 1, distributed_training: True, 16-bits training: False\n",
            "20/12/06 15:53:07 - INFO - tape.training -   ***** Running training *****\n",
            "20/12/06 15:53:07 - INFO - tape.training -     Num examples = 53614\n",
            "20/12/06 15:53:07 - INFO - tape.training -     Batch size = 150\n",
            "20/12/06 15:53:07 - INFO - tape.training -     Num epochs = 10\n",
            "20/12/06 15:53:07 - INFO - tape.training -     Num train steps = 3574\n",
            "20/12/06 15:53:07 - INFO - tape.training -     Num parameters = 38340\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "20/12/06 15:53:18 - INFO - tape.training -   [Ep: 0.06][Iter: 20][Time: 10.93s][Loss: 0.36292][LR: 0.00049748]\n",
            "20/12/06 15:53:29 - INFO - tape.training -   [Ep: 0.11][Iter: 40][Time: 10.58s][Loss: 0.33235][LR: 0.00049468]\n",
            "20/12/06 15:53:39 - INFO - tape.training -   [Ep: 0.17][Iter: 60][Time: 10.52s][Loss: 0.35576][LR: 0.00049188]\n",
            "20/12/06 15:53:49 - INFO - tape.training -   [Ep: 0.22][Iter: 80][Time: 10.30s][Loss: 0.34853][LR: 0.00048908]\n",
            "20/12/06 15:54:00 - INFO - tape.training -   [Ep: 0.28][Iter: 100][Time: 10.66s][Loss: 0.33968][LR: 0.00048628]\n",
            "20/12/06 15:54:11 - INFO - tape.training -   [Ep: 0.34][Iter: 120][Time: 10.55s][Loss: 0.32806][LR: 0.00048348]\n",
            "20/12/06 15:54:21 - INFO - tape.training -   [Ep: 0.39][Iter: 140][Time: 10.19s][Loss: 0.33455][LR: 0.00048068]\n",
            "20/12/06 15:54:31 - INFO - tape.training -   [Ep: 0.45][Iter: 160][Time: 10.67s][Loss: 0.32869][LR: 0.00047788]\n",
            "20/12/06 15:54:42 - INFO - tape.training -   [Ep: 0.50][Iter: 180][Time: 10.55s][Loss: 0.33879][LR: 0.00047508]\n",
            "20/12/06 15:54:53 - INFO - tape.training -   [Ep: 0.56][Iter: 200][Time: 10.49s][Loss: 0.32641][LR: 0.00047228]\n",
            "20/12/06 15:55:03 - INFO - tape.training -   [Ep: 0.62][Iter: 220][Time: 10.67s][Loss: 0.33652][LR: 0.00046948]\n",
            "20/12/06 15:55:14 - INFO - tape.training -   [Ep: 0.67][Iter: 240][Time: 10.48s][Loss: 0.33788][LR: 0.00046669]\n",
            "20/12/06 15:55:24 - INFO - tape.training -   [Ep: 0.73][Iter: 260][Time: 10.55s][Loss: 0.3396][LR: 0.00046389]\n",
            "20/12/06 15:55:35 - INFO - tape.training -   [Ep: 0.78][Iter: 280][Time: 10.50s][Loss: 0.32439][LR: 0.00046109]\n",
            "20/12/06 15:55:45 - INFO - tape.training -   [Ep: 0.84][Iter: 300][Time: 10.52s][Loss: 0.33166][LR: 0.00045829]\n",
            "20/12/06 15:55:56 - INFO - tape.training -   [Ep: 0.90][Iter: 320][Time: 10.35s][Loss: 0.32762][LR: 0.00045549]\n",
            "20/12/06 15:56:06 - INFO - tape.training -   [Ep: 0.95][Iter: 340][Time: 10.80s][Loss: 0.31384][LR: 0.00045269]\n",
            "20/12/06 15:56:16 - INFO - tape.training -   Train: [Loss: 0.33255]\n",
            "20/12/06 15:56:21 - INFO - tape.training -   Evaluation: [Loss: 0.43268]\n",
            "20/12/06 15:56:21 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:56:21 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-06-15-53-03_313935\n",
            "20/12/06 15:56:23 - INFO - tape.training -   [Ep: 1.01][Iter: 360][Time:  1.92s][Loss: 0.35372][LR: 0.00044989]\n",
            "20/12/06 15:56:34 - INFO - tape.training -   [Ep: 1.06][Iter: 380][Time: 11.42s][Loss: 0.32955][LR: 0.00044709]\n",
            "20/12/06 15:56:45 - INFO - tape.training -   [Ep: 1.12][Iter: 400][Time: 10.81s][Loss: 0.3179][LR: 0.00044429]\n",
            "20/12/06 15:56:56 - INFO - tape.training -   [Ep: 1.18][Iter: 420][Time: 10.82s][Loss: 0.32995][LR: 0.00044149]\n",
            "20/12/06 15:57:06 - INFO - tape.training -   [Ep: 1.23][Iter: 440][Time: 10.42s][Loss: 0.32946][LR: 0.00043869]\n",
            "20/12/06 15:57:17 - INFO - tape.training -   [Ep: 1.29][Iter: 460][Time: 11.01s][Loss: 0.32772][LR: 0.00043589]\n",
            "20/12/06 15:57:28 - INFO - tape.training -   [Ep: 1.34][Iter: 480][Time: 10.49s][Loss: 0.32755][LR: 0.00043309]\n",
            "20/12/06 15:57:38 - INFO - tape.training -   [Ep: 1.40][Iter: 500][Time: 10.66s][Loss: 0.3242][LR: 0.00043029]\n",
            "20/12/06 15:57:49 - INFO - tape.training -   [Ep: 1.46][Iter: 520][Time: 10.55s][Loss: 0.32303][LR: 0.00042749]\n",
            "20/12/06 15:57:59 - INFO - tape.training -   [Ep: 1.51][Iter: 540][Time: 10.26s][Loss: 0.34035][LR: 0.00042469]\n",
            "20/12/06 15:58:10 - INFO - tape.training -   [Ep: 1.57][Iter: 560][Time: 11.05s][Loss: 0.32516][LR: 0.00042189]\n",
            "20/12/06 15:58:21 - INFO - tape.training -   [Ep: 1.62][Iter: 580][Time: 10.65s][Loss: 0.3337][LR: 0.00041909]\n",
            "20/12/06 15:58:32 - INFO - tape.training -   [Ep: 1.68][Iter: 600][Time: 11.03s][Loss: 0.34059][LR: 0.00041629]\n",
            "20/12/06 15:58:43 - INFO - tape.training -   [Ep: 1.74][Iter: 620][Time: 10.69s][Loss: 0.33499][LR: 0.00041349]\n",
            "20/12/06 15:58:54 - INFO - tape.training -   [Ep: 1.79][Iter: 640][Time: 10.96s][Loss: 0.31933][LR: 0.00041069]\n",
            "20/12/06 15:59:04 - INFO - tape.training -   [Ep: 1.85][Iter: 660][Time: 10.40s][Loss: 0.32794][LR: 0.00040789]\n",
            "20/12/06 15:59:15 - INFO - tape.training -   [Ep: 1.90][Iter: 680][Time: 10.65s][Loss: 0.33228][LR: 0.0004051]\n",
            "20/12/06 15:59:25 - INFO - tape.training -   [Ep: 1.96][Iter: 700][Time: 10.71s][Loss: 0.31711][LR: 0.0004023]\n",
            "20/12/06 15:59:33 - INFO - tape.training -   Train: [Loss: 0.32614]\n",
            "20/12/06 15:59:38 - INFO - tape.training -   Evaluation: [Loss: 0.43336]\n",
            "20/12/06 15:59:38 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 15:59:38 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-06-15-53-03_313935\n",
            "20/12/06 15:59:41 - INFO - tape.training -   [Ep: 2.02][Iter: 720][Time:  3.49s][Loss: 0.33404][LR: 0.0003995]\n",
            "20/12/06 15:59:52 - INFO - tape.training -   [Ep: 2.07][Iter: 740][Time: 10.52s][Loss: 0.32498][LR: 0.0003967]\n",
            "20/12/06 16:00:03 - INFO - tape.training -   [Ep: 2.13][Iter: 760][Time: 10.68s][Loss: 0.31764][LR: 0.0003939]\n",
            "20/12/06 16:00:13 - INFO - tape.training -   [Ep: 2.18][Iter: 780][Time: 10.22s][Loss: 0.32771][LR: 0.0003911]\n",
            "20/12/06 16:00:23 - INFO - tape.training -   [Ep: 2.24][Iter: 800][Time: 10.65s][Loss: 0.32844][LR: 0.0003883]\n",
            "20/12/06 16:00:34 - INFO - tape.training -   [Ep: 2.30][Iter: 820][Time: 10.28s][Loss: 0.32849][LR: 0.0003855]\n",
            "20/12/06 16:00:44 - INFO - tape.training -   [Ep: 2.35][Iter: 840][Time: 10.01s][Loss: 0.32176][LR: 0.0003827]\n",
            "20/12/06 16:00:54 - INFO - tape.training -   [Ep: 2.41][Iter: 860][Time:  9.84s][Loss: 0.32493][LR: 0.0003799]\n",
            "20/12/06 16:01:04 - INFO - tape.training -   [Ep: 2.46][Iter: 880][Time: 10.38s][Loss: 0.3251][LR: 0.0003771]\n",
            "20/12/06 16:01:14 - INFO - tape.training -   [Ep: 2.52][Iter: 900][Time:  9.93s][Loss: 0.31913][LR: 0.0003743]\n",
            "20/12/06 16:01:24 - INFO - tape.training -   [Ep: 2.58][Iter: 920][Time: 10.24s][Loss: 0.31368][LR: 0.0003715]\n",
            "20/12/06 16:01:35 - INFO - tape.training -   [Ep: 2.63][Iter: 940][Time: 10.79s][Loss: 0.32147][LR: 0.0003687]\n",
            "20/12/06 16:01:46 - INFO - tape.training -   [Ep: 2.69][Iter: 960][Time: 10.97s][Loss: 0.33169][LR: 0.0003659]\n",
            "20/12/06 16:01:56 - INFO - tape.training -   [Ep: 2.74][Iter: 980][Time: 10.39s][Loss: 0.32535][LR: 0.0003631]\n",
            "20/12/06 16:02:06 - INFO - tape.training -   [Ep: 2.80][Iter: 1000][Time: 10.13s][Loss: 0.31467][LR: 0.0003603]\n",
            "20/12/06 16:02:17 - INFO - tape.training -   [Ep: 2.86][Iter: 1020][Time: 10.14s][Loss: 0.32639][LR: 0.0003575]\n",
            "20/12/06 16:02:27 - INFO - tape.training -   [Ep: 2.91][Iter: 1040][Time: 10.15s][Loss: 0.31863][LR: 0.0003547]\n",
            "20/12/06 16:02:38 - INFO - tape.training -   [Ep: 2.97][Iter: 1060][Time: 10.88s][Loss: 0.31392][LR: 0.0003519]\n",
            "20/12/06 16:02:43 - INFO - tape.training -   Train: [Loss: 0.32225]\n",
            "20/12/06 16:02:48 - INFO - tape.training -   Evaluation: [Loss: 0.43671]\n",
            "20/12/06 16:02:48 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 16:02:48 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-06-15-53-03_313935\n",
            "20/12/06 16:02:53 - INFO - tape.training -   [Ep: 3.03][Iter: 1080][Time:  4.91s][Loss: 0.32299][LR: 0.0003491]\n",
            "20/12/06 16:03:04 - INFO - tape.training -   [Ep: 3.08][Iter: 1100][Time: 10.70s][Loss: 0.32018][LR: 0.0003463]\n",
            "20/12/06 16:03:14 - INFO - tape.training -   [Ep: 3.14][Iter: 1120][Time: 10.61s][Loss: 0.32082][LR: 0.00034351]\n",
            "20/12/06 16:03:25 - INFO - tape.training -   [Ep: 3.19][Iter: 1140][Time: 10.50s][Loss: 0.32938][LR: 0.00034071]\n",
            "20/12/06 16:03:36 - INFO - tape.training -   [Ep: 3.25][Iter: 1160][Time: 10.69s][Loss: 0.32673][LR: 0.00033791]\n",
            "20/12/06 16:03:47 - INFO - tape.training -   [Ep: 3.30][Iter: 1180][Time: 10.92s][Loss: 0.3251][LR: 0.00033511]\n",
            "20/12/06 16:03:57 - INFO - tape.training -   [Ep: 3.36][Iter: 1200][Time: 10.44s][Loss: 0.32131][LR: 0.00033231]\n",
            "20/12/06 16:04:08 - INFO - tape.training -   [Ep: 3.42][Iter: 1220][Time: 10.56s][Loss: 0.32743][LR: 0.00032951]\n",
            "20/12/06 16:04:18 - INFO - tape.training -   [Ep: 3.47][Iter: 1240][Time: 10.81s][Loss: 0.32626][LR: 0.00032671]\n",
            "20/12/06 16:04:29 - INFO - tape.training -   [Ep: 3.53][Iter: 1260][Time: 10.49s][Loss: 0.32135][LR: 0.00032391]\n",
            "20/12/06 16:04:39 - INFO - tape.training -   [Ep: 3.58][Iter: 1280][Time: 10.54s][Loss: 0.31776][LR: 0.00032111]\n",
            "20/12/06 16:04:50 - INFO - tape.training -   [Ep: 3.64][Iter: 1300][Time: 10.73s][Loss: 0.32206][LR: 0.00031831]\n",
            "20/12/06 16:05:01 - INFO - tape.training -   [Ep: 3.70][Iter: 1320][Time: 10.46s][Loss: 0.33273][LR: 0.00031551]\n",
            "20/12/06 16:05:11 - INFO - tape.training -   [Ep: 3.75][Iter: 1340][Time: 10.46s][Loss: 0.32557][LR: 0.00031271]\n",
            "20/12/06 16:05:21 - INFO - tape.training -   [Ep: 3.81][Iter: 1360][Time: 10.32s][Loss: 0.31295][LR: 0.00030991]\n",
            "20/12/06 16:05:32 - INFO - tape.training -   [Ep: 3.86][Iter: 1380][Time: 10.58s][Loss: 0.31971][LR: 0.00030711]\n",
            "20/12/06 16:05:43 - INFO - tape.training -   [Ep: 3.92][Iter: 1400][Time: 10.62s][Loss: 0.31157][LR: 0.00030431]\n",
            "20/12/06 16:05:53 - INFO - tape.training -   [Ep: 3.98][Iter: 1420][Time: 10.66s][Loss: 0.31236][LR: 0.00030151]\n",
            "20/12/06 16:05:58 - INFO - tape.training -   Train: [Loss: 0.32122]\n",
            "20/12/06 16:06:02 - INFO - tape.training -   Evaluation: [Loss: 0.43602]\n",
            "20/12/06 16:06:02 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 16:06:02 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-06-15-53-03_313935\n",
            "20/12/06 16:06:09 - INFO - tape.training -   [Ep: 4.03][Iter: 1440][Time:  6.81s][Loss: 0.28084][LR: 0.00029871]\n",
            "20/12/06 16:06:20 - INFO - tape.training -   [Ep: 4.09][Iter: 1460][Time: 10.51s][Loss: 0.30413][LR: 0.00029591]\n",
            "20/12/06 16:06:30 - INFO - tape.training -   [Ep: 4.15][Iter: 1480][Time: 10.39s][Loss: 0.32464][LR: 0.00029311]\n",
            "20/12/06 16:06:40 - INFO - tape.training -   [Ep: 4.20][Iter: 1500][Time: 10.00s][Loss: 0.32799][LR: 0.00029031]\n",
            "20/12/06 16:06:50 - INFO - tape.training -   [Ep: 4.26][Iter: 1520][Time: 10.53s][Loss: 0.33053][LR: 0.00028751]\n",
            "20/12/06 16:07:01 - INFO - tape.training -   [Ep: 4.31][Iter: 1540][Time: 10.72s][Loss: 0.32167][LR: 0.00028471]\n",
            "20/12/06 16:07:12 - INFO - tape.training -   [Ep: 4.37][Iter: 1560][Time: 10.87s][Loss: 0.3209][LR: 0.00028191]\n",
            "20/12/06 16:07:22 - INFO - tape.training -   [Ep: 4.43][Iter: 1580][Time: 10.32s][Loss: 0.32478][LR: 0.00027912]\n",
            "20/12/06 16:07:33 - INFO - tape.training -   [Ep: 4.48][Iter: 1600][Time: 10.58s][Loss: 0.32482][LR: 0.00027632]\n",
            "20/12/06 16:07:43 - INFO - tape.training -   [Ep: 4.54][Iter: 1620][Time:  9.94s][Loss: 0.3206][LR: 0.00027352]\n",
            "20/12/06 16:07:53 - INFO - tape.training -   [Ep: 4.59][Iter: 1640][Time: 10.52s][Loss: 0.31556][LR: 0.00027072]\n",
            "20/12/06 16:08:04 - INFO - tape.training -   [Ep: 4.65][Iter: 1660][Time: 10.74s][Loss: 0.3224][LR: 0.00026792]\n",
            "20/12/06 16:08:15 - INFO - tape.training -   [Ep: 4.70][Iter: 1680][Time: 10.60s][Loss: 0.32983][LR: 0.00026512]\n",
            "20/12/06 16:08:25 - INFO - tape.training -   [Ep: 4.76][Iter: 1700][Time: 10.59s][Loss: 0.32003][LR: 0.00026232]\n",
            "20/12/06 16:08:36 - INFO - tape.training -   [Ep: 4.82][Iter: 1720][Time: 10.27s][Loss: 0.3201][LR: 0.00025952]\n",
            "20/12/06 16:08:46 - INFO - tape.training -   [Ep: 4.87][Iter: 1740][Time: 10.15s][Loss: 0.32328][LR: 0.00025672]\n",
            "20/12/06 16:08:56 - INFO - tape.training -   [Ep: 4.93][Iter: 1760][Time: 10.10s][Loss: 0.30994][LR: 0.00025392]\n",
            "20/12/06 16:09:06 - INFO - tape.training -   [Ep: 4.98][Iter: 1780][Time: 10.15s][Loss: 0.3111][LR: 0.00025112]\n",
            "20/12/06 16:09:09 - INFO - tape.training -   Train: [Loss: 0.32096]\n",
            "20/12/06 16:09:14 - INFO - tape.training -   Evaluation: [Loss: 0.44396]\n",
            "20/12/06 16:09:14 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 16:09:14 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-06-15-53-03_313935\n",
            "20/12/06 16:09:22 - INFO - tape.training -   [Ep: 5.04][Iter: 1800][Time:  7.90s][Loss: 0.30867][LR: 0.00024832]\n",
            "20/12/06 16:09:32 - INFO - tape.training -   [Ep: 5.10][Iter: 1820][Time: 10.46s][Loss: 0.31065][LR: 0.00024552]\n",
            "20/12/06 16:09:42 - INFO - tape.training -   [Ep: 5.15][Iter: 1840][Time: 10.23s][Loss: 0.32881][LR: 0.00024272]\n",
            "20/12/06 16:09:53 - INFO - tape.training -   [Ep: 5.21][Iter: 1860][Time: 10.74s][Loss: 0.33136][LR: 0.00023992]\n",
            "20/12/06 16:10:03 - INFO - tape.training -   [Ep: 5.27][Iter: 1880][Time: 10.32s][Loss: 0.32905][LR: 0.00023712]\n",
            "20/12/06 16:10:14 - INFO - tape.training -   [Ep: 5.32][Iter: 1900][Time: 10.28s][Loss: 0.32073][LR: 0.00023432]\n",
            "20/12/06 16:10:24 - INFO - tape.training -   [Ep: 5.38][Iter: 1920][Time: 10.25s][Loss: 0.32055][LR: 0.00023152]\n",
            "20/12/06 16:10:34 - INFO - tape.training -   [Ep: 5.43][Iter: 1940][Time: 10.48s][Loss: 0.3225][LR: 0.00022872]\n",
            "20/12/06 16:10:45 - INFO - tape.training -   [Ep: 5.49][Iter: 1960][Time: 10.11s][Loss: 0.3253][LR: 0.00022592]\n",
            "20/12/06 16:10:55 - INFO - tape.training -   [Ep: 5.55][Iter: 1980][Time: 10.46s][Loss: 0.32111][LR: 0.00022312]\n",
            "20/12/06 16:11:06 - INFO - tape.training -   [Ep: 5.60][Iter: 2000][Time: 10.63s][Loss: 0.31909][LR: 0.00022032]\n",
            "20/12/06 16:11:16 - INFO - tape.training -   [Ep: 5.66][Iter: 2020][Time: 10.37s][Loss: 0.32617][LR: 0.00021753]\n",
            "20/12/06 16:11:26 - INFO - tape.training -   [Ep: 5.71][Iter: 2040][Time: 10.45s][Loss: 0.32892][LR: 0.00021473]\n",
            "20/12/06 16:11:37 - INFO - tape.training -   [Ep: 5.77][Iter: 2060][Time: 10.83s][Loss: 0.31687][LR: 0.00021193]\n",
            "20/12/06 16:11:48 - INFO - tape.training -   [Ep: 5.83][Iter: 2080][Time: 10.28s][Loss: 0.31694][LR: 0.00020913]\n",
            "20/12/06 16:11:58 - INFO - tape.training -   [Ep: 5.88][Iter: 2100][Time: 10.25s][Loss: 0.3269][LR: 0.00020633]\n",
            "20/12/06 16:12:09 - INFO - tape.training -   [Ep: 5.94][Iter: 2120][Time: 11.35s][Loss: 0.31249][LR: 0.00020353]\n",
            "20/12/06 16:12:20 - INFO - tape.training -   [Ep: 5.99][Iter: 2140][Time: 10.65s][Loss: 0.31322][LR: 0.00020073]\n",
            "20/12/06 16:12:21 - INFO - tape.training -   Train: [Loss: 0.32094]\n",
            "20/12/06 16:12:26 - INFO - tape.training -   Evaluation: [Loss: 0.44487]\n",
            "20/12/06 16:12:26 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 16:12:26 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-06-15-53-03_313935\n",
            "20/12/06 16:12:36 - INFO - tape.training -   [Ep: 6.05][Iter: 2160][Time:  9.97s][Loss: 0.29767][LR: 0.00019793]\n",
            "20/12/06 16:12:46 - INFO - tape.training -   [Ep: 6.11][Iter: 2180][Time: 10.25s][Loss: 0.30654][LR: 0.00019513]\n",
            "20/12/06 16:12:57 - INFO - tape.training -   [Ep: 6.16][Iter: 2200][Time: 10.46s][Loss: 0.32567][LR: 0.00019233]\n",
            "20/12/06 16:13:07 - INFO - tape.training -   [Ep: 6.22][Iter: 2220][Time: 10.14s][Loss: 0.32831][LR: 0.00018953]\n",
            "20/12/06 16:13:17 - INFO - tape.training -   [Ep: 6.27][Iter: 2240][Time: 10.50s][Loss: 0.32825][LR: 0.00018673]\n",
            "20/12/06 16:13:28 - INFO - tape.training -   [Ep: 6.33][Iter: 2260][Time: 10.41s][Loss: 0.31956][LR: 0.00018393]\n",
            "20/12/06 16:13:39 - INFO - tape.training -   [Ep: 6.39][Iter: 2280][Time: 10.94s][Loss: 0.32077][LR: 0.00018113]\n",
            "20/12/06 16:13:49 - INFO - tape.training -   [Ep: 6.44][Iter: 2300][Time: 10.53s][Loss: 0.32183][LR: 0.00017833]\n",
            "20/12/06 16:14:00 - INFO - tape.training -   [Ep: 6.50][Iter: 2320][Time: 10.59s][Loss: 0.3291][LR: 0.00017553]\n",
            "20/12/06 16:14:10 - INFO - tape.training -   [Ep: 6.55][Iter: 2340][Time: 10.60s][Loss: 0.31954][LR: 0.00017273]\n",
            "20/12/06 16:14:21 - INFO - tape.training -   [Ep: 6.61][Iter: 2360][Time: 10.70s][Loss: 0.32114][LR: 0.00016993]\n",
            "20/12/06 16:14:32 - INFO - tape.training -   [Ep: 6.67][Iter: 2380][Time: 10.71s][Loss: 0.32614][LR: 0.00016713]\n",
            "20/12/06 16:14:42 - INFO - tape.training -   [Ep: 6.72][Iter: 2400][Time: 10.32s][Loss: 0.33387][LR: 0.00016433]\n",
            "20/12/06 16:14:52 - INFO - tape.training -   [Ep: 6.78][Iter: 2420][Time: 10.10s][Loss: 0.31485][LR: 0.00016153]\n",
            "20/12/06 16:15:03 - INFO - tape.training -   [Ep: 6.83][Iter: 2440][Time: 10.48s][Loss: 0.32106][LR: 0.00015873]\n",
            "20/12/06 16:15:13 - INFO - tape.training -   [Ep: 6.89][Iter: 2460][Time: 10.48s][Loss: 0.32648][LR: 0.00015594]\n",
            "20/12/06 16:15:24 - INFO - tape.training -   [Ep: 6.95][Iter: 2480][Time: 10.55s][Loss: 0.31121][LR: 0.00015314]\n",
            "20/12/06 16:15:34 - INFO - tape.training -   Train: [Loss: 0.32086]\n",
            "20/12/06 16:15:39 - INFO - tape.training -   Evaluation: [Loss: 0.43869]\n",
            "20/12/06 16:15:39 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 16:15:39 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-06-15-53-03_313935\n",
            "20/12/06 16:15:40 - INFO - tape.training -   [Ep: 7.00][Iter: 2500][Time:  0.91s][Loss: 0.30637][LR: 0.00015034]\n",
            "20/12/06 16:15:51 - INFO - tape.training -   [Ep: 7.06][Iter: 2520][Time: 10.84s][Loss: 0.31297][LR: 0.00014754]\n",
            "20/12/06 16:16:01 - INFO - tape.training -   [Ep: 7.11][Iter: 2540][Time: 10.61s][Loss: 0.31101][LR: 0.00014474]\n",
            "20/12/06 16:16:12 - INFO - tape.training -   [Ep: 7.17][Iter: 2560][Time: 10.47s][Loss: 0.32375][LR: 0.00014194]\n",
            "20/12/06 16:16:22 - INFO - tape.training -   [Ep: 7.23][Iter: 2580][Time: 10.72s][Loss: 0.32738][LR: 0.00013914]\n",
            "20/12/06 16:16:33 - INFO - tape.training -   [Ep: 7.28][Iter: 2600][Time: 10.49s][Loss: 0.3276][LR: 0.00013634]\n",
            "20/12/06 16:16:43 - INFO - tape.training -   [Ep: 7.34][Iter: 2620][Time: 10.58s][Loss: 0.32228][LR: 0.00013354]\n",
            "20/12/06 16:16:54 - INFO - tape.training -   [Ep: 7.39][Iter: 2640][Time: 10.49s][Loss: 0.32311][LR: 0.00013074]\n",
            "20/12/06 16:17:04 - INFO - tape.training -   [Ep: 7.45][Iter: 2660][Time: 10.45s][Loss: 0.31892][LR: 0.00012794]\n",
            "20/12/06 16:17:15 - INFO - tape.training -   [Ep: 7.51][Iter: 2680][Time: 10.50s][Loss: 0.32594][LR: 0.00012514]\n",
            "20/12/06 16:17:26 - INFO - tape.training -   [Ep: 7.56][Iter: 2700][Time: 10.95s][Loss: 0.31403][LR: 0.00012234]\n",
            "20/12/06 16:17:36 - INFO - tape.training -   [Ep: 7.62][Iter: 2720][Time: 10.15s][Loss: 0.32326][LR: 0.00011954]\n",
            "20/12/06 16:17:46 - INFO - tape.training -   [Ep: 7.67][Iter: 2740][Time: 10.28s][Loss: 0.33372][LR: 0.00011674]\n",
            "20/12/06 16:17:57 - INFO - tape.training -   [Ep: 7.73][Iter: 2760][Time: 10.48s][Loss: 0.32369][LR: 0.00011394]\n",
            "20/12/06 16:18:07 - INFO - tape.training -   [Ep: 7.79][Iter: 2780][Time: 10.03s][Loss: 0.31344][LR: 0.00011114]\n",
            "20/12/06 16:18:17 - INFO - tape.training -   [Ep: 7.84][Iter: 2800][Time: 10.35s][Loss: 0.3249][LR: 0.00010834]\n",
            "20/12/06 16:18:28 - INFO - tape.training -   [Ep: 7.90][Iter: 2820][Time: 10.49s][Loss: 0.32187][LR: 0.00010554]\n",
            "20/12/06 16:18:38 - INFO - tape.training -   [Ep: 7.95][Iter: 2840][Time: 10.56s][Loss: 0.30683][LR: 0.00010274]\n",
            "20/12/06 16:18:47 - INFO - tape.training -   Train: [Loss: 0.32071]\n",
            "20/12/06 16:18:52 - INFO - tape.training -   Evaluation: [Loss: 0.44052]\n",
            "20/12/06 16:18:52 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 16:18:52 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-06-15-53-03_313935\n",
            "20/12/06 16:18:54 - INFO - tape.training -   [Ep: 8.01][Iter: 2860][Time:  2.29s][Loss: 0.34369][LR: 9.9944e-05]\n",
            "20/12/06 16:19:04 - INFO - tape.training -   [Ep: 8.07][Iter: 2880][Time:  9.95s][Loss: 0.32501][LR: 9.7144e-05]\n",
            "20/12/06 16:19:14 - INFO - tape.training -   [Ep: 8.12][Iter: 2900][Time: 10.18s][Loss: 0.31786][LR: 9.4345e-05]\n",
            "20/12/06 16:19:25 - INFO - tape.training -   [Ep: 8.18][Iter: 2920][Time: 10.72s][Loss: 0.32852][LR: 9.1545e-05]\n",
            "20/12/06 16:19:35 - INFO - tape.training -   [Ep: 8.23][Iter: 2940][Time: 10.13s][Loss: 0.32923][LR: 8.8746e-05]\n",
            "20/12/06 16:19:45 - INFO - tape.training -   [Ep: 8.29][Iter: 2960][Time: 10.26s][Loss: 0.32596][LR: 8.5946e-05]\n",
            "20/12/06 16:19:56 - INFO - tape.training -   [Ep: 8.35][Iter: 2980][Time: 10.41s][Loss: 0.31894][LR: 8.3147e-05]\n",
            "20/12/06 16:20:06 - INFO - tape.training -   [Ep: 8.40][Iter: 3000][Time:  9.99s][Loss: 0.32452][LR: 8.0347e-05]\n",
            "20/12/06 16:20:16 - INFO - tape.training -   [Ep: 8.46][Iter: 3020][Time: 10.48s][Loss: 0.32108][LR: 7.7548e-05]\n",
            "20/12/06 16:20:26 - INFO - tape.training -   [Ep: 8.51][Iter: 3040][Time: 10.30s][Loss: 0.32479][LR: 7.4748e-05]\n",
            "20/12/06 16:20:37 - INFO - tape.training -   [Ep: 8.57][Iter: 3060][Time: 10.53s][Loss: 0.31146][LR: 7.1948e-05]\n",
            "20/12/06 16:20:47 - INFO - tape.training -   [Ep: 8.63][Iter: 3080][Time:  9.87s][Loss: 0.32224][LR: 6.9149e-05]\n",
            "20/12/06 16:20:57 - INFO - tape.training -   [Ep: 8.68][Iter: 3100][Time: 10.55s][Loss: 0.33279][LR: 6.6349e-05]\n",
            "20/12/06 16:21:07 - INFO - tape.training -   [Ep: 8.74][Iter: 3120][Time: 10.14s][Loss: 0.32638][LR: 6.355e-05]\n",
            "20/12/06 16:21:18 - INFO - tape.training -   [Ep: 8.79][Iter: 3140][Time: 10.19s][Loss: 0.31267][LR: 6.075e-05]\n",
            "20/12/06 16:21:28 - INFO - tape.training -   [Ep: 8.85][Iter: 3160][Time: 10.27s][Loss: 0.32697][LR: 5.7951e-05]\n",
            "20/12/06 16:21:38 - INFO - tape.training -   [Ep: 8.91][Iter: 3180][Time: 10.27s][Loss: 0.32066][LR: 5.5151e-05]\n",
            "20/12/06 16:21:48 - INFO - tape.training -   [Ep: 8.96][Iter: 3200][Time: 10.24s][Loss: 0.312][LR: 5.2352e-05]\n",
            "20/12/06 16:21:55 - INFO - tape.training -   Train: [Loss: 0.32067]\n",
            "20/12/06 16:22:00 - INFO - tape.training -   Evaluation: [Loss: 0.43992]\n",
            "20/12/06 16:22:00 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 16:22:00 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-06-15-53-03_313935\n",
            "20/12/06 16:22:04 - INFO - tape.training -   [Ep: 9.02][Iter: 3220][Time:  3.99s][Loss: 0.26459][LR: 4.9552e-05]\n",
            "20/12/06 16:22:15 - INFO - tape.training -   [Ep: 9.08][Iter: 3240][Time: 10.49s][Loss: 0.29874][LR: 4.6753e-05]\n",
            "20/12/06 16:22:25 - INFO - tape.training -   [Ep: 9.13][Iter: 3260][Time: 10.51s][Loss: 0.31137][LR: 4.3953e-05]\n",
            "20/12/06 16:22:35 - INFO - tape.training -   [Ep: 9.19][Iter: 3280][Time: 10.29s][Loss: 0.32099][LR: 4.1153e-05]\n",
            "20/12/06 16:22:45 - INFO - tape.training -   [Ep: 9.24][Iter: 3300][Time:  9.91s][Loss: 0.32542][LR: 3.8354e-05]\n",
            "20/12/06 16:22:55 - INFO - tape.training -   [Ep: 9.30][Iter: 3320][Time: 10.19s][Loss: 0.32655][LR: 3.5554e-05]\n",
            "20/12/06 16:23:06 - INFO - tape.training -   [Ep: 9.36][Iter: 3340][Time: 10.34s][Loss: 0.32338][LR: 3.2755e-05]\n",
            "20/12/06 16:23:16 - INFO - tape.training -   [Ep: 9.41][Iter: 3360][Time: 10.46s][Loss: 0.32301][LR: 2.9955e-05]\n",
            "20/12/06 16:23:26 - INFO - tape.training -   [Ep: 9.47][Iter: 3380][Time:  9.94s][Loss: 0.32516][LR: 2.7156e-05]\n",
            "20/12/06 16:23:37 - INFO - tape.training -   [Ep: 9.52][Iter: 3400][Time: 10.33s][Loss: 0.31619][LR: 2.4356e-05]\n",
            "20/12/06 16:23:46 - INFO - tape.training -   [Ep: 9.58][Iter: 3420][Time:  9.94s][Loss: 0.31509][LR: 2.1557e-05]\n",
            "20/12/06 16:23:57 - INFO - tape.training -   [Ep: 9.64][Iter: 3440][Time: 10.08s][Loss: 0.32142][LR: 1.8757e-05]\n",
            "20/12/06 16:24:07 - INFO - tape.training -   [Ep: 9.69][Iter: 3460][Time: 10.21s][Loss: 0.32828][LR: 1.5957e-05]\n",
            "20/12/06 16:24:17 - INFO - tape.training -   [Ep: 9.75][Iter: 3480][Time: 10.59s][Loss: 0.32693][LR: 1.3158e-05]\n",
            "20/12/06 16:24:27 - INFO - tape.training -   [Ep: 9.80][Iter: 3500][Time:  9.88s][Loss: 0.31375][LR: 1.0358e-05]\n",
            "20/12/06 16:24:37 - INFO - tape.training -   [Ep: 9.86][Iter: 3520][Time:  9.85s][Loss: 0.32131][LR: 7.5588e-06]\n",
            "20/12/06 16:24:47 - INFO - tape.training -   [Ep: 9.91][Iter: 3540][Time:  9.76s][Loss: 0.31514][LR: 4.7592e-06]\n",
            "20/12/06 16:24:57 - INFO - tape.training -   [Ep: 9.97][Iter: 3560][Time: 10.03s][Loss: 0.30958][LR: 1.9597e-06]\n",
            "20/12/06 16:25:02 - INFO - tape.training -   Train: [Loss: 0.32074]\n",
            "20/12/06 16:25:07 - INFO - tape.training -   Evaluation: [Loss: 0.43985]\n",
            "20/12/06 16:25:07 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/06 16:25:07 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-06-15-53-03_313935\n",
            "20/12/06 16:25:07 - INFO - tape.training -   Finished training after 10 epochs.\n",
            "20/12/06 16:25:07 - Level 35 - tape.training -   Best Val Loss: 0.43267524242401123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL4bl_DFfFNl",
        "outputId": "01d0217e-7b82-432a-cb8e-fa7b4214f03b"
      },
      "source": [
        "!tape-eval resnet stability /content/results/stability_resnet_20-12-06-15-53-03_313935 --metrics mse mae spearmanr  "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/12/06 16:25:20 - INFO - tape.training -   device: cuda n_gpu: 1\n",
            "20/12/06 16:25:20 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/stability_resnet_20-12-06-15-53-03_313935/config.json\n",
            "20/12/06 16:25:20 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": -1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/12/06 16:25:20 - INFO - tape.models.modeling_utils -   loading weights file /content/results/stability_resnet_20-12-06-15-53-03_313935/pytorch_model.bin\n",
            "Evaluation: 100% 13/13 [00:01<00:00,  7.49it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[:, None]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[None, :]\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
            "  return (a < x) & (x < b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
            "  return (a < x) & (x < b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
            "  cond2 = cond0 & (x <= _a)\n",
            "20/12/06 16:25:26 - INFO - tape.training -   mse: 0.8426566123962402mae: 0.8272304534912109spearmanr: nan\n",
            "{'mse': 0.8426566, 'mae': 0.82723045, 'spearmanr': nan}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}