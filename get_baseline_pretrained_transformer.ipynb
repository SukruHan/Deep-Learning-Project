{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "get_baseline_pretrained_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuAdol1Acd6A",
        "outputId": "9d7eb21c-fc55-4e91-dd5c-9eb14f6386c2"
      },
      "source": [
        "# install tape \n",
        "!pip install tape_proteins"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tape_proteins\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/f7/bdfe0ef6fd6ffb45f55c944176f518b0bc6ea0c9dddba0816578fb0e7290/tape_proteins-0.4-py3-none-any.whl (68kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 20kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 30kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 61kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tape_proteins) (4.41.1)\n",
            "Collecting torch<1.5,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 15kB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 37.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: lmdb in /usr/local/lib/python3.6/dist-packages (from tape_proteins) (0.99)\n",
            "Collecting biopython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/02/8b606c4aa92ff61b5eda71d23b499ab1de57d5e818be33f77b01a6f435a8/biopython-1.78-cp36-cp36m-manylinux1_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from tape_proteins) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tape_proteins) (1.4.1)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/31/4d4861a90d66c287a348fd17eaefefcdc2e859951cab9884b555923f046d/boto3-1.16.23-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 38.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX->tape_proteins) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->tape_proteins) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->tape_proteins) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->tape_proteins) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->tape_proteins) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->tape_proteins) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->tape_proteins) (2.10)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.20.0,>=1.19.23\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/49/c8c99477416fdebb59078bda624acc5b3c7008f891c60d56d6ff1570d83e/botocore-1.19.23-py2.py3-none-any.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 32.0MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX->tape_proteins) (50.3.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.23->boto3->tape_proteins) (2.8.1)\n",
            "\u001b[31mERROR: torchvision 0.8.1+cu101 has requirement torch==1.7.0, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: botocore 1.19.23 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, tensorboardX, biopython, jmespath, botocore, s3transfer, boto3, tape-proteins\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "Successfully installed biopython-1.78 boto3-1.16.23 botocore-1.19.23 jmespath-0.10.0 s3transfer-0.3.3 tape-proteins-0.4 tensorboardX-2.1 torch-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qgGoCG8clGj",
        "outputId": "7782b716-d4bf-4680-eec9-c3a1372b1c54"
      },
      "source": [
        "!mkdir ./data\n",
        "!wget http://s3.amazonaws.com/proteindata/data_pytorch/fluorescence.tar.gz\n",
        "!tar -xzf fluorescence.tar.gz -C ./data\n",
        "!rm fluorescence.tar.gz\n",
        "!wget http://s3.amazonaws.com/proteindata/data_pytorch/proteinnet.tar.gz\n",
        "!tar -xzf proteinnet.tar.gz -C ./data\n",
        "!rm proteinnet.tar.gz\n",
        "!wget http://s3.amazonaws.com/proteindata/data_pytorch/remote_homology.tar.gz\n",
        "!tar -xzf remote_homology.tar.gz -C ./data\n",
        "!rm remote_homology.tar.gz\n",
        "!wget http://s3.amazonaws.com/proteindata/data_pytorch/secondary_structure.tar.gz\n",
        "!tar -xzf secondary_structure.tar.gz -C ./data\n",
        "!rm secondary_structure.tar.gz\n",
        "!wget http://s3.amazonaws.com/proteindata/data_pytorch/stability.tar.gz\n",
        "!tar -xzf stability.tar.gz -C ./data\n",
        "!rm stability.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-23 14:32:50--  http://s3.amazonaws.com/proteindata/data_pytorch/fluorescence.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.232.13\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.232.13|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1635678 (1.6M) [application/x-tar]\n",
            "Saving to: ‘fluorescence.tar.gz’\n",
            "\n",
            "fluorescence.tar.gz 100%[===================>]   1.56M  1.43MB/s    in 1.1s    \n",
            "\n",
            "2020-11-23 14:32:51 (1.43 MB/s) - ‘fluorescence.tar.gz’ saved [1635678/1635678]\n",
            "\n",
            "--2020-11-23 14:32:52--  http://s3.amazonaws.com/proteindata/data_pytorch/proteinnet.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.138.205\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.138.205|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 464501179 (443M) [application/x-tar]\n",
            "Saving to: ‘proteinnet.tar.gz’\n",
            "\n",
            "proteinnet.tar.gz   100%[===================>] 442.98M  16.7MB/s    in 28s     \n",
            "\n",
            "2020-11-23 14:33:20 (15.8 MB/s) - ‘proteinnet.tar.gz’ saved [464501179/464501179]\n",
            "\n",
            "--2020-11-23 14:33:28--  http://s3.amazonaws.com/proteindata/data_pytorch/remote_homology.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.84.141\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.84.141|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43581262 (42M) [application/x-tar]\n",
            "Saving to: ‘remote_homology.tar.gz’\n",
            "\n",
            "remote_homology.tar 100%[===================>]  41.56M  11.5MB/s    in 3.6s    \n",
            "\n",
            "2020-11-23 14:33:32 (11.5 MB/s) - ‘remote_homology.tar.gz’ saved [43581262/43581262]\n",
            "\n",
            "--2020-11-23 14:33:35--  http://s3.amazonaws.com/proteindata/data_pytorch/secondary_structure.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.141.150\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.141.150|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 251794897 (240M) [application/x-tar]\n",
            "Saving to: ‘secondary_structure.tar.gz’\n",
            "\n",
            "secondary_structure 100%[===================>] 240.13M  16.7MB/s    in 16s     \n",
            "\n",
            "2020-11-23 14:33:51 (15.3 MB/s) - ‘secondary_structure.tar.gz’ saved [251794897/251794897]\n",
            "\n",
            "--2020-11-23 14:33:58--  http://s3.amazonaws.com/proteindata/data_pytorch/stability.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.78.78\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.78.78|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3116829 (3.0M) [application/x-tar]\n",
            "Saving to: ‘stability.tar.gz’\n",
            "\n",
            "stability.tar.gz    100%[===================>]   2.97M  2.31MB/s    in 1.3s    \n",
            "\n",
            "2020-11-23 14:33:59 (2.31 MB/s) - ‘stability.tar.gz’ saved [3116829/3116829]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR3SWU_uclI7"
      },
      "source": [
        "# !tape-train transformer contact_prediction --model_config_file config.json --from_pretrained /content/results/pretrained_transformer --batch_size 150 --learning_rate 5e-4 --num_train_epochs 10 --warmup_steps 2 --gradient_accumulation_steps 50 --seed 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLJBAn-qfDjW"
      },
      "source": [
        "# !tape-eval transformer contact_prediction /content/results/secondary_structure_transformer_20-11-16-15-36-39_069321 --metrics mse mae spearmanr accuracy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwqwkYKBclLT",
        "outputId": "31ae1305-c713-449b-a83e-e65b580e239c"
      },
      "source": [
        "!tape-train transformer fluorescence --model_config_file /content/results/baseline_fluorescence/config.json --from_pretrained /content/results/pretrained_transformer --batch_size 150 --learning_rate 5e-4 --num_train_epochs 10 --warmup_steps 2 --gradient_accumulation_steps 50 --seed 1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/11/23 14:34:56 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/pretrained_transformer/config.json\n",
            "20/11/23 14:34:56 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 8096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": -1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/11/23 14:34:56 - INFO - tape.models.modeling_utils -   loading weights file /content/results/pretrained_transformer/pytorch_model.bin\n",
            "20/11/23 14:34:56 - INFO - tape.models.modeling_utils -   Weights of ProteinBertForValuePrediction not initialized from pretrained model: ['predict.value_prediction.main.0.bias', 'predict.value_prediction.main.0.weight_g', 'predict.value_prediction.main.0.weight_v', 'predict.value_prediction.main.3.bias', 'predict.value_prediction.main.3.weight_g', 'predict.value_prediction.main.3.weight_v']\n",
            "20/11/23 14:34:56 - INFO - tape.models.modeling_utils -   Weights from pretrained model not used in ProteinBertForValuePrediction: ['mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n",
            "20/11/23 14:34:58 - INFO - tape.visualization -   tensorboard file at: logs/fluorescence_transformer_20-11-23-14-34-56_238060\n",
            "20/11/23 14:34:58 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/11/23 14:34:58 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/11/23 14:34:58 - WARNING - tape.visualization -   Cannot watch models when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/11/23 14:34:58 - INFO - tape.training -   device: cuda n_gpu: 1, distributed_training: False, 16-bits training: False\n",
            "20/11/23 14:34:58 - INFO - tape.training -   ***** Running training *****\n",
            "20/11/23 14:34:58 - INFO - tape.training -     Num examples = 21446\n",
            "20/11/23 14:34:58 - INFO - tape.training -     Batch size = 150\n",
            "20/11/23 14:34:58 - INFO - tape.training -     Num epochs = 10\n",
            "20/11/23 14:34:58 - INFO - tape.training -     Num train steps = 1429\n",
            "20/11/23 14:34:58 - INFO - tape.training -     Num parameters = 304259\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "20/11/23 14:35:23 - INFO - tape.training -   [Ep: 0.14][Iter: 20][Time: 24.35s][Loss: 8.7493][LR: 0.00049369]\n",
            "20/11/23 14:35:47 - INFO - tape.training -   [Ep: 0.28][Iter: 40][Time: 23.70s][Loss: 4.013][LR: 0.00048669]\n",
            "20/11/23 14:36:10 - INFO - tape.training -   [Ep: 0.42][Iter: 60][Time: 23.95s][Loss: 1.9267][LR: 0.00047968]\n",
            "20/11/23 14:36:35 - INFO - tape.training -   [Ep: 0.56][Iter: 80][Time: 24.72s][Loss: 1.1339][LR: 0.00047267]\n",
            "20/11/23 14:36:59 - INFO - tape.training -   [Ep: 0.70][Iter: 100][Time: 23.68s][Loss: 0.87946][LR: 0.00046566]\n",
            "20/11/23 14:37:23 - INFO - tape.training -   [Ep: 0.84][Iter: 120][Time: 23.86s][Loss: 0.78736][LR: 0.00045865]\n",
            "20/11/23 14:37:47 - INFO - tape.training -   [Ep: 0.98][Iter: 140][Time: 24.10s][Loss: 0.75002][LR: 0.00045165]\n",
            "20/11/23 14:37:50 - INFO - tape.training -   Train: [Loss: 1.9012]\n",
            "20/11/23 14:38:09 - INFO - tape.training -   Evaluation: [Loss: 0.72799]\n",
            "20/11/23 14:38:09 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 14:38:09 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_transformer_20-11-23-14-34-56_238060\n",
            "20/11/23 14:38:30 - INFO - tape.training -   [Ep: 1.13][Iter: 160][Time: 21.19s][Loss: 0.67317][LR: 0.00044464]\n",
            "20/11/23 14:38:55 - INFO - tape.training -   [Ep: 1.27][Iter: 180][Time: 24.43s][Loss: 0.70535][LR: 0.00043763]\n",
            "20/11/23 14:39:18 - INFO - tape.training -   [Ep: 1.41][Iter: 200][Time: 23.58s][Loss: 0.71643][LR: 0.00043062]\n",
            "20/11/23 14:39:43 - INFO - tape.training -   [Ep: 1.55][Iter: 220][Time: 24.95s][Loss: 0.70907][LR: 0.00042362]\n",
            "20/11/23 14:40:07 - INFO - tape.training -   [Ep: 1.69][Iter: 240][Time: 24.23s][Loss: 0.73253][LR: 0.00041661]\n",
            "20/11/23 14:40:31 - INFO - tape.training -   [Ep: 1.83][Iter: 260][Time: 23.20s][Loss: 0.76357][LR: 0.0004096]\n",
            "20/11/23 14:40:55 - INFO - tape.training -   [Ep: 1.97][Iter: 280][Time: 24.05s][Loss: 0.70246][LR: 0.00040259]\n",
            "20/11/23 14:41:01 - INFO - tape.training -   Train: [Loss: 0.71661]\n",
            "20/11/23 14:41:20 - INFO - tape.training -   Evaluation: [Loss: 0.89461]\n",
            "20/11/23 14:41:20 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 14:41:20 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_transformer_20-11-23-14-34-56_238060\n",
            "20/11/23 14:41:39 - INFO - tape.training -   [Ep: 2.11][Iter: 300][Time: 19.55s][Loss: 0.7698][LR: 0.00039559]\n",
            "20/11/23 14:42:03 - INFO - tape.training -   [Ep: 2.25][Iter: 320][Time: 24.07s][Loss: 0.74896][LR: 0.00038858]\n",
            "20/11/23 14:42:28 - INFO - tape.training -   [Ep: 2.39][Iter: 340][Time: 24.32s][Loss: 0.72701][LR: 0.00038157]\n",
            "20/11/23 14:42:52 - INFO - tape.training -   [Ep: 2.53][Iter: 360][Time: 23.95s][Loss: 0.70825][LR: 0.00037456]\n",
            "20/11/23 14:43:15 - INFO - tape.training -   [Ep: 2.67][Iter: 380][Time: 23.63s][Loss: 0.70906][LR: 0.00036755]\n",
            "20/11/23 14:43:39 - INFO - tape.training -   [Ep: 2.81][Iter: 400][Time: 23.94s][Loss: 0.6882][LR: 0.00036055]\n",
            "20/11/23 14:44:03 - INFO - tape.training -   [Ep: 2.95][Iter: 420][Time: 23.93s][Loss: 0.71957][LR: 0.00035354]\n",
            "20/11/23 14:44:12 - INFO - tape.training -   Train: [Loss: 0.71695]\n",
            "20/11/23 14:44:30 - INFO - tape.training -   Evaluation: [Loss: 0.70492]\n",
            "20/11/23 14:44:30 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 14:44:30 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_transformer_20-11-23-14-34-56_238060\n",
            "20/11/23 14:44:47 - INFO - tape.training -   [Ep: 3.10][Iter: 440][Time: 16.53s][Loss: 0.63832][LR: 0.00034653]\n",
            "20/11/23 14:45:12 - INFO - tape.training -   [Ep: 3.24][Iter: 460][Time: 25.19s][Loss: 0.68933][LR: 0.00033952]\n",
            "20/11/23 14:45:37 - INFO - tape.training -   [Ep: 3.38][Iter: 480][Time: 24.75s][Loss: 0.7026][LR: 0.00033252]\n",
            "20/11/23 14:46:01 - INFO - tape.training -   [Ep: 3.52][Iter: 500][Time: 24.49s][Loss: 0.69874][LR: 0.00032551]\n",
            "20/11/23 14:46:26 - INFO - tape.training -   [Ep: 3.66][Iter: 520][Time: 24.83s][Loss: 0.70388][LR: 0.0003185]\n",
            "20/11/23 14:46:50 - INFO - tape.training -   [Ep: 3.80][Iter: 540][Time: 23.99s][Loss: 0.70332][LR: 0.00031149]\n",
            "20/11/23 14:47:14 - INFO - tape.training -   [Ep: 3.94][Iter: 560][Time: 23.81s][Loss: 0.69646][LR: 0.00030448]\n",
            "20/11/23 14:47:25 - INFO - tape.training -   Train: [Loss: 0.70916]\n",
            "20/11/23 14:47:45 - INFO - tape.training -   Evaluation: [Loss: 0.74514]\n",
            "20/11/23 14:47:45 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 14:47:45 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_transformer_20-11-23-14-34-56_238060\n",
            "20/11/23 14:48:00 - INFO - tape.training -   [Ep: 4.08][Iter: 580][Time: 15.01s][Loss: 0.70641][LR: 0.00029748]\n",
            "20/11/23 14:48:25 - INFO - tape.training -   [Ep: 4.22][Iter: 600][Time: 24.65s][Loss: 0.71562][LR: 0.00029047]\n",
            "20/11/23 14:48:48 - INFO - tape.training -   [Ep: 4.36][Iter: 620][Time: 23.69s][Loss: 0.72778][LR: 0.00028346]\n",
            "20/11/23 14:49:12 - INFO - tape.training -   [Ep: 4.50][Iter: 640][Time: 23.48s][Loss: 0.74389][LR: 0.00027645]\n",
            "20/11/23 14:49:36 - INFO - tape.training -   [Ep: 4.64][Iter: 660][Time: 24.37s][Loss: 0.72764][LR: 0.00026945]\n",
            "20/11/23 14:50:01 - INFO - tape.training -   [Ep: 4.78][Iter: 680][Time: 24.89s][Loss: 0.72139][LR: 0.00026244]\n",
            "20/11/23 14:50:25 - INFO - tape.training -   [Ep: 4.92][Iter: 700][Time: 23.63s][Loss: 0.70876][LR: 0.00025543]\n",
            "20/11/23 14:50:38 - INFO - tape.training -   Train: [Loss: 0.71021]\n",
            "20/11/23 14:50:57 - INFO - tape.training -   Evaluation: [Loss: 0.70773]\n",
            "20/11/23 14:50:57 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 14:50:57 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_transformer_20-11-23-14-34-56_238060\n",
            "20/11/23 14:51:09 - INFO - tape.training -   [Ep: 5.07][Iter: 720][Time: 12.00s][Loss: 0.69264][LR: 0.00024842]\n",
            "20/11/23 14:51:34 - INFO - tape.training -   [Ep: 5.21][Iter: 740][Time: 24.38s][Loss: 0.70347][LR: 0.00024142]\n",
            "20/11/23 14:51:58 - INFO - tape.training -   [Ep: 5.35][Iter: 760][Time: 24.38s][Loss: 0.66961][LR: 0.00023441]\n",
            "20/11/23 14:52:23 - INFO - tape.training -   [Ep: 5.49][Iter: 780][Time: 24.47s][Loss: 0.68253][LR: 0.0002274]\n",
            "20/11/23 14:52:47 - INFO - tape.training -   [Ep: 5.63][Iter: 800][Time: 24.22s][Loss: 0.69157][LR: 0.00022039]\n",
            "20/11/23 14:53:11 - INFO - tape.training -   [Ep: 5.77][Iter: 820][Time: 24.38s][Loss: 0.72071][LR: 0.00021338]\n",
            "20/11/23 14:53:35 - INFO - tape.training -   [Ep: 5.91][Iter: 840][Time: 23.72s][Loss: 0.69663][LR: 0.00020638]\n",
            "20/11/23 14:53:50 - INFO - tape.training -   Train: [Loss: 0.69737]\n",
            "20/11/23 14:54:10 - INFO - tape.training -   Evaluation: [Loss: 0.70663]\n",
            "20/11/23 14:54:10 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 14:54:10 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_transformer_20-11-23-14-34-56_238060\n",
            "20/11/23 14:54:20 - INFO - tape.training -   [Ep: 6.06][Iter: 860][Time: 10.25s][Loss: 0.57158][LR: 0.00019937]\n",
            "20/11/23 14:54:44 - INFO - tape.training -   [Ep: 6.20][Iter: 880][Time: 24.20s][Loss: 0.65767][LR: 0.00019236]\n",
            "20/11/23 14:55:08 - INFO - tape.training -   [Ep: 6.34][Iter: 900][Time: 23.98s][Loss: 0.69696][LR: 0.00018535]\n",
            "20/11/23 14:55:33 - INFO - tape.training -   [Ep: 6.48][Iter: 920][Time: 24.86s][Loss: 0.72653][LR: 0.00017835]\n",
            "20/11/23 14:55:58 - INFO - tape.training -   [Ep: 6.62][Iter: 940][Time: 25.10s][Loss: 0.70003][LR: 0.00017134]\n",
            "20/11/23 14:56:22 - INFO - tape.training -   [Ep: 6.76][Iter: 960][Time: 24.49s][Loss: 0.68912][LR: 0.00016433]\n",
            "20/11/23 14:56:46 - INFO - tape.training -   [Ep: 6.90][Iter: 980][Time: 23.94s][Loss: 0.6784][LR: 0.00015732]\n",
            "20/11/23 14:57:05 - INFO - tape.training -   Train: [Loss: 0.69341]\n",
            "20/11/23 14:57:25 - INFO - tape.training -   Evaluation: [Loss: 0.69612]\n",
            "20/11/23 14:57:25 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 14:57:25 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_transformer_20-11-23-14-34-56_238060\n",
            "20/11/23 14:57:33 - INFO - tape.training -   [Ep: 7.04][Iter: 1000][Time:  8.02s][Loss: 0.67037][LR: 0.00015032]\n",
            "20/11/23 14:57:58 - INFO - tape.training -   [Ep: 7.18][Iter: 1020][Time: 24.46s][Loss: 0.68076][LR: 0.00014331]\n",
            "20/11/23 14:58:22 - INFO - tape.training -   [Ep: 7.32][Iter: 1040][Time: 24.15s][Loss: 0.66998][LR: 0.0001363]\n",
            "20/11/23 14:58:45 - INFO - tape.training -   [Ep: 7.46][Iter: 1060][Time: 23.57s][Loss: 0.68163][LR: 0.00012929]\n",
            "20/11/23 14:59:09 - INFO - tape.training -   [Ep: 7.60][Iter: 1080][Time: 23.98s][Loss: 0.68682][LR: 0.00012228]\n",
            "20/11/23 14:59:34 - INFO - tape.training -   [Ep: 7.74][Iter: 1100][Time: 24.64s][Loss: 0.68769][LR: 0.00011528]\n",
            "20/11/23 14:59:59 - INFO - tape.training -   [Ep: 7.88][Iter: 1120][Time: 24.66s][Loss: 0.69791][LR: 0.00010827]\n",
            "20/11/23 15:00:19 - INFO - tape.training -   Train: [Loss: 0.68988]\n",
            "20/11/23 15:00:38 - INFO - tape.training -   Evaluation: [Loss: 0.69336]\n",
            "20/11/23 15:00:38 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:00:38 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_transformer_20-11-23-14-34-56_238060\n",
            "20/11/23 15:00:43 - INFO - tape.training -   [Ep: 8.03][Iter: 1140][Time:  5.06s][Loss: 0.74443][LR: 0.00010126]\n",
            "20/11/23 15:01:08 - INFO - tape.training -   [Ep: 8.17][Iter: 1160][Time: 24.93s][Loss: 0.69473][LR: 9.4254e-05]\n",
            "20/11/23 15:01:32 - INFO - tape.training -   [Ep: 8.31][Iter: 1180][Time: 24.33s][Loss: 0.68798][LR: 8.7246e-05]\n",
            "20/11/23 15:01:56 - INFO - tape.training -   [Ep: 8.45][Iter: 1200][Time: 24.13s][Loss: 0.67867][LR: 8.0238e-05]\n",
            "20/11/23 15:02:20 - INFO - tape.training -   [Ep: 8.59][Iter: 1220][Time: 23.96s][Loss: 0.68777][LR: 7.3231e-05]\n",
            "20/11/23 15:02:44 - INFO - tape.training -   [Ep: 8.73][Iter: 1240][Time: 23.69s][Loss: 0.67878][LR: 6.6223e-05]\n",
            "20/11/23 15:03:07 - INFO - tape.training -   [Ep: 8.87][Iter: 1260][Time: 23.67s][Loss: 0.70362][LR: 5.9215e-05]\n",
            "20/11/23 15:03:30 - INFO - tape.training -   Train: [Loss: 0.68603]\n",
            "20/11/23 15:03:50 - INFO - tape.training -   Evaluation: [Loss: 0.70317]\n",
            "20/11/23 15:03:50 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:03:50 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_transformer_20-11-23-14-34-56_238060\n",
            "20/11/23 15:03:53 - INFO - tape.training -   [Ep: 9.01][Iter: 1280][Time:  2.53s][Loss: 0.66375][LR: 5.2207e-05]\n",
            "20/11/23 15:04:17 - INFO - tape.training -   [Ep: 9.15][Iter: 1300][Time: 24.02s][Loss: 0.6729][LR: 4.52e-05]\n",
            "20/11/23 15:04:41 - INFO - tape.training -   [Ep: 9.29][Iter: 1320][Time: 23.99s][Loss: 0.68237][LR: 3.8192e-05]\n",
            "20/11/23 15:05:05 - INFO - tape.training -   [Ep: 9.43][Iter: 1340][Time: 23.92s][Loss: 0.69786][LR: 3.1184e-05]\n",
            "20/11/23 15:05:29 - INFO - tape.training -   [Ep: 9.57][Iter: 1360][Time: 24.12s][Loss: 0.69414][LR: 2.4177e-05]\n",
            "20/11/23 15:05:53 - INFO - tape.training -   [Ep: 9.71][Iter: 1380][Time: 24.21s][Loss: 0.69364][LR: 1.7169e-05]\n",
            "20/11/23 15:06:18 - INFO - tape.training -   [Ep: 9.85][Iter: 1400][Time: 24.36s][Loss: 0.67037][LR: 1.0161e-05]\n",
            "20/11/23 15:06:41 - INFO - tape.training -   [Ep: 9.99][Iter: 1420][Time: 23.48s][Loss: 0.67219][LR: 3.1535e-06]\n",
            "20/11/23 15:06:42 - INFO - tape.training -   Train: [Loss: 0.68377]\n",
            "20/11/23 15:07:02 - INFO - tape.training -   Evaluation: [Loss: 0.70223]\n",
            "20/11/23 15:07:02 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:07:02 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_transformer_20-11-23-14-34-56_238060\n",
            "20/11/23 15:07:02 - INFO - tape.training -   Finished training after 10 epochs.\n",
            "20/11/23 15:07:02 - Level 35 - tape.training -   Best Val Loss: 0.693358626661216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRHQSKIyfD5T",
        "outputId": "dd6be652-dfb5-44eb-d13d-e38201ccf971"
      },
      "source": [
        "!tape-eval transformer fluorescence /content/results/fluorescence_transformer_20-11-23-14-34-56_238060 --metrics mse mae spearmanr  "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/11/23 15:07:18 - INFO - tape.training -   device: cuda n_gpu: 1\n",
            "20/11/23 15:07:18 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/fluorescence_transformer_20-11-23-14-34-56_238060/config.json\n",
            "20/11/23 15:07:18 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 8096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": -1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/11/23 15:07:18 - INFO - tape.models.modeling_utils -   loading weights file /content/results/fluorescence_transformer_20-11-23-14-34-56_238060/pytorch_model.bin\n",
            "Evaluation: 100% 27/27 [00:19<00:00,  1.41it/s]\n",
            "20/11/23 15:07:39 - INFO - tape.training -   mse: 2.337190866470337mae: 1.3190163373947144spearmanr: 0.21426544218359725\n",
            "{'mse': 2.3371909, 'mae': 1.3190163, 'spearmanr': 0.21426544218359725}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-faygRsAclNo",
        "outputId": "a11880d9-8c8d-43a1-fc6e-e89f7557707c"
      },
      "source": [
        "!tape-train transformer remote_homology --model_config_file /content/results/baseline_remote_homology/config.json --from_pretrained /content/results/pretrained_transformer --batch_size 150 --learning_rate 5e-4 --num_train_epochs 10 --warmup_steps 2 --gradient_accumulation_steps 50 --seed 1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/11/23 15:07:45 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/pretrained_transformer/config.json\n",
            "20/11/23 15:07:45 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 8096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": 1195,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/11/23 15:07:45 - INFO - tape.models.modeling_utils -   loading weights file /content/results/pretrained_transformer/pytorch_model.bin\n",
            "20/11/23 15:07:45 - INFO - tape.models.modeling_utils -   Weights of ProteinBertForSequenceClassification not initialized from pretrained model: ['classify.classify.main.0.bias', 'classify.classify.main.0.weight_g', 'classify.classify.main.0.weight_v', 'classify.classify.main.3.bias', 'classify.classify.main.3.weight_g', 'classify.classify.main.3.weight_v']\n",
            "20/11/23 15:07:45 - INFO - tape.models.modeling_utils -   Weights from pretrained model not used in ProteinBertForSequenceClassification: ['mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n",
            "20/11/23 15:07:47 - INFO - tape.visualization -   tensorboard file at: logs/remote_homology_transformer_20-11-23-15-07-45_531887\n",
            "20/11/23 15:07:47 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/11/23 15:07:47 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/11/23 15:07:47 - WARNING - tape.visualization -   Cannot watch models when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/11/23 15:07:47 - INFO - tape.training -   device: cuda n_gpu: 1, distributed_training: False, 16-bits training: False\n",
            "20/11/23 15:07:47 - INFO - tape.training -   ***** Running training *****\n",
            "20/11/23 15:07:47 - INFO - tape.training -     Num examples = 12312\n",
            "20/11/23 15:07:47 - INFO - tape.training -     Batch size = 150\n",
            "20/11/23 15:07:47 - INFO - tape.training -     Num epochs = 10\n",
            "20/11/23 15:07:47 - INFO - tape.training -     Num train steps = 820\n",
            "20/11/23 15:07:47 - INFO - tape.training -     Num parameters = 916781\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "20/11/23 15:08:11 - INFO - tape.training -   [Ep: 0.24][Iter: 20][Time: 24.22s][Loss: 6.971][Accuracy: 0.036376][LR: 0.000489]\n",
            "20/11/23 15:08:35 - INFO - tape.training -   [Ep: 0.49][Iter: 40][Time: 23.70s][Loss: 6.3791][Accuracy: 0.064355][LR: 0.00047677]\n",
            "20/11/23 15:08:59 - INFO - tape.training -   [Ep: 0.73][Iter: 60][Time: 24.28s][Loss: 5.9904][Accuracy: 0.074246][LR: 0.00046455]\n",
            "20/11/23 15:09:23 - INFO - tape.training -   [Ep: 0.97][Iter: 80][Time: 23.75s][Loss: 5.84][Accuracy: 0.076913][LR: 0.00045232]\n",
            "20/11/23 15:09:26 - INFO - tape.training -   Train: [Loss: 6.1448][Accuracy: 0.072602]\n",
            "20/11/23 15:09:29 - INFO - tape.training -   Evaluation: [Loss: 6.1451][Accuracy: 0.020325]\n",
            "20/11/23 15:09:29 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:09:29 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_transformer_20-11-23-15-07-45_531887\n",
            "20/11/23 15:09:51 - INFO - tape.training -   [Ep: 1.22][Iter: 100][Time: 21.85s][Loss: 5.6285][Accuracy: 0.065874][LR: 0.0004401]\n",
            "20/11/23 15:10:15 - INFO - tape.training -   [Ep: 1.46][Iter: 120][Time: 24.39s][Loss: 5.686][Accuracy: 0.076656][LR: 0.00042787]\n",
            "20/11/23 15:10:39 - INFO - tape.training -   [Ep: 1.71][Iter: 140][Time: 24.20s][Loss: 5.6576][Accuracy: 0.081711][LR: 0.00041565]\n",
            "20/11/23 15:11:04 - INFO - tape.training -   [Ep: 1.95][Iter: 160][Time: 24.52s][Loss: 5.6387][Accuracy: 0.08607][LR: 0.00040342]\n",
            "20/11/23 15:11:09 - INFO - tape.training -   Train: [Loss: 5.6888][Accuracy: 0.080894]\n",
            "20/11/23 15:11:12 - INFO - tape.training -   Evaluation: [Loss: 6.1343][Accuracy: 0.023035]\n",
            "20/11/23 15:11:12 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:11:12 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_transformer_20-11-23-15-07-45_531887\n",
            "20/11/23 15:11:31 - INFO - tape.training -   [Ep: 2.19][Iter: 180][Time: 18.98s][Loss: 5.4592][Accuracy: 0.084018][LR: 0.0003912]\n",
            "20/11/23 15:11:55 - INFO - tape.training -   [Ep: 2.44][Iter: 200][Time: 24.13s][Loss: 5.482][Accuracy: 0.093018][LR: 0.00037897]\n",
            "20/11/23 15:12:19 - INFO - tape.training -   [Ep: 2.68][Iter: 220][Time: 24.10s][Loss: 5.4151][Accuracy: 0.1002][LR: 0.00036675]\n",
            "20/11/23 15:12:43 - INFO - tape.training -   [Ep: 2.93][Iter: 240][Time: 24.31s][Loss: 5.3911][Accuracy: 0.10351][LR: 0.00035452]\n",
            "20/11/23 15:12:51 - INFO - tape.training -   Train: [Loss: 5.438][Accuracy: 0.10106]\n",
            "20/11/23 15:12:54 - INFO - tape.training -   Evaluation: [Loss: 5.8534][Accuracy: 0.03523]\n",
            "20/11/23 15:12:54 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:12:54 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_transformer_20-11-23-15-07-45_531887\n",
            "20/11/23 15:13:12 - INFO - tape.training -   [Ep: 3.17][Iter: 260][Time: 17.46s][Loss: 5.1179][Accuracy: 0.11722][LR: 0.0003423]\n",
            "20/11/23 15:13:36 - INFO - tape.training -   [Ep: 3.41][Iter: 280][Time: 24.38s][Loss: 5.1663][Accuracy: 0.11237][LR: 0.00033007]\n",
            "20/11/23 15:14:01 - INFO - tape.training -   [Ep: 3.66][Iter: 300][Time: 24.80s][Loss: 5.2051][Accuracy: 0.11344][LR: 0.00031785]\n",
            "20/11/23 15:14:25 - INFO - tape.training -   [Ep: 3.90][Iter: 320][Time: 24.63s][Loss: 5.2076][Accuracy: 0.12171][LR: 0.00030562]\n",
            "20/11/23 15:14:35 - INFO - tape.training -   Train: [Loss: 5.1992][Accuracy: 0.11878]\n",
            "20/11/23 15:14:38 - INFO - tape.training -   Evaluation: [Loss: 5.7582][Accuracy: 0.060976]\n",
            "20/11/23 15:14:38 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:14:38 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_transformer_20-11-23-15-07-45_531887\n",
            "20/11/23 15:14:53 - INFO - tape.training -   [Ep: 4.15][Iter: 340][Time: 14.95s][Loss: 5.044][Accuracy: 0.12399][LR: 0.0002934]\n",
            "20/11/23 15:15:17 - INFO - tape.training -   [Ep: 4.39][Iter: 360][Time: 24.49s][Loss: 5.0508][Accuracy: 0.13138][LR: 0.00028117]\n",
            "20/11/23 15:15:41 - INFO - tape.training -   [Ep: 4.63][Iter: 380][Time: 24.11s][Loss: 5.0089][Accuracy: 0.14101][LR: 0.00026895]\n",
            "20/11/23 15:16:05 - INFO - tape.training -   [Ep: 4.88][Iter: 400][Time: 23.98s][Loss: 4.9891][Accuracy: 0.14309][LR: 0.00025672]\n",
            "20/11/23 15:16:17 - INFO - tape.training -   Train: [Loss: 5.0113][Accuracy: 0.14016]\n",
            "20/11/23 15:16:21 - INFO - tape.training -   Evaluation: [Loss: 5.6444][Accuracy: 0.060976]\n",
            "20/11/23 15:16:21 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:16:21 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_transformer_20-11-23-15-07-45_531887\n",
            "20/11/23 15:16:33 - INFO - tape.training -   [Ep: 5.12][Iter: 420][Time: 12.26s][Loss: 4.6441][Accuracy: 0.16049][LR: 0.0002445]\n",
            "20/11/23 15:16:57 - INFO - tape.training -   [Ep: 5.37][Iter: 440][Time: 23.72s][Loss: 4.8181][Accuracy: 0.14744][LR: 0.00023227]\n",
            "20/11/23 15:17:20 - INFO - tape.training -   [Ep: 5.61][Iter: 460][Time: 23.37s][Loss: 4.8428][Accuracy: 0.14633][LR: 0.00022005]\n",
            "20/11/23 15:17:43 - INFO - tape.training -   [Ep: 5.85][Iter: 480][Time: 23.48s][Loss: 4.8145][Accuracy: 0.16056][LR: 0.00020782]\n",
            "20/11/23 15:17:59 - INFO - tape.training -   Train: [Loss: 4.8437][Accuracy: 0.15268]\n",
            "20/11/23 15:18:02 - INFO - tape.training -   Evaluation: [Loss: 5.4878][Accuracy: 0.060976]\n",
            "20/11/23 15:18:02 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:18:02 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_transformer_20-11-23-15-07-45_531887\n",
            "20/11/23 15:18:12 - INFO - tape.training -   [Ep: 6.10][Iter: 500][Time:  9.41s][Loss: 4.722][Accuracy: 0.13866][LR: 0.0001956]\n",
            "20/11/23 15:18:35 - INFO - tape.training -   [Ep: 6.34][Iter: 520][Time: 23.67s][Loss: 4.6725][Accuracy: 0.15761][LR: 0.00018337]\n",
            "20/11/23 15:18:59 - INFO - tape.training -   [Ep: 6.58][Iter: 540][Time: 23.79s][Loss: 4.6629][Accuracy: 0.16103][LR: 0.00017115]\n",
            "20/11/23 15:19:24 - INFO - tape.training -   [Ep: 6.83][Iter: 560][Time: 24.69s][Loss: 4.668][Accuracy: 0.16945][LR: 0.00015892]\n",
            "20/11/23 15:19:41 - INFO - tape.training -   Train: [Loss: 4.6815][Accuracy: 0.16415]\n",
            "20/11/23 15:19:43 - INFO - tape.training -   Evaluation: [Loss: 5.3838][Accuracy: 0.056911]\n",
            "20/11/23 15:19:43 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:19:44 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_transformer_20-11-23-15-07-45_531887\n",
            "20/11/23 15:19:51 - INFO - tape.training -   [Ep: 7.07][Iter: 580][Time:  7.16s][Loss: 4.6072][Accuracy: 0.17727][LR: 0.0001467]\n",
            "20/11/23 15:20:15 - INFO - tape.training -   [Ep: 7.32][Iter: 600][Time: 24.56s][Loss: 4.5662][Accuracy: 0.17305][LR: 0.00013447]\n",
            "20/11/23 15:20:38 - INFO - tape.training -   [Ep: 7.56][Iter: 620][Time: 23.18s][Loss: 4.5615][Accuracy: 0.16834][LR: 0.00012225]\n",
            "20/11/23 15:21:02 - INFO - tape.training -   [Ep: 7.80][Iter: 640][Time: 23.96s][Loss: 4.5628][Accuracy: 0.17013][LR: 0.00011002]\n",
            "20/11/23 15:21:22 - INFO - tape.training -   Train: [Loss: 4.5688][Accuracy: 0.16797]\n",
            "20/11/23 15:21:25 - INFO - tape.training -   Evaluation: [Loss: 5.3324][Accuracy: 0.058266]\n",
            "20/11/23 15:21:25 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:21:25 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_transformer_20-11-23-15-07-45_531887\n",
            "20/11/23 15:21:30 - INFO - tape.training -   [Ep: 8.05][Iter: 660][Time:  5.01s][Loss: 4.3402][Accuracy: 0.19724][LR: 9.78e-05]\n",
            "20/11/23 15:21:55 - INFO - tape.training -   [Ep: 8.29][Iter: 680][Time: 24.86s][Loss: 4.4006][Accuracy: 0.18284][LR: 8.5575e-05]\n",
            "20/11/23 15:22:20 - INFO - tape.training -   [Ep: 8.54][Iter: 700][Time: 25.19s][Loss: 4.4953][Accuracy: 0.17231][LR: 7.335e-05]\n",
            "20/11/23 15:22:44 - INFO - tape.training -   [Ep: 8.78][Iter: 720][Time: 23.88s][Loss: 4.4879][Accuracy: 0.16983][LR: 6.1125e-05]\n",
            "20/11/23 15:23:06 - INFO - tape.training -   Train: [Loss: 4.4979][Accuracy: 0.17008]\n",
            "20/11/23 15:23:10 - INFO - tape.training -   Evaluation: [Loss: 5.3105][Accuracy: 0.058266]\n",
            "20/11/23 15:23:10 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:23:10 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_transformer_20-11-23-15-07-45_531887\n",
            "20/11/23 15:23:12 - INFO - tape.training -   [Ep: 9.02][Iter: 740][Time:  2.65s][Loss: 4.5022][Accuracy: 0.159][LR: 4.89e-05]\n",
            "20/11/23 15:23:36 - INFO - tape.training -   [Ep: 9.27][Iter: 760][Time: 24.28s][Loss: 4.4647][Accuracy: 0.16895][LR: 3.6675e-05]\n",
            "20/11/23 15:24:01 - INFO - tape.training -   [Ep: 9.51][Iter: 780][Time: 24.10s][Loss: 4.4583][Accuracy: 0.17311][LR: 2.445e-05]\n",
            "20/11/23 15:24:24 - INFO - tape.training -   [Ep: 9.76][Iter: 800][Time: 23.59s][Loss: 4.4844][Accuracy: 0.16879][LR: 1.2225e-05]\n",
            "20/11/23 15:24:48 - INFO - tape.training -   [Ep: 10.00][Iter: 820][Time: 23.87s][Loss: 4.4429][Accuracy: 0.1786][LR: 0]\n",
            "20/11/23 15:24:48 - INFO - tape.training -   Train: [Loss: 4.4583][Accuracy: 0.17463]\n",
            "20/11/23 15:24:51 - INFO - tape.training -   Evaluation: [Loss: 5.3058][Accuracy: 0.056911]\n",
            "20/11/23 15:24:51 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:24:51 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_transformer_20-11-23-15-07-45_531887\n",
            "20/11/23 15:24:51 - INFO - tape.training -   Finished training after 10 epochs.\n",
            "20/11/23 15:24:51 - Level 35 - tape.training -   Best Val Loss: 5.305807188274414\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbgTxvUifEUF"
      },
      "source": [
        "# !tape-eval transformer remote_homology /content/results/secondary_structure_transformer_20-11-16-15-36-39_069321 --metrics mse mae spearmanr "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9xC0m3CclQT",
        "outputId": "505fc451-7c68-4c4d-b3f4-79d7f0c0f4c3"
      },
      "source": [
        "!tape-train transformer secondary_structure --model_config_file /content/results/baseline_secondary_structure/config.json --from_pretrained /content/results/pretrained_transformer --batch_size 150 --learning_rate 5e-4 --num_train_epochs 10 --warmup_steps 2 --gradient_accumulation_steps 50 --seed 1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/11/23 15:25:12 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/pretrained_transformer/config.json\n",
            "20/11/23 15:25:12 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 8096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": 3,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/11/23 15:25:12 - INFO - tape.models.modeling_utils -   loading weights file /content/results/pretrained_transformer/pytorch_model.bin\n",
            "20/11/23 15:25:12 - INFO - tape.models.modeling_utils -   Weights of ProteinBertForSequenceToSequenceClassification not initialized from pretrained model: ['classify.classify.main.0.weight', 'classify.classify.main.0.bias', 'classify.classify.main.0.running_mean', 'classify.classify.main.0.running_var', 'classify.classify.main.1.bias', 'classify.classify.main.1.weight_g', 'classify.classify.main.1.weight_v', 'classify.classify.main.4.bias', 'classify.classify.main.4.weight_g', 'classify.classify.main.4.weight_v']\n",
            "20/11/23 15:25:12 - INFO - tape.models.modeling_utils -   Weights from pretrained model not used in ProteinBertForSequenceToSequenceClassification: ['mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n",
            "20/11/23 15:25:14 - INFO - tape.visualization -   tensorboard file at: logs/secondary_structure_transformer_20-11-23-15-25-12_986640\n",
            "20/11/23 15:25:14 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/11/23 15:25:14 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/11/23 15:25:14 - WARNING - tape.visualization -   Cannot watch models when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/11/23 15:25:14 - INFO - tape.training -   device: cuda n_gpu: 1, distributed_training: False, 16-bits training: False\n",
            "20/11/23 15:25:14 - INFO - tape.training -   ***** Running training *****\n",
            "20/11/23 15:25:14 - INFO - tape.training -     Num examples = 8678\n",
            "20/11/23 15:25:14 - INFO - tape.training -     Batch size = 150\n",
            "20/11/23 15:25:14 - INFO - tape.training -     Num epochs = 10\n",
            "20/11/23 15:25:14 - INFO - tape.training -     Num train steps = 578\n",
            "20/11/23 15:25:14 - INFO - tape.training -     Num parameters = 373957\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "20/11/23 15:25:43 - INFO - tape.training -   [Ep: 0.35][Iter: 20][Time: 28.84s][Loss: 1.0262][Accuracy: 0.4566][LR: 0.00048437]\n",
            "20/11/23 15:26:11 - INFO - tape.training -   [Ep: 0.69][Iter: 40][Time: 27.89s][Loss: 0.94603][Accuracy: 0.53933][LR: 0.00046701]\n",
            "20/11/23 15:26:36 - INFO - tape.training -   Train: [Loss: 0.93272][Accuracy: 0.55727]\n",
            "20/11/23 15:26:46 - INFO - tape.training -   Evaluation: [Loss: 0.83056][Accuracy: 0.62488]\n",
            "20/11/23 15:26:46 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:26:46 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_transformer_20-11-23-15-25-12_986640\n",
            "20/11/23 15:26:50 - INFO - tape.training -   [Ep: 1.05][Iter: 60][Time:  4.55s][Loss: 0.86625][Accuracy: 0.6001][LR: 0.00044965]\n",
            "20/11/23 15:27:19 - INFO - tape.training -   [Ep: 1.40][Iter: 80][Time: 28.33s][Loss: 0.87073][Accuracy: 0.60136][LR: 0.00043229]\n",
            "20/11/23 15:27:48 - INFO - tape.training -   [Ep: 1.74][Iter: 100][Time: 29.00s][Loss: 0.87033][Accuracy: 0.60408][LR: 0.00041493]\n",
            "20/11/23 15:28:09 - INFO - tape.training -   Train: [Loss: 0.86673][Accuracy: 0.60577]\n",
            "20/11/23 15:28:19 - INFO - tape.training -   Evaluation: [Loss: 0.82012][Accuracy: 0.63165]\n",
            "20/11/23 15:28:19 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:28:19 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_transformer_20-11-23-15-25-12_986640\n",
            "20/11/23 15:28:28 - INFO - tape.training -   [Ep: 2.10][Iter: 120][Time:  8.60s][Loss: 0.86068][Accuracy: 0.60201][LR: 0.00039757]\n",
            "20/11/23 15:28:56 - INFO - tape.training -   [Ep: 2.45][Iter: 140][Time: 28.36s][Loss: 0.84811][Accuracy: 0.61265][LR: 0.00038021]\n",
            "20/11/23 15:29:25 - INFO - tape.training -   [Ep: 2.79][Iter: 160][Time: 29.03s][Loss: 0.8417][Accuracy: 0.61762][LR: 0.00036285]\n",
            "20/11/23 15:29:43 - INFO - tape.training -   Train: [Loss: 0.84006][Accuracy: 0.61892]\n",
            "20/11/23 15:29:52 - INFO - tape.training -   Evaluation: [Loss: 0.78524][Accuracy: 0.65306]\n",
            "20/11/23 15:29:52 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:29:52 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_transformer_20-11-23-15-25-12_986640\n",
            "20/11/23 15:30:05 - INFO - tape.training -   [Ep: 3.16][Iter: 180][Time: 12.88s][Loss: 0.82318][Accuracy: 0.63255][LR: 0.00034549]\n",
            "20/11/23 15:30:34 - INFO - tape.training -   [Ep: 3.50][Iter: 200][Time: 28.63s][Loss: 0.81601][Accuracy: 0.63518][LR: 0.00032813]\n",
            "20/11/23 15:31:02 - INFO - tape.training -   [Ep: 3.85][Iter: 220][Time: 28.30s][Loss: 0.8127][Accuracy: 0.63671][LR: 0.00031076]\n",
            "20/11/23 15:31:15 - INFO - tape.training -   Train: [Loss: 0.81444][Accuracy: 0.63556]\n",
            "20/11/23 15:31:25 - INFO - tape.training -   Evaluation: [Loss: 0.77736][Accuracy: 0.65681]\n",
            "20/11/23 15:31:25 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:31:25 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_transformer_20-11-23-15-25-12_986640\n",
            "20/11/23 15:31:42 - INFO - tape.training -   [Ep: 4.21][Iter: 240][Time: 17.24s][Loss: 0.80599][Accuracy: 0.64152][LR: 0.0002934]\n",
            "20/11/23 15:32:10 - INFO - tape.training -   [Ep: 4.55][Iter: 260][Time: 28.08s][Loss: 0.80426][Accuracy: 0.64109][LR: 0.00027604]\n",
            "20/11/23 15:32:38 - INFO - tape.training -   [Ep: 4.90][Iter: 280][Time: 28.14s][Loss: 0.80492][Accuracy: 0.64145][LR: 0.00025868]\n",
            "20/11/23 15:32:47 - INFO - tape.training -   Train: [Loss: 0.80407][Accuracy: 0.64169]\n",
            "20/11/23 15:32:56 - INFO - tape.training -   Evaluation: [Loss: 0.77108][Accuracy: 0.66008]\n",
            "20/11/23 15:32:56 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:32:56 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_transformer_20-11-23-15-25-12_986640\n",
            "20/11/23 15:33:18 - INFO - tape.training -   [Ep: 5.26][Iter: 300][Time: 21.85s][Loss: 0.80518][Accuracy: 0.64179][LR: 0.00024132]\n",
            "20/11/23 15:33:48 - INFO - tape.training -   [Ep: 5.60][Iter: 320][Time: 29.62s][Loss: 0.79893][Accuracy: 0.64492][LR: 0.00022396]\n",
            "20/11/23 15:34:16 - INFO - tape.training -   [Ep: 5.95][Iter: 340][Time: 28.54s][Loss: 0.79613][Accuracy: 0.6465][LR: 0.0002066]\n",
            "20/11/23 15:34:21 - INFO - tape.training -   Train: [Loss: 0.79658][Accuracy: 0.6464]\n",
            "20/11/23 15:34:30 - INFO - tape.training -   Evaluation: [Loss: 0.77202][Accuracy: 0.65878]\n",
            "20/11/23 15:34:30 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:34:30 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_transformer_20-11-23-15-25-12_986640\n",
            "20/11/23 15:34:57 - INFO - tape.training -   [Ep: 6.31][Iter: 360][Time: 26.92s][Loss: 0.78698][Accuracy: 0.65054][LR: 0.00018924]\n",
            "20/11/23 15:35:26 - INFO - tape.training -   [Ep: 6.66][Iter: 380][Time: 29.16s][Loss: 0.78822][Accuracy: 0.64987][LR: 0.00017187]\n",
            "20/11/23 15:35:54 - INFO - tape.training -   Train: [Loss: 0.79016][Accuracy: 0.64964]\n",
            "20/11/23 15:36:04 - INFO - tape.training -   Evaluation: [Loss: 0.76143][Accuracy: 0.66477]\n",
            "20/11/23 15:36:04 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:36:04 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_transformer_20-11-23-15-25-12_986640\n",
            "20/11/23 15:36:05 - INFO - tape.training -   [Ep: 7.02][Iter: 400][Time:  1.63s][Loss: 0.77688][Accuracy: 0.65916][LR: 0.00015451]\n",
            "20/11/23 15:36:34 - INFO - tape.training -   [Ep: 7.36][Iter: 420][Time: 28.24s][Loss: 0.78399][Accuracy: 0.65372][LR: 0.00013715]\n",
            "20/11/23 15:37:02 - INFO - tape.training -   [Ep: 7.71][Iter: 440][Time: 28.84s][Loss: 0.78723][Accuracy: 0.65191][LR: 0.00011979]\n",
            "20/11/23 15:37:27 - INFO - tape.training -   Train: [Loss: 0.7855][Accuracy: 0.65241]\n",
            "20/11/23 15:37:36 - INFO - tape.training -   Evaluation: [Loss: 0.76013][Accuracy: 0.66561]\n",
            "20/11/23 15:37:36 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:37:36 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_transformer_20-11-23-15-25-12_986640\n",
            "20/11/23 15:37:43 - INFO - tape.training -   [Ep: 8.07][Iter: 460][Time:  6.32s][Loss: 0.7721][Accuracy: 0.66066][LR: 0.00010243]\n",
            "20/11/23 15:38:12 - INFO - tape.training -   [Ep: 8.41][Iter: 480][Time: 28.87s][Loss: 0.77814][Accuracy: 0.65697][LR: 8.5069e-05]\n",
            "20/11/23 15:38:40 - INFO - tape.training -   [Ep: 8.76][Iter: 500][Time: 28.17s][Loss: 0.77866][Accuracy: 0.65663][LR: 6.7708e-05]\n",
            "20/11/23 15:39:00 - INFO - tape.training -   Train: [Loss: 0.77964][Accuracy: 0.65583]\n",
            "20/11/23 15:39:10 - INFO - tape.training -   Evaluation: [Loss: 0.7544][Accuracy: 0.66857]\n",
            "20/11/23 15:39:10 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:39:10 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_transformer_20-11-23-15-25-12_986640\n",
            "20/11/23 15:39:21 - INFO - tape.training -   [Ep: 9.12][Iter: 520][Time: 10.48s][Loss: 0.77504][Accuracy: 0.65744][LR: 5.0347e-05]\n",
            "20/11/23 15:39:49 - INFO - tape.training -   [Ep: 9.47][Iter: 540][Time: 28.46s][Loss: 0.77496][Accuracy: 0.65836][LR: 3.2986e-05]\n",
            "20/11/23 15:40:19 - INFO - tape.training -   [Ep: 9.81][Iter: 560][Time: 29.44s][Loss: 0.77436][Accuracy: 0.65878][LR: 1.5625e-05]\n",
            "20/11/23 15:40:34 - INFO - tape.training -   Train: [Loss: 0.77523][Accuracy: 0.65869]\n",
            "20/11/23 15:40:43 - INFO - tape.training -   Evaluation: [Loss: 0.7528][Accuracy: 0.66924]\n",
            "20/11/23 15:40:43 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:40:43 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_transformer_20-11-23-15-25-12_986640\n",
            "20/11/23 15:40:43 - INFO - tape.training -   Finished training after 10 epochs.\n",
            "20/11/23 15:40:43 - Level 35 - tape.training -   Best Val Loss: 0.7527967739994355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmTVYN62fEwJ"
      },
      "source": [
        "# !tape-eval transformer secondary_structure /content/results/secondary_structure_transformer_20-11-16-15-36-39_069321 --metrics mse mae spearmanr accuracy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAsP4o9HclSs",
        "outputId": "c7fd4f59-88ef-4093-83bf-559415e175fc"
      },
      "source": [
        "!tape-train transformer stability --model_config_file /content/results/baseline_stability/config.json --from_pretrained /content/results/pretrained_transformer --batch_size 150 --learning_rate 5e-4 --num_train_epochs 10 --warmup_steps 2 --gradient_accumulation_steps 50 --seed 1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/11/23 15:40:49 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/pretrained_transformer/config.json\n",
            "20/11/23 15:40:49 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 8096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": -1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/11/23 15:40:49 - INFO - tape.models.modeling_utils -   loading weights file /content/results/pretrained_transformer/pytorch_model.bin\n",
            "20/11/23 15:40:49 - INFO - tape.models.modeling_utils -   Weights of ProteinBertForValuePrediction not initialized from pretrained model: ['predict.value_prediction.main.0.bias', 'predict.value_prediction.main.0.weight_g', 'predict.value_prediction.main.0.weight_v', 'predict.value_prediction.main.3.bias', 'predict.value_prediction.main.3.weight_g', 'predict.value_prediction.main.3.weight_v']\n",
            "20/11/23 15:40:49 - INFO - tape.models.modeling_utils -   Weights from pretrained model not used in ProteinBertForValuePrediction: ['mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n",
            "20/11/23 15:40:51 - INFO - tape.visualization -   tensorboard file at: logs/stability_transformer_20-11-23-15-40-49_603263\n",
            "20/11/23 15:40:51 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/11/23 15:40:51 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/11/23 15:40:51 - WARNING - tape.visualization -   Cannot watch models when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/11/23 15:40:51 - INFO - tape.training -   device: cuda n_gpu: 1, distributed_training: False, 16-bits training: False\n",
            "20/11/23 15:40:51 - INFO - tape.training -   ***** Running training *****\n",
            "20/11/23 15:40:51 - INFO - tape.training -     Num examples = 53614\n",
            "20/11/23 15:40:51 - INFO - tape.training -     Batch size = 150\n",
            "20/11/23 15:40:51 - INFO - tape.training -     Num epochs = 10\n",
            "20/11/23 15:40:51 - INFO - tape.training -     Num train steps = 3574\n",
            "20/11/23 15:40:51 - INFO - tape.training -     Num parameters = 304259\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "20/11/23 15:41:15 - INFO - tape.training -   [Ep: 0.06][Iter: 20][Time: 23.51s][Loss: 0.37054][LR: 0.00049748]\n",
            "20/11/23 15:41:38 - INFO - tape.training -   [Ep: 0.11][Iter: 40][Time: 22.58s][Loss: 0.35079][LR: 0.00049468]\n",
            "20/11/23 15:42:01 - INFO - tape.training -   [Ep: 0.17][Iter: 60][Time: 22.95s][Loss: 0.33364][LR: 0.00049188]\n",
            "20/11/23 15:42:23 - INFO - tape.training -   [Ep: 0.22][Iter: 80][Time: 22.54s][Loss: 0.32511][LR: 0.00048908]\n",
            "20/11/23 15:42:46 - INFO - tape.training -   [Ep: 0.28][Iter: 100][Time: 22.68s][Loss: 0.33533][LR: 0.00048628]\n",
            "20/11/23 15:43:09 - INFO - tape.training -   [Ep: 0.34][Iter: 120][Time: 23.15s][Loss: 0.31758][LR: 0.00048348]\n",
            "20/11/23 15:43:32 - INFO - tape.training -   [Ep: 0.39][Iter: 140][Time: 23.00s][Loss: 0.31306][LR: 0.00048068]\n",
            "20/11/23 15:43:56 - INFO - tape.training -   [Ep: 0.45][Iter: 160][Time: 24.33s][Loss: 0.31155][LR: 0.00047788]\n",
            "20/11/23 15:44:19 - INFO - tape.training -   [Ep: 0.50][Iter: 180][Time: 23.00s][Loss: 0.31343][LR: 0.00047508]\n",
            "20/11/23 15:44:42 - INFO - tape.training -   [Ep: 0.56][Iter: 200][Time: 23.14s][Loss: 0.3135][LR: 0.00047228]\n",
            "20/11/23 15:45:05 - INFO - tape.training -   [Ep: 0.62][Iter: 220][Time: 22.71s][Loss: 0.30882][LR: 0.00046948]\n",
            "20/11/23 15:45:29 - INFO - tape.training -   [Ep: 0.67][Iter: 240][Time: 23.54s][Loss: 0.30199][LR: 0.00046669]\n",
            "20/11/23 15:45:51 - INFO - tape.training -   [Ep: 0.73][Iter: 260][Time: 22.73s][Loss: 0.298][LR: 0.00046389]\n",
            "20/11/23 15:46:14 - INFO - tape.training -   [Ep: 0.78][Iter: 280][Time: 22.87s][Loss: 0.29177][LR: 0.00046109]\n",
            "20/11/23 15:46:37 - INFO - tape.training -   [Ep: 0.84][Iter: 300][Time: 22.92s][Loss: 0.29306][LR: 0.00045829]\n",
            "20/11/23 15:47:00 - INFO - tape.training -   [Ep: 0.90][Iter: 320][Time: 23.11s][Loss: 0.28895][LR: 0.00045549]\n",
            "20/11/23 15:47:24 - INFO - tape.training -   [Ep: 0.95][Iter: 340][Time: 23.27s][Loss: 0.29182][LR: 0.00045269]\n",
            "20/11/23 15:47:44 - INFO - tape.training -   Train: [Loss: 0.3099]\n",
            "20/11/23 15:47:52 - INFO - tape.training -   Evaluation: [Loss: 0.41295]\n",
            "20/11/23 15:47:52 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:47:52 - INFO - tape.training -   Saving model checkpoint to results/stability_transformer_20-11-23-15-40-49_603263\n",
            "20/11/23 15:47:56 - INFO - tape.training -   [Ep: 1.01][Iter: 360][Time:  3.58s][Loss: 0.29895][LR: 0.00044989]\n",
            "20/11/23 15:48:19 - INFO - tape.training -   [Ep: 1.06][Iter: 380][Time: 23.32s][Loss: 0.28705][LR: 0.00044709]\n",
            "20/11/23 15:48:43 - INFO - tape.training -   [Ep: 1.12][Iter: 400][Time: 23.93s][Loss: 0.2868][LR: 0.00044429]\n",
            "20/11/23 15:49:07 - INFO - tape.training -   [Ep: 1.18][Iter: 420][Time: 23.64s][Loss: 0.27586][LR: 0.00044149]\n",
            "20/11/23 15:49:31 - INFO - tape.training -   [Ep: 1.23][Iter: 440][Time: 24.45s][Loss: 0.28214][LR: 0.00043869]\n",
            "20/11/23 15:49:55 - INFO - tape.training -   [Ep: 1.29][Iter: 460][Time: 24.05s][Loss: 0.28518][LR: 0.00043589]\n",
            "20/11/23 15:50:19 - INFO - tape.training -   [Ep: 1.34][Iter: 480][Time: 23.12s][Loss: 0.2687][LR: 0.00043309]\n",
            "20/11/23 15:50:42 - INFO - tape.training -   [Ep: 1.40][Iter: 500][Time: 23.26s][Loss: 0.27348][LR: 0.00043029]\n",
            "20/11/23 15:51:04 - INFO - tape.training -   [Ep: 1.46][Iter: 520][Time: 22.58s][Loss: 0.27123][LR: 0.00042749]\n",
            "20/11/23 15:51:28 - INFO - tape.training -   [Ep: 1.51][Iter: 540][Time: 23.71s][Loss: 0.28023][LR: 0.00042469]\n",
            "20/11/23 15:51:51 - INFO - tape.training -   [Ep: 1.57][Iter: 560][Time: 23.00s][Loss: 0.2739][LR: 0.00042189]\n",
            "20/11/23 15:52:14 - INFO - tape.training -   [Ep: 1.62][Iter: 580][Time: 23.02s][Loss: 0.26786][LR: 0.00041909]\n",
            "20/11/23 15:52:38 - INFO - tape.training -   [Ep: 1.68][Iter: 600][Time: 23.50s][Loss: 0.25963][LR: 0.00041629]\n",
            "20/11/23 15:53:01 - INFO - tape.training -   [Ep: 1.74][Iter: 620][Time: 23.04s][Loss: 0.27479][LR: 0.00041349]\n",
            "20/11/23 15:53:23 - INFO - tape.training -   [Ep: 1.79][Iter: 640][Time: 22.88s][Loss: 0.27716][LR: 0.00041069]\n",
            "20/11/23 15:53:47 - INFO - tape.training -   [Ep: 1.85][Iter: 660][Time: 23.39s][Loss: 0.26882][LR: 0.00040789]\n",
            "20/11/23 15:54:10 - INFO - tape.training -   [Ep: 1.90][Iter: 680][Time: 22.66s][Loss: 0.27172][LR: 0.0004051]\n",
            "20/11/23 15:54:32 - INFO - tape.training -   [Ep: 1.96][Iter: 700][Time: 22.91s][Loss: 0.2653][LR: 0.0004023]\n",
            "20/11/23 15:54:48 - INFO - tape.training -   Train: [Loss: 0.27359]\n",
            "20/11/23 15:54:58 - INFO - tape.training -   Evaluation: [Loss: 0.37176]\n",
            "20/11/23 15:54:58 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 15:54:58 - INFO - tape.training -   Saving model checkpoint to results/stability_transformer_20-11-23-15-40-49_603263\n",
            "20/11/23 15:55:05 - INFO - tape.training -   [Ep: 2.02][Iter: 720][Time:  7.08s][Loss: 0.26948][LR: 0.0003995]\n",
            "20/11/23 15:55:28 - INFO - tape.training -   [Ep: 2.07][Iter: 740][Time: 22.95s][Loss: 0.25789][LR: 0.0003967]\n",
            "20/11/23 15:55:52 - INFO - tape.training -   [Ep: 2.13][Iter: 760][Time: 24.19s][Loss: 0.27252][LR: 0.0003939]\n",
            "20/11/23 15:56:15 - INFO - tape.training -   [Ep: 2.18][Iter: 780][Time: 22.66s][Loss: 0.2614][LR: 0.0003911]\n",
            "20/11/23 15:56:37 - INFO - tape.training -   [Ep: 2.24][Iter: 800][Time: 22.43s][Loss: 0.27033][LR: 0.0003883]\n",
            "20/11/23 15:57:01 - INFO - tape.training -   [Ep: 2.30][Iter: 820][Time: 23.65s][Loss: 0.26617][LR: 0.0003855]\n",
            "20/11/23 15:57:25 - INFO - tape.training -   [Ep: 2.35][Iter: 840][Time: 23.72s][Loss: 0.26585][LR: 0.0003827]\n",
            "20/11/23 15:57:48 - INFO - tape.training -   [Ep: 2.41][Iter: 860][Time: 22.88s][Loss: 0.2498][LR: 0.0003799]\n",
            "20/11/23 15:58:10 - INFO - tape.training -   [Ep: 2.46][Iter: 880][Time: 22.18s][Loss: 0.25553][LR: 0.0003771]\n",
            "20/11/23 15:58:33 - INFO - tape.training -   [Ep: 2.52][Iter: 900][Time: 22.94s][Loss: 0.25724][LR: 0.0003743]\n",
            "20/11/23 15:58:56 - INFO - tape.training -   [Ep: 2.58][Iter: 920][Time: 23.67s][Loss: 0.2663][LR: 0.0003715]\n",
            "20/11/23 15:59:20 - INFO - tape.training -   [Ep: 2.63][Iter: 940][Time: 23.44s][Loss: 0.26909][LR: 0.0003687]\n",
            "20/11/23 15:59:43 - INFO - tape.training -   [Ep: 2.69][Iter: 960][Time: 23.48s][Loss: 0.2628][LR: 0.0003659]\n",
            "20/11/23 16:00:06 - INFO - tape.training -   [Ep: 2.74][Iter: 980][Time: 23.09s][Loss: 0.25916][LR: 0.0003631]\n",
            "20/11/23 16:00:29 - INFO - tape.training -   [Ep: 2.80][Iter: 1000][Time: 22.85s][Loss: 0.25406][LR: 0.0003603]\n",
            "20/11/23 16:00:53 - INFO - tape.training -   [Ep: 2.86][Iter: 1020][Time: 23.45s][Loss: 0.25469][LR: 0.0003575]\n",
            "20/11/23 16:01:16 - INFO - tape.training -   [Ep: 2.91][Iter: 1040][Time: 23.68s][Loss: 0.2604][LR: 0.0003547]\n",
            "20/11/23 16:01:39 - INFO - tape.training -   [Ep: 2.97][Iter: 1060][Time: 22.68s][Loss: 0.25875][LR: 0.0003519]\n",
            "20/11/23 16:01:52 - INFO - tape.training -   Train: [Loss: 0.26088]\n",
            "20/11/23 16:02:01 - INFO - tape.training -   Evaluation: [Loss: 0.29249]\n",
            "20/11/23 16:02:01 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 16:02:01 - INFO - tape.training -   Saving model checkpoint to results/stability_transformer_20-11-23-15-40-49_603263\n",
            "20/11/23 16:02:12 - INFO - tape.training -   [Ep: 3.03][Iter: 1080][Time: 10.53s][Loss: 0.27371][LR: 0.0003491]\n",
            "20/11/23 16:02:36 - INFO - tape.training -   [Ep: 3.08][Iter: 1100][Time: 24.62s][Loss: 0.26957][LR: 0.0003463]\n",
            "20/11/23 16:02:59 - INFO - tape.training -   [Ep: 3.14][Iter: 1120][Time: 22.62s][Loss: 0.26612][LR: 0.00034351]\n",
            "20/11/23 16:03:23 - INFO - tape.training -   [Ep: 3.19][Iter: 1140][Time: 23.59s][Loss: 0.26584][LR: 0.00034071]\n",
            "20/11/23 16:03:45 - INFO - tape.training -   [Ep: 3.25][Iter: 1160][Time: 22.80s][Loss: 0.25606][LR: 0.00033791]\n",
            "20/11/23 16:04:09 - INFO - tape.training -   [Ep: 3.30][Iter: 1180][Time: 23.28s][Loss: 0.2574][LR: 0.00033511]\n",
            "20/11/23 16:04:33 - INFO - tape.training -   [Ep: 3.36][Iter: 1200][Time: 24.47s][Loss: 0.2532][LR: 0.00033231]\n",
            "20/11/23 16:04:56 - INFO - tape.training -   [Ep: 3.42][Iter: 1220][Time: 23.10s][Loss: 0.25792][LR: 0.00032951]\n",
            "20/11/23 16:05:20 - INFO - tape.training -   [Ep: 3.47][Iter: 1240][Time: 23.84s][Loss: 0.24455][LR: 0.00032671]\n",
            "20/11/23 16:05:44 - INFO - tape.training -   [Ep: 3.53][Iter: 1260][Time: 23.84s][Loss: 0.2417][LR: 0.00032391]\n",
            "20/11/23 16:06:07 - INFO - tape.training -   [Ep: 3.58][Iter: 1280][Time: 23.07s][Loss: 0.24903][LR: 0.00032111]\n",
            "20/11/23 16:06:31 - INFO - tape.training -   [Ep: 3.64][Iter: 1300][Time: 23.66s][Loss: 0.25044][LR: 0.00031831]\n",
            "20/11/23 16:06:54 - INFO - tape.training -   [Ep: 3.70][Iter: 1320][Time: 23.59s][Loss: 0.25711][LR: 0.00031551]\n",
            "20/11/23 16:07:17 - INFO - tape.training -   [Ep: 3.75][Iter: 1340][Time: 22.44s][Loss: 0.25265][LR: 0.00031271]\n",
            "20/11/23 16:07:40 - INFO - tape.training -   [Ep: 3.81][Iter: 1360][Time: 23.56s][Loss: 0.24981][LR: 0.00030991]\n",
            "20/11/23 16:08:04 - INFO - tape.training -   [Ep: 3.86][Iter: 1380][Time: 23.53s][Loss: 0.24796][LR: 0.00030711]\n",
            "20/11/23 16:08:27 - INFO - tape.training -   [Ep: 3.92][Iter: 1400][Time: 23.45s][Loss: 0.25333][LR: 0.00030431]\n",
            "20/11/23 16:08:50 - INFO - tape.training -   [Ep: 3.98][Iter: 1420][Time: 22.66s][Loss: 0.25211][LR: 0.00030151]\n",
            "20/11/23 16:09:00 - INFO - tape.training -   Train: [Loss: 0.25417]\n",
            "20/11/23 16:09:09 - INFO - tape.training -   Evaluation: [Loss: 0.3239]\n",
            "20/11/23 16:09:09 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 16:09:09 - INFO - tape.training -   Saving model checkpoint to results/stability_transformer_20-11-23-15-40-49_603263\n",
            "20/11/23 16:09:23 - INFO - tape.training -   [Ep: 4.03][Iter: 1440][Time: 14.14s][Loss: 0.32204][LR: 0.00029871]\n",
            "20/11/23 16:09:47 - INFO - tape.training -   [Ep: 4.09][Iter: 1460][Time: 23.67s][Loss: 0.27067][LR: 0.00029591]\n",
            "20/11/23 16:10:10 - INFO - tape.training -   [Ep: 4.15][Iter: 1480][Time: 23.31s][Loss: 0.25634][LR: 0.00029311]\n",
            "20/11/23 16:10:32 - INFO - tape.training -   [Ep: 4.20][Iter: 1500][Time: 22.43s][Loss: 0.24396][LR: 0.00029031]\n",
            "20/11/23 16:10:55 - INFO - tape.training -   [Ep: 4.26][Iter: 1520][Time: 22.63s][Loss: 0.2397][LR: 0.00028751]\n",
            "20/11/23 16:11:18 - INFO - tape.training -   [Ep: 4.31][Iter: 1540][Time: 22.80s][Loss: 0.24504][LR: 0.00028471]\n",
            "20/11/23 16:11:40 - INFO - tape.training -   [Ep: 4.37][Iter: 1560][Time: 22.47s][Loss: 0.24173][LR: 0.00028191]\n",
            "20/11/23 16:12:03 - INFO - tape.training -   [Ep: 4.43][Iter: 1580][Time: 23.03s][Loss: 0.24558][LR: 0.00027912]\n",
            "20/11/23 16:12:27 - INFO - tape.training -   [Ep: 4.48][Iter: 1600][Time: 23.24s][Loss: 0.24187][LR: 0.00027632]\n",
            "20/11/23 16:12:49 - INFO - tape.training -   [Ep: 4.54][Iter: 1620][Time: 22.65s][Loss: 0.24556][LR: 0.00027352]\n",
            "20/11/23 16:13:12 - INFO - tape.training -   [Ep: 4.59][Iter: 1640][Time: 22.77s][Loss: 0.25191][LR: 0.00027072]\n",
            "20/11/23 16:13:36 - INFO - tape.training -   [Ep: 4.65][Iter: 1660][Time: 23.97s][Loss: 0.2501][LR: 0.00026792]\n",
            "20/11/23 16:13:59 - INFO - tape.training -   [Ep: 4.70][Iter: 1680][Time: 23.43s][Loss: 0.24212][LR: 0.00026512]\n",
            "20/11/23 16:14:23 - INFO - tape.training -   [Ep: 4.76][Iter: 1700][Time: 23.73s][Loss: 0.24956][LR: 0.00026232]\n",
            "20/11/23 16:14:47 - INFO - tape.training -   [Ep: 4.82][Iter: 1720][Time: 23.38s][Loss: 0.25036][LR: 0.00025952]\n",
            "20/11/23 16:15:10 - INFO - tape.training -   [Ep: 4.87][Iter: 1740][Time: 23.54s][Loss: 0.24929][LR: 0.00025672]\n",
            "20/11/23 16:15:34 - INFO - tape.training -   [Ep: 4.93][Iter: 1760][Time: 23.52s][Loss: 0.24528][LR: 0.00025392]\n",
            "20/11/23 16:15:57 - INFO - tape.training -   [Ep: 4.98][Iter: 1780][Time: 23.47s][Loss: 0.24324][LR: 0.00025112]\n",
            "20/11/23 16:16:03 - INFO - tape.training -   Train: [Loss: 0.24583]\n",
            "20/11/23 16:16:12 - INFO - tape.training -   Evaluation: [Loss: 0.36515]\n",
            "20/11/23 16:16:12 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 16:16:12 - INFO - tape.training -   Saving model checkpoint to results/stability_transformer_20-11-23-15-40-49_603263\n",
            "20/11/23 16:16:30 - INFO - tape.training -   [Ep: 5.04][Iter: 1800][Time: 18.06s][Loss: 0.25225][LR: 0.00024832]\n",
            "20/11/23 16:16:53 - INFO - tape.training -   [Ep: 5.10][Iter: 1820][Time: 22.76s][Loss: 0.23776][LR: 0.00024552]\n",
            "20/11/23 16:17:16 - INFO - tape.training -   [Ep: 5.15][Iter: 1840][Time: 23.20s][Loss: 0.23887][LR: 0.00024272]\n",
            "20/11/23 16:17:39 - INFO - tape.training -   [Ep: 5.21][Iter: 1860][Time: 22.97s][Loss: 0.23679][LR: 0.00023992]\n",
            "20/11/23 16:18:02 - INFO - tape.training -   [Ep: 5.27][Iter: 1880][Time: 22.75s][Loss: 0.23775][LR: 0.00023712]\n",
            "20/11/23 16:18:24 - INFO - tape.training -   [Ep: 5.32][Iter: 1900][Time: 22.70s][Loss: 0.2343][LR: 0.00023432]\n",
            "20/11/23 16:18:48 - INFO - tape.training -   [Ep: 5.38][Iter: 1920][Time: 23.66s][Loss: 0.23718][LR: 0.00023152]\n",
            "20/11/23 16:19:10 - INFO - tape.training -   [Ep: 5.43][Iter: 1940][Time: 22.25s][Loss: 0.24345][LR: 0.00022872]\n",
            "20/11/23 16:19:34 - INFO - tape.training -   [Ep: 5.49][Iter: 1960][Time: 23.50s][Loss: 0.24531][LR: 0.00022592]\n",
            "20/11/23 16:19:56 - INFO - tape.training -   [Ep: 5.55][Iter: 1980][Time: 22.58s][Loss: 0.24119][LR: 0.00022312]\n",
            "20/11/23 16:20:19 - INFO - tape.training -   [Ep: 5.60][Iter: 2000][Time: 23.03s][Loss: 0.2359][LR: 0.00022032]\n",
            "20/11/23 16:20:43 - INFO - tape.training -   [Ep: 5.66][Iter: 2020][Time: 23.13s][Loss: 0.23765][LR: 0.00021753]\n",
            "20/11/23 16:21:06 - INFO - tape.training -   [Ep: 5.71][Iter: 2040][Time: 23.32s][Loss: 0.23941][LR: 0.00021473]\n",
            "20/11/23 16:21:29 - INFO - tape.training -   [Ep: 5.77][Iter: 2060][Time: 23.10s][Loss: 0.24281][LR: 0.00021193]\n",
            "20/11/23 16:21:53 - INFO - tape.training -   [Ep: 5.83][Iter: 2080][Time: 24.32s][Loss: 0.24206][LR: 0.00020913]\n",
            "20/11/23 16:22:17 - INFO - tape.training -   [Ep: 5.88][Iter: 2100][Time: 23.37s][Loss: 0.24071][LR: 0.00020633]\n",
            "20/11/23 16:22:40 - INFO - tape.training -   [Ep: 5.94][Iter: 2120][Time: 23.48s][Loss: 0.23876][LR: 0.00020353]\n",
            "20/11/23 16:23:04 - INFO - tape.training -   [Ep: 5.99][Iter: 2140][Time: 23.30s][Loss: 0.23542][LR: 0.00020073]\n",
            "20/11/23 16:23:06 - INFO - tape.training -   Train: [Loss: 0.23956]\n",
            "20/11/23 16:23:15 - INFO - tape.training -   Evaluation: [Loss: 0.25133]\n",
            "20/11/23 16:23:15 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 16:23:15 - INFO - tape.training -   Saving model checkpoint to results/stability_transformer_20-11-23-15-40-49_603263\n",
            "20/11/23 16:23:37 - INFO - tape.training -   [Ep: 6.05][Iter: 2160][Time: 21.37s][Loss: 0.22715][LR: 0.00019793]\n",
            "20/11/23 16:24:00 - INFO - tape.training -   [Ep: 6.11][Iter: 2180][Time: 23.02s][Loss: 0.23373][LR: 0.00019513]\n",
            "20/11/23 16:24:23 - INFO - tape.training -   [Ep: 6.16][Iter: 2200][Time: 23.51s][Loss: 0.23987][LR: 0.00019233]\n",
            "20/11/23 16:24:46 - INFO - tape.training -   [Ep: 6.22][Iter: 2220][Time: 23.04s][Loss: 0.23201][LR: 0.00018953]\n",
            "20/11/23 16:25:10 - INFO - tape.training -   [Ep: 6.27][Iter: 2240][Time: 23.29s][Loss: 0.23863][LR: 0.00018673]\n",
            "20/11/23 16:25:33 - INFO - tape.training -   [Ep: 6.33][Iter: 2260][Time: 23.65s][Loss: 0.23663][LR: 0.00018393]\n",
            "20/11/23 16:25:57 - INFO - tape.training -   [Ep: 6.39][Iter: 2280][Time: 23.63s][Loss: 0.23082][LR: 0.00018113]\n",
            "20/11/23 16:26:20 - INFO - tape.training -   [Ep: 6.44][Iter: 2300][Time: 23.35s][Loss: 0.23733][LR: 0.00017833]\n",
            "20/11/23 16:26:43 - INFO - tape.training -   [Ep: 6.50][Iter: 2320][Time: 23.10s][Loss: 0.23512][LR: 0.00017553]\n",
            "20/11/23 16:27:07 - INFO - tape.training -   [Ep: 6.55][Iter: 2340][Time: 23.31s][Loss: 0.24069][LR: 0.00017273]\n",
            "20/11/23 16:27:30 - INFO - tape.training -   [Ep: 6.61][Iter: 2360][Time: 23.42s][Loss: 0.2347][LR: 0.00016993]\n",
            "20/11/23 16:27:55 - INFO - tape.training -   [Ep: 6.67][Iter: 2380][Time: 24.81s][Loss: 0.22902][LR: 0.00016713]\n",
            "20/11/23 16:28:18 - INFO - tape.training -   [Ep: 6.72][Iter: 2400][Time: 22.96s][Loss: 0.23677][LR: 0.00016433]\n",
            "20/11/23 16:28:41 - INFO - tape.training -   [Ep: 6.78][Iter: 2420][Time: 22.75s][Loss: 0.23747][LR: 0.00016153]\n",
            "20/11/23 16:29:04 - INFO - tape.training -   [Ep: 6.83][Iter: 2440][Time: 23.67s][Loss: 0.23548][LR: 0.00015873]\n",
            "20/11/23 16:29:27 - INFO - tape.training -   [Ep: 6.89][Iter: 2460][Time: 23.24s][Loss: 0.23286][LR: 0.00015594]\n",
            "20/11/23 16:29:51 - INFO - tape.training -   [Ep: 6.95][Iter: 2480][Time: 23.30s][Loss: 0.23064][LR: 0.00015314]\n",
            "20/11/23 16:30:14 - INFO - tape.training -   Train: [Loss: 0.23491]\n",
            "20/11/23 16:30:23 - INFO - tape.training -   Evaluation: [Loss: 0.29282]\n",
            "20/11/23 16:30:23 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 16:30:23 - INFO - tape.training -   Saving model checkpoint to results/stability_transformer_20-11-23-15-40-49_603263\n",
            "20/11/23 16:30:25 - INFO - tape.training -   [Ep: 7.00][Iter: 2500][Time:  1.40s][Loss: 0.20591][LR: 0.00015034]\n",
            "20/11/23 16:30:47 - INFO - tape.training -   [Ep: 7.06][Iter: 2520][Time: 22.70s][Loss: 0.21457][LR: 0.00014754]\n",
            "20/11/23 16:31:11 - INFO - tape.training -   [Ep: 7.11][Iter: 2540][Time: 24.08s][Loss: 0.2186][LR: 0.00014474]\n",
            "20/11/23 16:31:35 - INFO - tape.training -   [Ep: 7.17][Iter: 2560][Time: 23.86s][Loss: 0.23077][LR: 0.00014194]\n",
            "20/11/23 16:31:59 - INFO - tape.training -   [Ep: 7.23][Iter: 2580][Time: 23.92s][Loss: 0.23019][LR: 0.00013914]\n",
            "20/11/23 16:32:22 - INFO - tape.training -   [Ep: 7.28][Iter: 2600][Time: 23.22s][Loss: 0.23172][LR: 0.00013634]\n",
            "20/11/23 16:32:46 - INFO - tape.training -   [Ep: 7.34][Iter: 2620][Time: 23.14s][Loss: 0.23346][LR: 0.00013354]\n",
            "20/11/23 16:33:09 - INFO - tape.training -   [Ep: 7.39][Iter: 2640][Time: 23.05s][Loss: 0.22845][LR: 0.00013074]\n",
            "20/11/23 16:33:32 - INFO - tape.training -   [Ep: 7.45][Iter: 2660][Time: 23.23s][Loss: 0.22917][LR: 0.00012794]\n",
            "20/11/23 16:33:55 - INFO - tape.training -   [Ep: 7.51][Iter: 2680][Time: 23.51s][Loss: 0.23209][LR: 0.00012514]\n",
            "20/11/23 16:34:20 - INFO - tape.training -   [Ep: 7.56][Iter: 2700][Time: 24.24s][Loss: 0.24099][LR: 0.00012234]\n",
            "20/11/23 16:34:43 - INFO - tape.training -   [Ep: 7.62][Iter: 2720][Time: 23.31s][Loss: 0.23618][LR: 0.00011954]\n",
            "20/11/23 16:35:05 - INFO - tape.training -   [Ep: 7.67][Iter: 2740][Time: 22.49s][Loss: 0.23253][LR: 0.00011674]\n",
            "20/11/23 16:35:29 - INFO - tape.training -   [Ep: 7.73][Iter: 2760][Time: 23.36s][Loss: 0.22561][LR: 0.00011394]\n",
            "20/11/23 16:35:52 - INFO - tape.training -   [Ep: 7.79][Iter: 2780][Time: 23.71s][Loss: 0.2306][LR: 0.00011114]\n",
            "20/11/23 16:36:15 - INFO - tape.training -   [Ep: 7.84][Iter: 2800][Time: 22.72s][Loss: 0.22387][LR: 0.00010834]\n",
            "20/11/23 16:36:39 - INFO - tape.training -   [Ep: 7.90][Iter: 2820][Time: 23.48s][Loss: 0.22814][LR: 0.00010554]\n",
            "20/11/23 16:37:02 - INFO - tape.training -   [Ep: 7.95][Iter: 2840][Time: 22.92s][Loss: 0.2275][LR: 0.00010274]\n",
            "20/11/23 16:37:21 - INFO - tape.training -   Train: [Loss: 0.23023]\n",
            "20/11/23 16:37:30 - INFO - tape.training -   Evaluation: [Loss: 0.24361]\n",
            "20/11/23 16:37:30 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 16:37:30 - INFO - tape.training -   Saving model checkpoint to results/stability_transformer_20-11-23-15-40-49_603263\n",
            "20/11/23 16:37:34 - INFO - tape.training -   [Ep: 8.01][Iter: 2860][Time:  4.88s][Loss: 0.20978][LR: 9.9944e-05]\n",
            "20/11/23 16:37:57 - INFO - tape.training -   [Ep: 8.07][Iter: 2880][Time: 22.69s][Loss: 0.2198][LR: 9.7144e-05]\n",
            "20/11/23 16:38:20 - INFO - tape.training -   [Ep: 8.12][Iter: 2900][Time: 23.30s][Loss: 0.2277][LR: 9.4345e-05]\n",
            "20/11/23 16:38:43 - INFO - tape.training -   [Ep: 8.18][Iter: 2920][Time: 22.82s][Loss: 0.22882][LR: 9.1545e-05]\n",
            "20/11/23 16:39:06 - INFO - tape.training -   [Ep: 8.23][Iter: 2940][Time: 22.70s][Loss: 0.22317][LR: 8.8746e-05]\n",
            "20/11/23 16:39:29 - INFO - tape.training -   [Ep: 8.29][Iter: 2960][Time: 22.70s][Loss: 0.22938][LR: 8.5946e-05]\n",
            "20/11/23 16:39:52 - INFO - tape.training -   [Ep: 8.35][Iter: 2980][Time: 23.24s][Loss: 0.23029][LR: 8.3147e-05]\n",
            "20/11/23 16:40:15 - INFO - tape.training -   [Ep: 8.40][Iter: 3000][Time: 23.13s][Loss: 0.22568][LR: 8.0347e-05]\n",
            "20/11/23 16:40:39 - INFO - tape.training -   [Ep: 8.46][Iter: 3020][Time: 24.15s][Loss: 0.22654][LR: 7.7548e-05]\n",
            "20/11/23 16:41:03 - INFO - tape.training -   [Ep: 8.51][Iter: 3040][Time: 23.74s][Loss: 0.22921][LR: 7.4748e-05]\n",
            "20/11/23 16:41:27 - INFO - tape.training -   [Ep: 8.57][Iter: 3060][Time: 24.06s][Loss: 0.22683][LR: 7.1948e-05]\n",
            "20/11/23 16:41:51 - INFO - tape.training -   [Ep: 8.63][Iter: 3080][Time: 23.54s][Loss: 0.22181][LR: 6.9149e-05]\n",
            "20/11/23 16:42:14 - INFO - tape.training -   [Ep: 8.68][Iter: 3100][Time: 23.08s][Loss: 0.22398][LR: 6.6349e-05]\n",
            "20/11/23 16:42:37 - INFO - tape.training -   [Ep: 8.74][Iter: 3120][Time: 23.09s][Loss: 0.22543][LR: 6.355e-05]\n",
            "20/11/23 16:43:00 - INFO - tape.training -   [Ep: 8.79][Iter: 3140][Time: 23.79s][Loss: 0.22646][LR: 6.075e-05]\n",
            "20/11/23 16:43:23 - INFO - tape.training -   [Ep: 8.85][Iter: 3160][Time: 22.44s][Loss: 0.22856][LR: 5.7951e-05]\n",
            "20/11/23 16:43:47 - INFO - tape.training -   [Ep: 8.91][Iter: 3180][Time: 23.63s][Loss: 0.22838][LR: 5.5151e-05]\n",
            "20/11/23 16:44:09 - INFO - tape.training -   [Ep: 8.96][Iter: 3200][Time: 22.28s][Loss: 0.22319][LR: 5.2352e-05]\n",
            "20/11/23 16:44:25 - INFO - tape.training -   Train: [Loss: 0.22689]\n",
            "20/11/23 16:44:34 - INFO - tape.training -   Evaluation: [Loss: 0.24933]\n",
            "20/11/23 16:44:34 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 16:44:34 - INFO - tape.training -   Saving model checkpoint to results/stability_transformer_20-11-23-15-40-49_603263\n",
            "20/11/23 16:44:42 - INFO - tape.training -   [Ep: 9.02][Iter: 3220][Time:  8.37s][Loss: 0.2027][LR: 4.9552e-05]\n",
            "20/11/23 16:45:06 - INFO - tape.training -   [Ep: 9.08][Iter: 3240][Time: 23.63s][Loss: 0.22293][LR: 4.6753e-05]\n",
            "20/11/23 16:45:28 - INFO - tape.training -   [Ep: 9.13][Iter: 3260][Time: 22.46s][Loss: 0.21959][LR: 4.3953e-05]\n",
            "20/11/23 16:45:52 - INFO - tape.training -   [Ep: 9.19][Iter: 3280][Time: 23.47s][Loss: 0.21606][LR: 4.1153e-05]\n",
            "20/11/23 16:46:15 - INFO - tape.training -   [Ep: 9.24][Iter: 3300][Time: 23.69s][Loss: 0.21669][LR: 3.8354e-05]\n",
            "20/11/23 16:46:39 - INFO - tape.training -   [Ep: 9.30][Iter: 3320][Time: 23.31s][Loss: 0.23042][LR: 3.5554e-05]\n",
            "20/11/23 16:47:02 - INFO - tape.training -   [Ep: 9.36][Iter: 3340][Time: 23.39s][Loss: 0.22232][LR: 3.2755e-05]\n",
            "20/11/23 16:47:25 - INFO - tape.training -   [Ep: 9.41][Iter: 3360][Time: 23.02s][Loss: 0.22405][LR: 2.9955e-05]\n",
            "20/11/23 16:47:49 - INFO - tape.training -   [Ep: 9.47][Iter: 3380][Time: 23.89s][Loss: 0.23394][LR: 2.7156e-05]\n",
            "20/11/23 16:48:12 - INFO - tape.training -   [Ep: 9.52][Iter: 3400][Time: 22.92s][Loss: 0.22601][LR: 2.4356e-05]\n",
            "20/11/23 16:48:35 - INFO - tape.training -   [Ep: 9.58][Iter: 3420][Time: 23.04s][Loss: 0.22346][LR: 2.1557e-05]\n",
            "20/11/23 16:48:59 - INFO - tape.training -   [Ep: 9.64][Iter: 3440][Time: 23.56s][Loss: 0.22064][LR: 1.8757e-05]\n",
            "20/11/23 16:49:22 - INFO - tape.training -   [Ep: 9.69][Iter: 3460][Time: 23.42s][Loss: 0.21678][LR: 1.5957e-05]\n",
            "20/11/23 16:49:45 - INFO - tape.training -   [Ep: 9.75][Iter: 3480][Time: 22.83s][Loss: 0.22813][LR: 1.3158e-05]\n",
            "20/11/23 16:50:08 - INFO - tape.training -   [Ep: 9.80][Iter: 3500][Time: 23.10s][Loss: 0.22081][LR: 1.0358e-05]\n",
            "20/11/23 16:50:32 - INFO - tape.training -   [Ep: 9.86][Iter: 3520][Time: 23.78s][Loss: 0.22291][LR: 7.5588e-06]\n",
            "20/11/23 16:50:56 - INFO - tape.training -   [Ep: 9.91][Iter: 3540][Time: 23.99s][Loss: 0.22567][LR: 4.7592e-06]\n",
            "20/11/23 16:51:19 - INFO - tape.training -   [Ep: 9.97][Iter: 3560][Time: 23.30s][Loss: 0.22658][LR: 1.9597e-06]\n",
            "20/11/23 16:51:30 - INFO - tape.training -   Train: [Loss: 0.22354]\n",
            "20/11/23 16:51:40 - INFO - tape.training -   Evaluation: [Loss: 0.24434]\n",
            "20/11/23 16:51:40 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/11/23 16:51:40 - INFO - tape.training -   Saving model checkpoint to results/stability_transformer_20-11-23-15-40-49_603263\n",
            "20/11/23 16:51:40 - INFO - tape.training -   Finished training after 10 epochs.\n",
            "20/11/23 16:51:40 - Level 35 - tape.training -   Best Val Loss: 0.2436139451130488\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL4bl_DFfFNl",
        "outputId": "4eea5e1a-3e22-4533-b543-340c680f41c9"
      },
      "source": [
        "!tape-eval transformer stability /content/results/stability_transformer_20-11-23-15-40-49_603263 --metrics mse mae spearmanr  "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/11/23 16:51:59 - INFO - tape.training -   device: cuda n_gpu: 1\n",
            "20/11/23 16:51:59 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/stability_transformer_20-11-23-15-40-49_603263/config.json\n",
            "20/11/23 16:51:59 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 8096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": -1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/11/23 16:51:59 - INFO - tape.models.modeling_utils -   loading weights file /content/results/stability_transformer_20-11-23-15-40-49_603263/pytorch_model.bin\n",
            "Evaluation: 100% 13/13 [00:02<00:00,  6.20it/s]\n",
            "20/11/23 16:52:04 - INFO - tape.training -   mse: 0.3714797794818878mae: 0.524421751499176spearmanr: 0.6200878539909553\n",
            "{'mse': 0.37147978, 'mae': 0.52442175, 'spearmanr': 0.6200878539909553}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}