{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "get_baseline_pretrained2_resnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuAdol1Acd6A",
        "outputId": "55140b4f-389d-4d88-c51b-be026ec7fe90"
      },
      "source": [
        "# install tape \n",
        "!pip install tape_proteins"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tape_proteins in /usr/local/lib/python3.6/dist-packages (0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tape_proteins) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from tape_proteins) (2.23.0)\n",
            "Requirement already satisfied: biopython in /usr/local/lib/python3.6/dist-packages (from tape_proteins) (1.78)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (from tape_proteins) (2.1)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.6/dist-packages (from tape_proteins) (0.99)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tape_proteins) (4.41.1)\n",
            "Requirement already satisfied: torch<1.5,>=1.0 in /usr/local/lib/python3.6/dist-packages (from tape_proteins) (1.4.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from tape_proteins) (1.16.32)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->tape_proteins) (1.18.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->tape_proteins) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->tape_proteins) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->tape_proteins) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->tape_proteins) (2020.11.8)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->tape_proteins) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->tape_proteins) (1.15.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->tape_proteins) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->tape_proteins) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.20.0,>=1.19.32 in /usr/local/lib/python3.6/dist-packages (from boto3->tape_proteins) (1.19.32)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX->tape_proteins) (50.3.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.32->boto3->tape_proteins) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qgGoCG8clGj",
        "outputId": "fdf09c08-a6a8-4918-f4b9-84422da92c0e"
      },
      "source": [
        "!mkdir ./data\n",
        "!wget http://s3.amazonaws.com/proteindata/data_pytorch/fluorescence.tar.gz\n",
        "!tar -xzf fluorescence.tar.gz -C ./data\n",
        "!rm fluorescence.tar.gz\n",
        "!wget http://s3.amazonaws.com/proteindata/data_pytorch/proteinnet.tar.gz\n",
        "!tar -xzf proteinnet.tar.gz -C ./data\n",
        "!rm proteinnet.tar.gz\n",
        "!wget http://s3.amazonaws.com/proteindata/data_pytorch/remote_homology.tar.gz\n",
        "!tar -xzf remote_homology.tar.gz -C ./data\n",
        "!rm remote_homology.tar.gz\n",
        "!wget http://s3.amazonaws.com/proteindata/data_pytorch/secondary_structure.tar.gz\n",
        "!tar -xzf secondary_structure.tar.gz -C ./data\n",
        "!rm secondary_structure.tar.gz\n",
        "!wget http://s3.amazonaws.com/proteindata/data_pytorch/stability.tar.gz\n",
        "!tar -xzf stability.tar.gz -C ./data\n",
        "!rm stability.tar.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./data’: File exists\n",
            "--2020-12-09 10:24:28--  http://s3.amazonaws.com/proteindata/data_pytorch/fluorescence.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.170.101\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.170.101|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1635678 (1.6M) [application/x-tar]\n",
            "Saving to: ‘fluorescence.tar.gz’\n",
            "\n",
            "fluorescence.tar.gz 100%[===================>]   1.56M  1.37MB/s    in 1.1s    \n",
            "\n",
            "2020-12-09 10:24:30 (1.37 MB/s) - ‘fluorescence.tar.gz’ saved [1635678/1635678]\n",
            "\n",
            "--2020-12-09 10:24:30--  http://s3.amazonaws.com/proteindata/data_pytorch/proteinnet.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.14.110\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.14.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 464501179 (443M) [application/x-tar]\n",
            "Saving to: ‘proteinnet.tar.gz’\n",
            "\n",
            "proteinnet.tar.gz   100%[===================>] 442.98M  16.6MB/s    in 29s     \n",
            "\n",
            "2020-12-09 10:25:00 (15.4 MB/s) - ‘proteinnet.tar.gz’ saved [464501179/464501179]\n",
            "\n",
            "--2020-12-09 10:25:08--  http://s3.amazonaws.com/proteindata/data_pytorch/remote_homology.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.89.174\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.89.174|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43581262 (42M) [application/x-tar]\n",
            "Saving to: ‘remote_homology.tar.gz’\n",
            "\n",
            "remote_homology.tar 100%[===================>]  41.56M  11.3MB/s    in 3.7s    \n",
            "\n",
            "2020-12-09 10:25:12 (11.3 MB/s) - ‘remote_homology.tar.gz’ saved [43581262/43581262]\n",
            "\n",
            "--2020-12-09 10:25:14--  http://s3.amazonaws.com/proteindata/data_pytorch/secondary_structure.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.170.205\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.170.205|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 251794897 (240M) [application/x-tar]\n",
            "Saving to: ‘secondary_structure.tar.gz’\n",
            "\n",
            "secondary_structure 100%[===================>] 240.13M  16.5MB/s    in 16s     \n",
            "\n",
            "2020-12-09 10:25:31 (15.0 MB/s) - ‘secondary_structure.tar.gz’ saved [251794897/251794897]\n",
            "\n",
            "--2020-12-09 10:25:38--  http://s3.amazonaws.com/proteindata/data_pytorch/stability.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.79.222\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.79.222|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3116829 (3.0M) [application/x-tar]\n",
            "Saving to: ‘stability.tar.gz’\n",
            "\n",
            "stability.tar.gz    100%[===================>]   2.97M  2.27MB/s    in 1.3s    \n",
            "\n",
            "2020-12-09 10:25:39 (2.27 MB/s) - ‘stability.tar.gz’ saved [3116829/3116829]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUUCJPasfopg",
        "outputId": "02d7b4f6-9417-47f4-9aef-eb5cac3e84d1"
      },
      "source": [
        "%%bash\n",
        "\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "cd apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-yvnh5fal\n",
            "Created temporary directory: /tmp/pip-req-tracker-pxb11_b_\n",
            "Created requirements tracker '/tmp/pip-req-tracker-pxb11_b_'\n",
            "Created temporary directory: /tmp/pip-install-7u_obgl1\n",
            "Processing /content/apex\n",
            "  Created temporary directory: /tmp/pip-req-build-5gbp90jx\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-pxb11_b_'\n",
            "    Running setup.py (path:/tmp/pip-req-build-5gbp90jx/setup.py) egg_info for package from file:///content/apex\n",
            "  Source in /tmp/pip-req-build-5gbp90jx has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-pxb11_b_'\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Found existing installation: apex 0.1\n",
            "    Uninstalling apex-0.1:\n",
            "      Created temporary directory: /tmp/pip-uninstall-1ccebb4j\n",
            "      Removing file or directory /usr/local/lib/python3.6/dist-packages/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
            "      Created temporary directory: /usr/local/lib/python3.6/dist-packages/~pex-0.1-py3.6.egg-info\n",
            "      Removing file or directory /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
            "      Created temporary directory: /usr/local/lib/python3.6/dist-packages/~pex\n",
            "      Removing file or directory /usr/local/lib/python3.6/dist-packages/apex/\n",
            "      Removing file or directory /usr/local/lib/python3.6/dist-packages/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
            "      Removing file or directory /usr/local/lib/python3.6/dist-packages/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "      Removing file or directory /usr/local/lib/python3.6/dist-packages/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "      Removing file or directory /usr/local/lib/python3.6/dist-packages/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
            "      Successfully uninstalled apex-0.1\n",
            "  Created temporary directory: /tmp/pip-record-ulez928r\n",
            "    Running setup.py install for apex: started\n",
            "    Running setup.py install for apex: finished with status 'done'\n",
            "  Removing source in /tmp/pip-req-build-5gbp90jx\n",
            "Successfully installed apex-0.1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-pxb11_b_'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'apex' already exists and is not an empty directory.\n",
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.4.0\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-5gbp90jx/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-5gbp90jx/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-5gbp90jx/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-5gbp90jx/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-5gbp90jx/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-req-build-5gbp90jx/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-5gbp90jx/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-5gbp90jx/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-5gbp90jx/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-ulez928r/install-record.txt --single-version-externally-managed --compile\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.4.0\n",
            "\n",
            "\n",
            "    /tmp/pip-req-build-5gbp90jx/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "    Compiling cuda extensions with\n",
            "    nvcc: NVIDIA (R) Cuda compiler driver\n",
            "    Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "    Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "    Cuda compilation tools, release 10.1, V10.1.243\n",
            "    from /usr/local/cuda/bin\n",
            "\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    creating build\n",
            "    creating build/lib.linux-x86_64-3.6\n",
            "    creating build/lib.linux-x86_64-3.6/apex\n",
            "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    creating build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.6/apex/mlp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.6/apex/contrib/sparsity\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    running build_ext\n",
            "    building 'apex_C' extension\n",
            "    creating build/temp.linux-x86_64-3.6\n",
            "    creating build/temp.linux-x86_64-3.6/csrc\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -o build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'amp_C' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/amp_C_frontend.cpp -o build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_sgd_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_scale_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_axpby_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_l2norm_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_1.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb_stage_2.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adam.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_adagrad.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_novograd.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/multi_tensor_lamb.cu -o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -lineinfo -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=amp_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/amp_C_frontend.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_sgd_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_scale_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_axpby_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_l2norm_kernel.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_1.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb_stage_2.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adam.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_adagrad.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_novograd.o build/temp.linux-x86_64-3.6/csrc/multi_tensor_lamb.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'syncbn' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/syncbn.cpp -o build/temp.linux-x86_64-3.6/csrc/syncbn.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/welford.cu -o build/temp.linux-x86_64-3.6/csrc/welford.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=syncbn -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/syncbn.o build/temp.linux-x86_64-3.6/csrc/welford.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'fused_layer_norm_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda.cpp -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/layer_norm_cuda_kernel.cu -o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -maxrregcount=50 -O3 --use_fast_math -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=fused_layer_norm_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda.o build/temp.linux-x86_64-3.6/csrc/layer_norm_cuda_kernel.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    building 'mlp_cuda' extension\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/mlp.cpp -o build/temp.linux-x86_64-3.6/csrc/mlp.o -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n",
            "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_forward(int, int, std::vector<at::Tensor>)’:\n",
            "    csrc/mlp.cpp:56:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "       auto reserved_space = at::empty({reserved_size}, inputs[0].type());\n",
            "                                                                        ^\n",
            "    csrc/mlp.cpp:65:68: warning: narrowing conversion of ‘reserved_size’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:116:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:31:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:70:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:76:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_fp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:67:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_forward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In function ‘std::vector<at::Tensor> mlp_backward(int, int, at::Tensor, std::vector<at::Tensor>, std::vector<at::Tensor>)’:\n",
            "    csrc/mlp.cpp:113:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < num_layers; i++) {\n",
            "                       ~~^~~~~~~~~~~~\n",
            "    csrc/mlp.cpp:119:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "       for (int i = 0; i < inputs.size(); i++) {\n",
            "                       ~~^~~~~~~~~~~~~~~\n",
            "    In file included from /usr/local/lib/python3.6/dist-packages/torch/include/ATen/ATen.h:9:0,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/types.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader_options.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/base.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader/stateful.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data/dataloader.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/data.h:3,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:4,\n",
            "                     from /usr/local/lib/python3.6/dist-packages/torch/include/torch/extension.h:4,\n",
            "                     from csrc/mlp.cpp:1:\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:116:56: warning: ‘c10::ScalarType detail::scalar_type(const at::DeprecatedTypeProperties&)’ is deprecated [-Wdeprecated-declarations]\n",
            "         at::ScalarType _st = ::detail::scalar_type(the_type);                    \\\n",
            "                                                            ^\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:31:23: note: declared here\n",
            "     inline at::ScalarType scalar_type(const at::DeprecatedTypeProperties &t) {\n",
            "                           ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp: In lambda function:\n",
            "    csrc/mlp.cpp:125:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < num_layers; i++) {\n",
            "                         ~~^~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:129:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\n",
            "         for (int i = 0; i < inputs.size(); i++) {\n",
            "                         ~~^~~~~~~~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:137:44: warning: narrowing conversion of ‘(work_size / sizeof (scalar_t))’ from ‘long unsigned int’ to ‘long int’ inside { } [-Wnarrowing]\n",
            "         auto work_space = at::empty({work_size / sizeof(scalar_t)}, inputs[0].type());\n",
            "                                      ~~~~~~~~~~^~~~~~~~~\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    csrc/mlp.cpp:139:10: warning: unused variable ‘result’ [-Wunused-variable]\n",
            "         auto result = mlp_bp<scalar_t>(\n",
            "              ^\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/ATen/Dispatch.h:12:12: note: in definition of macro ‘AT_PRIVATE_CASE_TYPE’\n",
            "         return __VA_ARGS__();                          \\\n",
            "                ^~~~~~~~~~~\n",
            "    csrc/mlp.cpp:123:3: note: in expansion of macro ‘AT_DISPATCH_FLOATING_TYPES_AND_HALF’\n",
            "       AT_DISPATCH_FLOATING_TYPES_AND_HALF(inputs[0].type(), \"mlp_backward\", [&] {\n",
            "       ^\n",
            "    /usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.6m -c csrc/mlp_cuda.cu -o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' -O3 -DVERSION_GE_1_1 -DVERSION_GE_1_3 -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=mlp_cuda -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++11\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(97): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(112): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/c10/core/TensorTypeSet.h(44): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(14): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(15): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(18): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(19): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(23): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include/torch/nn/functional/padding.h(24): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(97): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    /usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/autograd/profiler.h(112): warning: attribute \"__visibility__\" does not apply here\n",
            "\n",
            "    x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.6/csrc/mlp.o build/temp.linux-x86_64-3.6/csrc/mlp_cuda.o -L/usr/local/cuda/lib64 -lcudart -o build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "    running install_lib\n",
            "    copying build/lib.linux-x86_64-3.6/apex_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex\n",
            "    copying build/lib.linux-x86_64-3.6/apex/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/nvtx/nvmarker.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/nvvp.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/db.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/parse/parse.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pointwise.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/normalization.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/recurrentCell.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/softmax.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/output.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/convert.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/embedding.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/misc.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/prof.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/activation.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/usage.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/__main__.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/reduction.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/blas.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/dropout.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/loss.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/utility.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/index_slice_join_mutate.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/base.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/linear.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/data.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/randomSample.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/pooling.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/optim.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    copying build/lib.linux-x86_64-3.6/apex/pyprof/prof/conv.py -> /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/loss_scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16util.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    copying build/lib.linux-x86_64-3.6/apex/fp16_utils/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/fp16_utils\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/mlp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/mlp/mlp.py -> /usr/local/lib/python3.6/dist-packages/apex/mlp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/normalization/fused_layer_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/normalization\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/distributed.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/LARC.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/multiproc.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/optimized_sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    copying build/lib.linux-x86_64-3.6/apex/parallel/sync_batchnorm_kernel.py -> /usr/local/lib/python3.6/dist-packages/apex/parallel\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/reparameterization.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    copying build/lib.linux-x86_64-3.6/apex/reparameterization/weight_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/reparameterization\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/asp.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/sparsity/sparse_masklib.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/groupbn/batch_norm.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/fp16_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/optimizers/distributed_fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    copying build/lib.linux-x86_64-3.6/apex/contrib/xentropy/softmax_xentropy.py -> /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_sgd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_novograd.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_lamb.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adam.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    copying build/lib.linux-x86_64-3.6/apex/optimizers/fused_adagrad.py -> /usr/local/lib/python3.6/dist-packages/apex/optimizers\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    copying build/lib.linux-x86_64-3.6/apex/multi_tensor_apply/multi_tensor_apply.py -> /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/models.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/RNNBackend.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    copying build/lib.linux-x86_64-3.6/apex/RNN/cells.py -> /usr/local/lib/python3.6/dist-packages/apex/RNN\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/opt.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/scaler.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_amp_state.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/rnn_compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/frontend.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    creating /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/__init__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/tensor_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/functional_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/lists/torch_overrides.py -> /usr/local/lib/python3.6/dist-packages/apex/amp/lists\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_process_optimizer.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/compat.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/wrap.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/amp.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/__version__.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/utils.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/handle.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/apex/amp/_initialize.py -> /usr/local/lib/python3.6/dist-packages/apex/amp\n",
            "    copying build/lib.linux-x86_64-3.6/mlp_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/syncbn.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    copying build/lib.linux-x86_64-3.6/amp_C.cpython-36m-x86_64-linux-gnu.so -> /usr/local/lib/python3.6/dist-packages\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/mask_softmax_dropout_func.py to mask_softmax_dropout_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/asp.py to asp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/sparsity/sparse_masklib.py to sparse_masklib.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_lamb.py to distributed_fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
            "    byte-compiling /usr/local/lib/python3.6/dist-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
            "    running install_egg_info\n",
            "    running egg_info\n",
            "    creating apex.egg-info\n",
            "    writing apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to apex.egg-info/top_level.txt\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "    Copying apex.egg-info to /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
            "    running install_scripts\n",
            "    writing list of installed files to '/tmp/pip-record-ulez928r/install-record.txt'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4l_OLNzfor7",
        "outputId": "f36221dc-b524-4439-c43c-84319adfc4dd"
      },
      "source": [
        "%%writefile /usr/local/lib/python3.6/dist-packages/tape/datasets.py\n",
        "\n",
        "from typing import Union, List, Tuple, Sequence, Dict, Any, Optional, Collection\n",
        "from copy import copy\n",
        "from pathlib import Path\n",
        "import pickle as pkl\n",
        "import logging\n",
        "import random\n",
        "\n",
        "import lmdb\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "\n",
        "from .tokenizers import TAPETokenizer\n",
        "from .registry import registry\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def dataset_factory(data_file: Union[str, Path], *args, **kwargs) -> Dataset:\n",
        "    data_file = Path(data_file)\n",
        "    if not data_file.exists():\n",
        "        raise FileNotFoundError(data_file)\n",
        "    if data_file.suffix == '.lmdb':\n",
        "        return LMDBDataset(data_file, *args, **kwargs)\n",
        "    elif data_file.suffix in {'.fasta', '.fna', '.ffn', '.faa', '.frn'}:\n",
        "        return FastaDataset(data_file, *args, **kwargs)\n",
        "    elif data_file.suffix == '.json':\n",
        "        return JSONDataset(data_file, *args, **kwargs)\n",
        "    elif data_file.is_dir():\n",
        "        return NPZDataset(data_file, *args, **kwargs)\n",
        "    else:\n",
        "        raise ValueError(f\"Unrecognized datafile type {data_file.suffix}\")\n",
        "\n",
        "\n",
        "def pad_sequences(sequences: Sequence, constant_value=0, dtype=None) -> np.ndarray:\n",
        "    batch_size = len(sequences)\n",
        "    shape = [batch_size] + np.max([seq.shape for seq in sequences], 0).tolist()\n",
        "\n",
        "    if dtype is None:\n",
        "        dtype = sequences[0].dtype\n",
        "\n",
        "    if isinstance(sequences[0], np.ndarray):\n",
        "        array = np.full(shape, constant_value, dtype=dtype)\n",
        "    elif isinstance(sequences[0], torch.Tensor):\n",
        "        array = torch.full(shape, constant_value, dtype=dtype)\n",
        "\n",
        "    for arr, seq in zip(array, sequences):\n",
        "        arrslice = tuple(slice(dim) for dim in seq.shape)\n",
        "        arr[arrslice] = seq\n",
        "\n",
        "    return array\n",
        "\n",
        "\n",
        "class FastaDataset(Dataset):\n",
        "    \"\"\"Creates a dataset from a fasta file.\n",
        "    Args:\n",
        "        data_file (Union[str, Path]): Path to fasta file.\n",
        "        in_memory (bool, optional): Whether to load the full dataset into memory.\n",
        "            Default: False.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_file: Union[str, Path],\n",
        "                 in_memory: bool = False):\n",
        "\n",
        "        from Bio import SeqIO\n",
        "        data_file = Path(data_file)\n",
        "        if not data_file.exists():\n",
        "            raise FileNotFoundError(data_file)\n",
        "\n",
        "        # if in_memory:\n",
        "        cache = list(SeqIO.parse(str(data_file), 'fasta'))\n",
        "        num_examples = len(cache)\n",
        "        self._cache = cache\n",
        "        # else:\n",
        "            # records = SeqIO.index(str(data_file), 'fasta')\n",
        "            # num_examples = len(records)\n",
        "#\n",
        "            # if num_examples < 10000:\n",
        "                # logger.info(\"Reading full fasta file into memory because number of examples \"\n",
        "                            # \"is very low. This loads data approximately 20x faster.\")\n",
        "                # in_memory = True\n",
        "                # cache = list(records.values())\n",
        "                # self._cache = cache\n",
        "            # else:\n",
        "                # self._records = records\n",
        "                # self._keys = list(records.keys())\n",
        "\n",
        "        self._in_memory = in_memory\n",
        "        self._num_examples = num_examples\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self._num_examples\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        if not 0 <= index < self._num_examples:\n",
        "            raise IndexError(index)\n",
        "\n",
        "        # if self._in_memory and self._cache[index] is not None:\n",
        "        record = self._cache[index]\n",
        "        # else:\n",
        "            # key = self._keys[index]\n",
        "            # record = self._records[key]\n",
        "            # if self._in_memory:\n",
        "                # self._cache[index] = record\n",
        "\n",
        "        item = {'id': record.id,\n",
        "                'primary': str(record.seq),\n",
        "                'protein_length': len(record.seq)}\n",
        "        return item\n",
        "\n",
        "\n",
        "class LMDBDataset(Dataset):\n",
        "    \"\"\"Creates a dataset from an lmdb file.\n",
        "    Args:\n",
        "        data_file (Union[str, Path]): Path to lmdb file.\n",
        "        in_memory (bool, optional): Whether to load the full dataset into memory.\n",
        "            Default: False.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_file: Union[str, Path],\n",
        "                 in_memory: bool = False):\n",
        "\n",
        "        data_file = Path(data_file)\n",
        "        if not data_file.exists():\n",
        "            raise FileNotFoundError(data_file)\n",
        "\n",
        "        env = lmdb.open(str(data_file), max_readers=1, readonly=True,\n",
        "                        lock=False, readahead=False, meminit=False)\n",
        "\n",
        "        with env.begin(write=False) as txn:\n",
        "            num_examples = pkl.loads(txn.get(b'num_examples'))\n",
        "\n",
        "        if in_memory:\n",
        "            cache = [None] * num_examples\n",
        "            self._cache = cache\n",
        "\n",
        "        self._env = env\n",
        "        self._in_memory = in_memory\n",
        "        self._num_examples = num_examples\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self._num_examples\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        if not 0 <= index < self._num_examples:\n",
        "            raise IndexError(index)\n",
        "\n",
        "        if self._in_memory and self._cache[index] is not None:\n",
        "            item = self._cache[index]\n",
        "        else:\n",
        "            with self._env.begin(write=False) as txn:\n",
        "                item = pkl.loads(txn.get(str(index).encode()))\n",
        "                if 'id' not in item:\n",
        "                    item['id'] = str(index)\n",
        "                if self._in_memory:\n",
        "                    self._cache[index] = item\n",
        "        return item\n",
        "\n",
        "\n",
        "class JSONDataset(Dataset):\n",
        "    \"\"\"Creates a dataset from a json file. Assumes that data is\n",
        "       a JSON serialized list of record, where each record is\n",
        "       a dictionary.\n",
        "    Args:\n",
        "        data_file (Union[str, Path]): Path to json file.\n",
        "        in_memory (bool): Dummy variable to match API of other datasets\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_file: Union[str, Path], in_memory: bool = True):\n",
        "        import json\n",
        "        data_file = Path(data_file)\n",
        "        if not data_file.exists():\n",
        "            raise FileNotFoundError(data_file)\n",
        "        records = json.loads(data_file.read_text())\n",
        "\n",
        "        if not isinstance(records, list):\n",
        "            raise TypeError(f\"TAPE JSONDataset requires a json serialized list, \"\n",
        "                            f\"received {type(records)}\")\n",
        "        self._records = records\n",
        "        self._num_examples = len(records)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self._num_examples\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        if not 0 <= index < self._num_examples:\n",
        "            raise IndexError(index)\n",
        "\n",
        "        item = self._records[index]\n",
        "        if not isinstance(item, dict):\n",
        "            raise TypeError(f\"Expected dataset to contain a list of dictionary \"\n",
        "                            f\"records, received record of type {type(item)}\")\n",
        "        if 'id' not in item:\n",
        "            item['id'] = str(index)\n",
        "        return item\n",
        "\n",
        "\n",
        "class NPZDataset(Dataset):\n",
        "    \"\"\"Creates a dataset from a directory of npz files.\n",
        "    Args:\n",
        "        data_file (Union[str, Path]): Path to directory of npz files\n",
        "        in_memory (bool): Dummy variable to match API of other datasets\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_file: Union[str, Path],\n",
        "                 in_memory: bool = True,\n",
        "                 split_files: Optional[Collection[str]] = None):\n",
        "        data_file = Path(data_file)\n",
        "        if not data_file.exists():\n",
        "            raise FileNotFoundError(data_file)\n",
        "        if not data_file.is_dir():\n",
        "            raise NotADirectoryError(data_file)\n",
        "        file_glob = data_file.glob('*.npz')\n",
        "        if split_files is None:\n",
        "            file_list = list(file_glob)\n",
        "        else:\n",
        "            split_files = set(split_files)\n",
        "            if len(split_files) == 0:\n",
        "                raise ValueError(\"Passed an empty split file set\")\n",
        "\n",
        "            file_list = [f for f in file_glob if f.name in split_files]\n",
        "            if len(file_list) != len(split_files):\n",
        "                num_missing = len(split_files) - len(file_list)\n",
        "                raise FileNotFoundError(\n",
        "                    f\"{num_missing} specified split files not found in directory\")\n",
        "\n",
        "        if len(file_list) == 0:\n",
        "            raise FileNotFoundError(f\"No .npz files found in {data_file}\")\n",
        "\n",
        "        self._file_list = file_list\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._file_list)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        if not 0 <= index < len(self):\n",
        "            raise IndexError(index)\n",
        "\n",
        "        item = dict(np.load(self._file_list[index]))\n",
        "        if not isinstance(item, dict):\n",
        "            raise TypeError(f\"Expected dataset to contain a list of dictionary \"\n",
        "                            f\"records, received record of type {type(item)}\")\n",
        "        if 'id' not in item:\n",
        "            item['id'] = self._file_list[index].stem\n",
        "        return item\n",
        "\n",
        "\n",
        "@registry.register_task('embed')\n",
        "class EmbedDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_file: Union[str, Path],\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False,\n",
        "                 convert_tokens_to_ids: bool = True):\n",
        "        super().__init__()\n",
        "\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataset_factory(data_file)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        item = self.data[index]\n",
        "        token_ids = self.tokenizer.encode(item['primary'])\n",
        "        input_mask = np.ones_like(token_ids)\n",
        "        return item['id'], token_ids, input_mask\n",
        "\n",
        "    def collate_fn(self, batch: List[Tuple[Any, ...]]) -> Dict[str, torch.Tensor]:\n",
        "        ids, tokens, input_mask = zip(*batch)\n",
        "        ids = list(ids)\n",
        "        tokens = torch.from_numpy(pad_sequences(tokens))\n",
        "        input_mask = torch.from_numpy(pad_sequences(input_mask))\n",
        "        return {'ids': ids, 'input_ids': tokens, 'input_mask': input_mask}  # type: ignore\n",
        "\n",
        "\n",
        "@registry.register_task('masked_language_modeling')\n",
        "class MaskedLanguageModelingDataset(Dataset):\n",
        "    \"\"\"Creates the Masked Language Modeling Pfam Dataset\n",
        "    Args:\n",
        "        data_path (Union[str, Path]): Path to tape data root.\n",
        "        split (str): One of ['train', 'valid', 'holdout'], specifies which data file to load.\n",
        "        in_memory (bool, optional): Whether to load the full dataset into memory.\n",
        "            Default: False.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_path: Union[str, Path],\n",
        "                 split: str,\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False):\n",
        "        super().__init__()\n",
        "        if split not in ('train', 'valid', 'holdout'):\n",
        "            raise ValueError(\n",
        "                f\"Unrecognized split: {split}. \"\n",
        "                f\"Must be one of ['train', 'valid', 'holdout']\")\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        data_path = Path(data_path)\n",
        "        data_file = f'pfam/pfam_{split}.lmdb'\n",
        "        self.data = dataset_factory(data_path / data_file, in_memory)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        tokens = self.tokenizer.tokenize(item['primary'])\n",
        "        tokens = self.tokenizer.add_special_tokens(tokens)\n",
        "        masked_tokens, labels = self._apply_bert_mask(tokens)\n",
        "        masked_token_ids = np.array(\n",
        "            self.tokenizer.convert_tokens_to_ids(masked_tokens), np.int64)\n",
        "        input_mask = np.ones_like(masked_token_ids)\n",
        "\n",
        "        masked_token_ids = np.array(\n",
        "            self.tokenizer.convert_tokens_to_ids(masked_tokens), np.int64)\n",
        "\n",
        "        return masked_token_ids, input_mask, labels, item['clan'], item['family']\n",
        "\n",
        "    def collate_fn(self, batch: List[Any]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, input_mask, lm_label_ids, clan, family = tuple(zip(*batch))\n",
        "\n",
        "        input_ids = torch.from_numpy(pad_sequences(input_ids, 0))\n",
        "        input_mask = torch.from_numpy(pad_sequences(input_mask, 0))\n",
        "        # ignore_index is -1\n",
        "        lm_label_ids = torch.from_numpy(pad_sequences(lm_label_ids, -1))\n",
        "        clan = torch.LongTensor(clan)  # type: ignore\n",
        "        family = torch.LongTensor(family)  # type: ignore\n",
        "\n",
        "        return {'input_ids': input_ids,\n",
        "                'input_mask': input_mask,\n",
        "                'targets': lm_label_ids}\n",
        "\n",
        "    def _apply_bert_mask(self, tokens: List[str]) -> Tuple[List[str], List[int]]:\n",
        "        masked_tokens = copy(tokens)\n",
        "        labels = np.zeros([len(tokens)], np.int64) - 1\n",
        "\n",
        "        for i, token in enumerate(tokens):\n",
        "            # Tokens begin and end with start_token and stop_token, ignore these\n",
        "            if token in (self.tokenizer.start_token, self.tokenizer.stop_token):\n",
        "                pass\n",
        "\n",
        "            prob = random.random()\n",
        "            if prob < 0.15:\n",
        "                prob /= 0.15\n",
        "                labels[i] = self.tokenizer.convert_token_to_id(token)\n",
        "\n",
        "                if prob < 0.8:\n",
        "                    # 80% random change to mask token\n",
        "                    token = self.tokenizer.mask_token\n",
        "                elif prob < 0.9:\n",
        "                    # 10% chance to change to random token\n",
        "                    token = self.tokenizer.convert_id_to_token(\n",
        "                        random.randint(0, self.tokenizer.vocab_size - 1))\n",
        "                else:\n",
        "                    # 10% chance to keep current token\n",
        "                    pass\n",
        "\n",
        "                masked_tokens[i] = token\n",
        "\n",
        "        return masked_tokens, labels\n",
        "\n",
        "\n",
        "@registry.register_task('language_modeling')\n",
        "class LanguageModelingDataset(Dataset):\n",
        "    \"\"\"Creates the Language Modeling Pfam Dataset\n",
        "    Args:\n",
        "        data_path (Union[str, Path]): Path to tape data root.\n",
        "        split (str): One of ['train', 'valid', 'holdout'], specifies which data file to load.\n",
        "        in_memory (bool, optional): Whether to load the full dataset into memory.\n",
        "            Default: False.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_path: Union[str, Path],\n",
        "                 split: str,\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False):\n",
        "        super().__init__()\n",
        "        if split not in ('train', 'valid', 'holdout'):\n",
        "            raise ValueError(\n",
        "                f\"Unrecognized split: {split}. \"\n",
        "                f\"Must be one of ['train', 'valid', 'holdout']\")\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        data_path = Path(data_path)\n",
        "        data_file = f'pfam/pfam_{split}.lmdb'\n",
        "        self.data = dataset_factory(data_path / data_file, in_memory)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        token_ids = self.tokenizer.encode(item['primary'])\n",
        "        input_mask = np.ones_like(token_ids)\n",
        "\n",
        "        return token_ids, input_mask, item['clan'], item['family']\n",
        "\n",
        "    def collate_fn(self, batch: List[Any]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, input_mask, clan, family = tuple(zip(*batch))\n",
        "\n",
        "        torch_inputs = torch.from_numpy(pad_sequences(input_ids, 0))\n",
        "        input_mask = torch.from_numpy(pad_sequences(input_mask, 0))\n",
        "        # ignore_index is -1\n",
        "        torch_labels = torch.from_numpy(pad_sequences(input_ids, -1))\n",
        "        clan = torch.LongTensor(clan)  # type: ignore\n",
        "        family = torch.LongTensor(family)  # type: ignore\n",
        "\n",
        "        return {'input_ids': torch_inputs,\n",
        "                'input_mask': input_mask,\n",
        "                'targets': torch_labels}\n",
        "\n",
        "\n",
        "@registry.register_task('fluorescence')\n",
        "class FluorescenceDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_path: Union[str, Path],\n",
        "                 split: str,\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False):\n",
        "\n",
        "        if split not in ('train', 'valid', 'test'):\n",
        "            raise ValueError(f\"Unrecognized split: {split}. \"\n",
        "                             f\"Must be one of ['train', 'valid', 'test']\")\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        data_path = Path(data_path)\n",
        "        data_file = f'fluorescence/fluorescence_{split}.lmdb'\n",
        "        self.data = dataset_factory(data_path / data_file, in_memory)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "        # return int(len(self.data) / 4)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        item = self.data[index]\n",
        "        token_ids = self.tokenizer.encode(item['primary'])\n",
        "        input_mask = np.ones_like(token_ids)\n",
        "        return token_ids, input_mask, float(item['log_fluorescence'][0])\n",
        "\n",
        "    def collate_fn(self, batch: List[Tuple[Any, ...]]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, input_mask, fluorescence_true_value = tuple(zip(*batch))\n",
        "        input_ids = torch.from_numpy(pad_sequences(input_ids, 0))\n",
        "        input_mask = torch.from_numpy(pad_sequences(input_mask, 0))\n",
        "        fluorescence_true_value = torch.FloatTensor(fluorescence_true_value)  # type: ignore\n",
        "        fluorescence_true_value = fluorescence_true_value.unsqueeze(1)\n",
        "\n",
        "        return {'input_ids': input_ids,\n",
        "                'input_mask': input_mask,\n",
        "                'targets': fluorescence_true_value}\n",
        "\n",
        "\n",
        "@registry.register_task('stability')\n",
        "class StabilityDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_path: Union[str, Path],\n",
        "                 split: str,\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False):\n",
        "\n",
        "        if split not in ('train', 'valid', 'test'):\n",
        "            raise ValueError(f\"Unrecognized split: {split}. \"\n",
        "                             f\"Must be one of ['train', 'valid', 'test']\")\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        data_path = Path(data_path)\n",
        "        data_file = f'stability/stability_{split}.lmdb'\n",
        "\n",
        "        self.data = dataset_factory(data_path / data_file, in_memory)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "        # return int(len(self.data) / 4)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        item = self.data[index]\n",
        "        token_ids = self.tokenizer.encode(item['primary'])\n",
        "        input_mask = np.ones_like(token_ids)\n",
        "        return token_ids, input_mask, float(item['stability_score'][0])\n",
        "\n",
        "    def collate_fn(self, batch: List[Tuple[Any, ...]]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, input_mask, stability_true_value = tuple(zip(*batch))\n",
        "        input_ids = torch.from_numpy(pad_sequences(input_ids, 0))\n",
        "        input_mask = torch.from_numpy(pad_sequences(input_mask, 0))\n",
        "        stability_true_value = torch.FloatTensor(stability_true_value)  # type: ignore\n",
        "        stability_true_value = stability_true_value.unsqueeze(1)\n",
        "\n",
        "        return {'input_ids': input_ids,\n",
        "                'input_mask': input_mask,\n",
        "                'targets': stability_true_value}\n",
        "\n",
        "\n",
        "@registry.register_task('remote_homology', num_labels=1195)\n",
        "class RemoteHomologyDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_path: Union[str, Path],\n",
        "                 split: str,\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False):\n",
        "\n",
        "        if split not in ('train', 'valid', 'test_fold_holdout',\n",
        "                         'test_family_holdout', 'test_superfamily_holdout'):\n",
        "            raise ValueError(f\"Unrecognized split: {split}. Must be one of \"\n",
        "                             f\"['train', 'valid', 'test_fold_holdout', \"\n",
        "                             f\"'test_family_holdout', 'test_superfamily_holdout']\")\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        data_path = Path(data_path)\n",
        "        data_file = f'remote_homology/remote_homology_{split}.lmdb'\n",
        "        self.data = dataset_factory(data_path / data_file, in_memory)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "        # return int(len(self.data) / 4)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        item = self.data[index]\n",
        "        token_ids = self.tokenizer.encode(item['primary'])\n",
        "        input_mask = np.ones_like(token_ids)\n",
        "        return token_ids, input_mask, item['fold_label']\n",
        "\n",
        "    def collate_fn(self, batch: List[Tuple[Any, ...]]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, input_mask, fold_label = tuple(zip(*batch))\n",
        "        input_ids = torch.from_numpy(pad_sequences(input_ids, 0))\n",
        "        input_mask = torch.from_numpy(pad_sequences(input_mask, 0))\n",
        "        fold_label = torch.LongTensor(fold_label)  # type: ignore\n",
        "\n",
        "        return {'input_ids': input_ids,\n",
        "                'input_mask': input_mask,\n",
        "                'targets': fold_label}\n",
        "\n",
        "\n",
        "@registry.register_task('contact_prediction')\n",
        "class ProteinnetDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_path: Union[str, Path],\n",
        "                 split: str,\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False):\n",
        "\n",
        "        if split not in ('train', 'train_unfiltered', 'valid', 'test'):\n",
        "            raise ValueError(f\"Unrecognized split: {split}. Must be one of \"\n",
        "                             f\"['train', 'train_unfiltered', 'valid', 'test']\")\n",
        "\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        data_path = Path(data_path)\n",
        "        data_file = f'proteinnet/proteinnet_{split}.lmdb'\n",
        "        self.data = dataset_factory(data_path / data_file, in_memory)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        # return len(self.data)\n",
        "        return int(len(self.data) / 4)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        item = self.data[index]\n",
        "        protein_length = len(item['primary'])\n",
        "        token_ids = self.tokenizer.encode(item['primary'])\n",
        "        input_mask = np.ones_like(token_ids)\n",
        "\n",
        "        valid_mask = item['valid_mask']\n",
        "        contact_map = np.less(squareform(pdist(item['tertiary'])), 8.0).astype(np.int64)\n",
        "\n",
        "        yind, xind = np.indices(contact_map.shape)\n",
        "        invalid_mask = ~(valid_mask[:, None] & valid_mask[None, :])\n",
        "        invalid_mask |= np.abs(yind - xind) < 6\n",
        "        contact_map[invalid_mask] = -1\n",
        "\n",
        "        return token_ids, input_mask, contact_map, protein_length\n",
        "\n",
        "    def collate_fn(self, batch: List[Tuple[Any, ...]]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, input_mask, contact_labels, protein_length = tuple(zip(*batch))\n",
        "        input_ids = torch.from_numpy(pad_sequences(input_ids, 0))\n",
        "        input_mask = torch.from_numpy(pad_sequences(input_mask, 0))\n",
        "        contact_labels = torch.from_numpy(pad_sequences(contact_labels, -1))\n",
        "        protein_length = torch.LongTensor(protein_length)  # type: ignore\n",
        "\n",
        "        return {'input_ids': input_ids,\n",
        "                'input_mask': input_mask,\n",
        "                'targets': contact_labels,\n",
        "                'protein_length': protein_length}\n",
        "\n",
        "\n",
        "@registry.register_task('secondary_structure', num_labels=3)\n",
        "class SecondaryStructureDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_path: Union[str, Path],\n",
        "                 split: str,\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False):\n",
        "\n",
        "        if split not in ('train', 'valid', 'casp12', 'ts115', 'cb513'):\n",
        "            raise ValueError(f\"Unrecognized split: {split}. Must be one of \"\n",
        "                             f\"['train', 'valid', 'casp12', \"\n",
        "                             f\"'ts115', 'cb513']\")\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        data_path = Path(data_path)\n",
        "        data_file = f'secondary_structure/secondary_structure_{split}.lmdb'\n",
        "        self.data = dataset_factory(data_path / data_file, in_memory)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data)\n",
        "        # return int(len(self.data) / 4)\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        item = self.data[index]\n",
        "        token_ids = self.tokenizer.encode(item['primary'])\n",
        "        input_mask = np.ones_like(token_ids)\n",
        "\n",
        "        # pad with -1s because of cls/sep tokens\n",
        "        labels = np.asarray(item['ss3'], np.int64)\n",
        "        labels = np.pad(labels, (1, 1), 'constant', constant_values=-1)\n",
        "\n",
        "        return token_ids, input_mask, labels\n",
        "\n",
        "    def collate_fn(self, batch: List[Tuple[Any, ...]]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, input_mask, ss_label = tuple(zip(*batch))\n",
        "        input_ids = torch.from_numpy(pad_sequences(input_ids, 0))\n",
        "        input_mask = torch.from_numpy(pad_sequences(input_mask, 0))\n",
        "        ss_label = torch.from_numpy(pad_sequences(ss_label, -1))\n",
        "\n",
        "        output = {'input_ids': input_ids,\n",
        "                  'input_mask': input_mask,\n",
        "                  'targets': ss_label}\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "@registry.register_task('trrosetta')\n",
        "class TRRosettaDataset(Dataset):\n",
        "\n",
        "    def __init__(self,\n",
        "                 data_path: Union[str, Path],\n",
        "                 split: str,\n",
        "                 tokenizer: Union[str, TAPETokenizer] = 'iupac',\n",
        "                 in_memory: bool = False,\n",
        "                 max_seqlen: int = 300):\n",
        "        if split not in ('train', 'valid'):\n",
        "            raise ValueError(\n",
        "                f\"Unrecognized split: {split}. \"\n",
        "                f\"Must be one of ['train', 'valid']\")\n",
        "        if isinstance(tokenizer, str):\n",
        "            tokenizer = TAPETokenizer(vocab=tokenizer)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        data_path = Path(data_path)\n",
        "        data_path = data_path / 'trrosetta'\n",
        "        split_files = (data_path / f'{split}_files.txt').read_text().split()\n",
        "        self.data = NPZDataset(data_path / 'npz', in_memory, split_files=split_files)\n",
        "\n",
        "        self._dist_bins = np.arange(2, 20.1, 0.5)\n",
        "        self._dihedral_bins = (15 + np.arange(-180, 180, 15)) / 180 * np.pi\n",
        "        self._planar_bins = (15 + np.arange(0, 180, 15)) / 180 * np.pi\n",
        "        self._split = split\n",
        "        self.max_seqlen = max_seqlen\n",
        "        self.msa_cutoff = 0.8\n",
        "        self.penalty_coeff = 4.5\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        # return len(self.data)\n",
        "        return int(len(self.data) / 4)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "\n",
        "        msa = item['msa']\n",
        "        dist = item['dist6d']\n",
        "        omega = item['omega6d']\n",
        "        theta = item['theta6d']\n",
        "        phi = item['phi6d']\n",
        "\n",
        "        if self._split == 'train':\n",
        "            msa = self._subsample_msa(msa)\n",
        "        elif self._split == 'valid':\n",
        "            msa = msa[:20000]  # runs out of memory if msa is way too big\n",
        "        msa, dist, omega, theta, phi = self._slice_long_sequences(\n",
        "            msa, dist, omega, theta, phi)\n",
        "\n",
        "        mask = dist == 0\n",
        "\n",
        "        dist_bins = np.digitize(dist, self._dist_bins)\n",
        "        omega_bins = np.digitize(omega, self._dihedral_bins) + 1\n",
        "        theta_bins = np.digitize(theta, self._dihedral_bins) + 1\n",
        "        phi_bins = np.digitize(phi, self._planar_bins) + 1\n",
        "\n",
        "        dist_bins[mask] = 0\n",
        "        omega_bins[mask] = 0\n",
        "        theta_bins[mask] = 0\n",
        "        phi_bins[mask] = 0\n",
        "\n",
        "        dist_bins[np.diag_indices_from(dist_bins)] = -1\n",
        "\n",
        "        # input_mask = np.ones_like(msa[0])\n",
        "\n",
        "        return msa, dist_bins, omega_bins, theta_bins, phi_bins\n",
        "\n",
        "    def _slice_long_sequences(self, msa, dist, omega, theta, phi):\n",
        "        seqlen = msa.shape[1]\n",
        "        if self.max_seqlen > 0 and seqlen > self.max_seqlen:\n",
        "            start = np.random.randint(seqlen - self.max_seqlen + 1)\n",
        "            end = start + self.max_seqlen\n",
        "\n",
        "            msa = msa[:, start:end]\n",
        "            dist = dist[start:end, start:end]\n",
        "            omega = omega[start:end, start:end]\n",
        "            theta = theta[start:end, start:end]\n",
        "            phi = phi[start:end, start:end]\n",
        "\n",
        "        return msa, dist, omega, theta, phi\n",
        "\n",
        "    def _subsample_msa(self, msa):\n",
        "        num_alignments, seqlen = msa.shape\n",
        "\n",
        "        if num_alignments < 10:\n",
        "            return msa\n",
        "\n",
        "        num_sample = int(10 ** np.random.uniform(np.log10(num_alignments)) - 10)\n",
        "\n",
        "        if num_sample <= 0:\n",
        "            return msa[0][None, :]\n",
        "        elif num_sample > 20000:\n",
        "            num_sample = 20000\n",
        "\n",
        "        indices = np.random.choice(\n",
        "            msa.shape[0] - 1, size=num_sample, replace=False) + 1\n",
        "        indices = np.pad(indices, [1, 0], 'constant')  # add the sequence back in\n",
        "        return msa[indices]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        msa, dist_bins, omega_bins, theta_bins, phi_bins = tuple(zip(*batch))\n",
        "        # features = pad_sequences([self.featurize(msa_) for msa_ in msa], 0)\n",
        "        msa1hot = pad_sequences(\n",
        "            [F.one_hot(torch.LongTensor(msa_), 21) for msa_ in msa], 0, torch.float)\n",
        "        # input_mask = torch.FloatTensor(pad_sequences(input_mask, 0))\n",
        "        dist_bins = torch.LongTensor(pad_sequences(dist_bins, -1))\n",
        "        omega_bins = torch.LongTensor(pad_sequences(omega_bins, 0))\n",
        "        theta_bins = torch.LongTensor(pad_sequences(theta_bins, 0))\n",
        "        phi_bins = torch.LongTensor(pad_sequences(phi_bins, 0))\n",
        "\n",
        "        return {'msa1hot': msa1hot,\n",
        "                # 'input_mask': input_mask,\n",
        "                'dist': dist_bins,\n",
        "                'omega': omega_bins,\n",
        "                'theta': theta_bins,\n",
        "                'phi': phi_bins}\n",
        "\n",
        "    def featurize(self, msa):\n",
        "        msa = torch.LongTensor(msa)\n",
        "        msa1hot = F.one_hot(msa, 21).float()\n",
        "\n",
        "        seqlen = msa1hot.size(1)\n",
        "\n",
        "        weights = self.reweight(msa1hot)\n",
        "        features_1d = self.extract_features_1d(msa1hot, weights)\n",
        "        features_2d = self.extract_features_2d(msa1hot, weights)\n",
        "\n",
        "        features = torch.cat((\n",
        "            features_1d.unsqueeze(1).repeat(1, seqlen, 1),\n",
        "            features_1d.unsqueeze(0).repeat(seqlen, 1, 1),\n",
        "            features_2d), -1)\n",
        "\n",
        "        features = features.permute(2, 0, 1)\n",
        "\n",
        "        return features\n",
        "\n",
        "    def reweight(self, msa1hot):\n",
        "        # Reweight\n",
        "        seqlen = msa1hot.size(1)\n",
        "        id_min = seqlen * self.msa_cutoff\n",
        "        id_mtx = torch.tensordot(msa1hot, msa1hot, [[1, 2], [1, 2]])\n",
        "        id_mask = id_mtx > id_min\n",
        "        weights = 1.0 / id_mask.float().sum(-1)\n",
        "        return weights\n",
        "\n",
        "    def extract_features_1d(self, msa1hot, weights):\n",
        "        # 1D Features\n",
        "        seqlen = msa1hot.size(1)\n",
        "        f1d_seq = msa1hot[0, :, :20]\n",
        "\n",
        "        # msa2pssm\n",
        "        beff = weights.sum()\n",
        "        f_i = (weights[:, None, None] * msa1hot).sum(0) / beff + 1e-9\n",
        "        h_i = (-f_i * f_i.log()).sum(1, keepdims=True)\n",
        "        f1d_pssm = torch.cat((f_i, h_i), dim=1)\n",
        "\n",
        "        f1d = torch.cat((f1d_seq, f1d_pssm), dim=1)\n",
        "        f1d = f1d.view(seqlen, 42)\n",
        "        return f1d\n",
        "\n",
        "    def extract_features_2d(self, msa1hot, weights):\n",
        "        # 2D Features\n",
        "        num_alignments = msa1hot.size(0)\n",
        "        seqlen = msa1hot.size(1)\n",
        "        num_symbols = 21\n",
        "        if num_alignments == 1:\n",
        "            # No alignments, predict from sequence alone\n",
        "            f2d_dca = torch.zeros(seqlen, seqlen, 442, dtype=torch.float)\n",
        "        else:\n",
        "            # fast_dca\n",
        "\n",
        "            # covariance\n",
        "            x = msa1hot.view(num_alignments, seqlen * num_symbols)\n",
        "            num_points = weights.sum() - weights.mean().sqrt()\n",
        "            mean = (x * weights[:, None]).sum(0, keepdims=True) / num_points\n",
        "            x = (x - mean) * weights[:, None].sqrt()\n",
        "            cov = torch.matmul(x.transpose(-1, -2), x) / num_points\n",
        "\n",
        "            # inverse covariance\n",
        "            reg = torch.eye(seqlen * num_symbols) * self.penalty_coeff / weights.sum().sqrt()\n",
        "            cov_reg = cov + reg\n",
        "            inv_cov = torch.inverse(cov_reg)\n",
        "\n",
        "            x1 = inv_cov.view(seqlen, num_symbols, seqlen, num_symbols)\n",
        "            x2 = x1.permute(0, 2, 1, 3)\n",
        "            features = x2.reshape(seqlen, seqlen, num_symbols * num_symbols)\n",
        "\n",
        "            x3 = (x1[:, :-1, :, :-1] ** 2).sum((1, 3)).sqrt() * (1 - torch.eye(seqlen))\n",
        "            apc = x3.sum(0, keepdims=True) * x3.sum(1, keepdims=True) / x3.sum()\n",
        "            contacts = (x3 - apc) * (1 - torch.eye(seqlen))\n",
        "\n",
        "            f2d_dca = torch.cat([features, contacts[:, :, None]], axis=2)\n",
        "\n",
        "        return f2d_dca\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /usr/local/lib/python3.6/dist-packages/tape/datasets.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5rSuCxsfovZ",
        "outputId": "68299ef7-6a4e-4d06-dd11-b5da21f2fd5d"
      },
      "source": [
        "%%writefile /usr/local/lib/python3.6/dist-packages/tape/models/modeling_resnet.py\n",
        "\n",
        "import typing\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from .modeling_utils import ProteinConfig\n",
        "from .modeling_utils import ProteinModel\n",
        "from .modeling_utils import get_activation_fn\n",
        "from .modeling_utils import MLMHead\n",
        "from .modeling_utils import LayerNorm\n",
        "from .modeling_utils import ValuePredictionHead\n",
        "from .modeling_utils import SequenceClassificationHead\n",
        "from .modeling_utils import SequenceToSequenceClassificationHead\n",
        "from .modeling_utils import PairwiseContactPredictionHead\n",
        "from ..registry import registry\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "RESNET_PRETRAINED_CONFIG_ARCHIVE_MAP: typing.Dict[str, str] = {}\n",
        "RESNET_PRETRAINED_MODEL_ARCHIVE_MAP: typing.Dict[str, str] = {}\n",
        "\n",
        "\n",
        "class ProteinResNetConfig(ProteinConfig):\n",
        "    pretrained_config_archive_map = RESNET_PRETRAINED_CONFIG_ARCHIVE_MAP\n",
        "\n",
        "    def __init__(self,\n",
        "                 vocab_size: int = 30,\n",
        "                 hidden_size: int = 32, # hidden_size: int = 512,\n",
        "                 num_hidden_layers: int = 3, #num_hidden_layers: int = 30,\n",
        "                 hidden_act: str = \"gelu\",\n",
        "                 hidden_dropout_prob: float = 0.1,\n",
        "                 initializer_range: float = 0.02,\n",
        "                 layer_norm_eps: float = 1e-12,\n",
        "                 **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.vocab_size = vocab_size\n",
        "        self.num_hidden_layers = num_hidden_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_act = hidden_act\n",
        "        self.hidden_dropout_prob = hidden_dropout_prob\n",
        "        self.initializer_range = initializer_range\n",
        "        self.layer_norm_eps = layer_norm_eps\n",
        "\n",
        "\n",
        "class MaskedConv1d(nn.Conv1d):\n",
        "\n",
        "    def forward(self, x, input_mask=None):\n",
        "        if input_mask is not None:\n",
        "            x = x * input_mask\n",
        "        return super().forward(x)\n",
        "\n",
        "\n",
        "class ProteinResNetLayerNorm(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.norm = LayerNorm(config.hidden_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.norm(x.transpose(1, 2)).transpose(1, 2)\n",
        "\n",
        "\n",
        "class ProteinResNetBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.conv1 = MaskedConv1d(\n",
        "            config.hidden_size, config.hidden_size, 3, padding=1, bias=False)\n",
        "        # self.bn1 = nn.BatchNorm1d(config.hidden_size)\n",
        "        self.bn1 = ProteinResNetLayerNorm(config)\n",
        "        self.conv2 = MaskedConv1d(\n",
        "            config.hidden_size, config.hidden_size, 3, padding=1, bias=False)\n",
        "        # self.bn2 = nn.BatchNorm1d(config.hidden_size)\n",
        "        self.bn2 = ProteinResNetLayerNorm(config)\n",
        "        self.activation_fn = get_activation_fn(config.hidden_act)\n",
        "\n",
        "    def forward(self, x, input_mask=None):\n",
        "        identity = x\n",
        "\n",
        "        out = self.conv1(x, input_mask)\n",
        "        out = self.bn1(out)\n",
        "        out = self.activation_fn(out)\n",
        "\n",
        "        out = self.conv2(out, input_mask)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.activation_fn(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ProteinResNetEmbeddings(nn.Module):\n",
        "    \"\"\"Construct the embeddings from word, position and token_type embeddings.\n",
        "    \"\"\"\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        embed_dim = config.hidden_size\n",
        "        self.word_embeddings = nn.Embedding(config.vocab_size, embed_dim, padding_idx=0)\n",
        "        inverse_frequency = 1 / (10000 ** (torch.arange(0.0, embed_dim, 2.0) / embed_dim))\n",
        "        self.register_buffer('inverse_frequency', inverse_frequency)\n",
        "\n",
        "        self.layer_norm = LayerNorm(embed_dim, eps=config.layer_norm_eps)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        words_embeddings = self.word_embeddings(input_ids)\n",
        "\n",
        "        seq_length = input_ids.size(1)\n",
        "        position_ids = torch.arange(\n",
        "            seq_length - 1, -1, -1.0,\n",
        "            dtype=words_embeddings.dtype,\n",
        "            device=words_embeddings.device)\n",
        "        sinusoidal_input = torch.ger(position_ids, self.inverse_frequency)\n",
        "        position_embeddings = torch.cat([sinusoidal_input.sin(), sinusoidal_input.cos()], -1)\n",
        "        position_embeddings = position_embeddings.unsqueeze(0)\n",
        "\n",
        "        embeddings = words_embeddings + position_embeddings\n",
        "        embeddings = self.layer_norm(embeddings)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class ProteinResNetPooler(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.attention_weights = nn.Linear(config.hidden_size, 1)\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, hidden_states, mask=None):\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        attention_scores = self.attention_weights(hidden_states)\n",
        "        if mask is not None:\n",
        "            attention_scores += -10000. * (1 - mask)\n",
        "        attention_weights = torch.softmax(attention_scores, -1)\n",
        "        weighted_mean_embedding = torch.matmul(\n",
        "            hidden_states.transpose(1, 2), attention_weights).squeeze(2)\n",
        "        pooled_output = self.dense(weighted_mean_embedding)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        return pooled_output\n",
        "\n",
        "\n",
        "class ResNetEncoder(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.output_hidden_states = config.output_hidden_states\n",
        "        self.layer = nn.ModuleList(\n",
        "            [ProteinResNetBlock(config) for _ in range(config.num_hidden_layers)])\n",
        "\n",
        "    def forward(self, hidden_states, input_mask=None):\n",
        "        all_hidden_states = ()\n",
        "        for layer_module in self.layer:\n",
        "            if self.output_hidden_states:\n",
        "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "            hidden_states = layer_module(hidden_states, input_mask)\n",
        "\n",
        "        if self.output_hidden_states:\n",
        "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
        "\n",
        "        outputs = (hidden_states,)\n",
        "        if self.output_hidden_states:\n",
        "            outputs = outputs + (all_hidden_states,)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class ProteinResNetAbstractModel(ProteinModel):\n",
        "    \"\"\" An abstract class to handle weights initialization and\n",
        "        a simple interface for dowloading and loading pretrained models.\n",
        "    \"\"\"\n",
        "    config_class = ProteinResNetConfig\n",
        "    pretrained_model_archive_map = RESNET_PRETRAINED_MODEL_ARCHIVE_MAP\n",
        "    base_model_prefix = \"resnet\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        \"\"\" Initialize the weights \"\"\"\n",
        "        if isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "        elif isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, nn.Conv1d):\n",
        "            nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        # elif isinstance(module, ProteinResNetBlock):\n",
        "            # nn.init.constant_(module.bn2.weight, 0)\n",
        "\n",
        "\n",
        "@registry.register_task_model('embed', 'resnet')\n",
        "class ProteinResNetModel(ProteinResNetAbstractModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.embeddings = ProteinResNetEmbeddings(config)\n",
        "        self.encoder = ResNetEncoder(config)\n",
        "        self.pooler = ProteinResNetPooler(config)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self,\n",
        "                input_ids,\n",
        "                input_mask=None):\n",
        "        if input_mask is not None and torch.any(input_mask != 1):\n",
        "            extended_input_mask = input_mask.unsqueeze(2)\n",
        "            # fp16 compatibility\n",
        "            extended_input_mask = extended_input_mask.to(\n",
        "                dtype=next(self.parameters()).dtype)\n",
        "        else:\n",
        "            extended_input_mask = None\n",
        "\n",
        "        embedding_output = self.embeddings(input_ids)\n",
        "        embedding_output = embedding_output.transpose(1, 2)\n",
        "        if extended_input_mask is not None:\n",
        "            extended_input_mask = extended_input_mask.transpose(1, 2)\n",
        "        encoder_outputs = self.encoder(embedding_output, extended_input_mask)\n",
        "        sequence_output = encoder_outputs[0]\n",
        "        sequence_output = sequence_output.transpose(1, 2).contiguous()\n",
        "        # sequence_output = encoder_outputs[0]\n",
        "        if extended_input_mask is not None:\n",
        "            extended_input_mask = extended_input_mask.transpose(1, 2)\n",
        "        pooled_output = self.pooler(sequence_output, extended_input_mask)\n",
        "\n",
        "        # add hidden_states and attentions if they are here\n",
        "        outputs = (sequence_output, pooled_output,) + encoder_outputs[1:]\n",
        "        return outputs  # sequence_output, pooled_output, (hidden_states)\n",
        "\n",
        "\n",
        "@registry.register_task_model('masked_language_modeling', 'resnet')\n",
        "class ProteinResNetForMaskedLM(ProteinResNetAbstractModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.resnet = ProteinResNetModel(config)\n",
        "        self.mlm = MLMHead(\n",
        "            config.hidden_size, config.vocab_size, config.hidden_act, config.layer_norm_eps,\n",
        "            ignore_index=-1)\n",
        "\n",
        "        self.init_weights()\n",
        "        self.tie_weights()\n",
        "\n",
        "    def tie_weights(self):\n",
        "        \"\"\" Make sure we are sharing the input and output embeddings.\n",
        "            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n",
        "        \"\"\"\n",
        "        self._tie_or_clone_weights(self.mlm.decoder,\n",
        "                                   self.resnet.embeddings.word_embeddings)\n",
        "\n",
        "    def forward(self,\n",
        "                input_ids,\n",
        "                input_mask=None,\n",
        "                targets=None):\n",
        "\n",
        "        outputs = self.resnet(input_ids, input_mask=input_mask)\n",
        "\n",
        "        sequence_output, pooled_output = outputs[:2]\n",
        "        outputs = self.mlm(sequence_output, targets) + outputs[2:]\n",
        "        # (loss), prediction_scores, (hidden_states), (attentions)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "@registry.register_task_model('fluorescence', 'resnet')\n",
        "@registry.register_task_model('stability', 'resnet')\n",
        "class ProteinResNetForValuePrediction(ProteinResNetAbstractModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.resnet = ProteinResNetModel(config)\n",
        "        self.predict = ValuePredictionHead(config.hidden_size)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids, input_mask=None, targets=None):\n",
        "\n",
        "        outputs = self.resnet(input_ids, input_mask=input_mask)\n",
        "\n",
        "        sequence_output, pooled_output = outputs[:2]\n",
        "        outputs = self.predict(pooled_output, targets) + outputs[2:]\n",
        "        # (loss), prediction_scores, (hidden_states), (attentions)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "@registry.register_task_model('remote_homology', 'resnet')\n",
        "class ProteinResNetForSequenceClassification(ProteinResNetAbstractModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.resnet = ProteinResNetModel(config)\n",
        "        self.classify = SequenceClassificationHead(config.hidden_size, config.num_labels)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids, input_mask=None, targets=None):\n",
        "\n",
        "        outputs = self.resnet(input_ids, input_mask=input_mask)\n",
        "\n",
        "        sequence_output, pooled_output = outputs[:2]\n",
        "        outputs = self.classify(pooled_output, targets) + outputs[2:]\n",
        "        # (loss), prediction_scores, (hidden_states), (attentions)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "@registry.register_task_model('secondary_structure', 'resnet')\n",
        "class ProteinResNetForSequenceToSequenceClassification(ProteinResNetAbstractModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.resnet = ProteinResNetModel(config)\n",
        "        self.classify = SequenceToSequenceClassificationHead(\n",
        "            config.hidden_size, config.num_labels, ignore_index=-1)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids, input_mask=None, targets=None):\n",
        "\n",
        "        outputs = self.resnet(input_ids, input_mask=input_mask)\n",
        "\n",
        "        sequence_output, pooled_output = outputs[:2]\n",
        "        outputs = self.classify(sequence_output, targets) + outputs[2:]\n",
        "        # (loss), prediction_scores, (hidden_states), (attentions)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "@registry.register_task_model('contact_prediction', 'resnet')\n",
        "class ProteinResNetForContactPrediction(ProteinResNetAbstractModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        self.resnet = ProteinResNetModel(config)\n",
        "        self.predict = PairwiseContactPredictionHead(config.hidden_size, ignore_index=-1)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def forward(self, input_ids, protein_length, input_mask=None, targets=None):\n",
        "\n",
        "        outputs = self.resnet(input_ids, input_mask=input_mask)\n",
        "\n",
        "        sequence_output, pooled_output = outputs[:2]\n",
        "        outputs = self.predict(sequence_output, protein_length, targets) + outputs[2:]\n",
        "        # (loss), prediction_scores, (hidden_states), (attentions)\n",
        "        return outputs\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /usr/local/lib/python3.6/dist-packages/tape/models/modeling_resnet.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR3SWU_uclI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc11fd2-9686-4d6b-f1f9-b5e295b169ab"
      },
      "source": [
        "!tape-train-distributed resnet contact_prediction --model_config_file /content/results/baseline_resnet/config.json --from_pretrained /content/results/pretrained2 --batch_size 150 --learning_rate 5e-4 --num_train_epochs 10 --warmup_steps 2 --gradient_accumulation_steps 100 --seed 1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/12/09 10:35:21 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/pretrained2/config.json\n",
            "20/12/09 10:35:21 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": -1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/12/09 10:35:21 - INFO - tape.models.modeling_utils -   loading weights file /content/results/pretrained2/pytorch_model.bin\n",
            "20/12/09 10:35:21 - INFO - tape.models.modeling_utils -   Weights of ProteinResNetForContactPrediction not initialized from pretrained model: ['embeddings.inverse_frequency', 'embeddings.word_embeddings.weight', 'embeddings.layer_norm.weight', 'embeddings.layer_norm.bias', 'encoder.layer.0.conv1.weight', 'encoder.layer.0.bn1.norm.weight', 'encoder.layer.0.bn1.norm.bias', 'encoder.layer.0.conv2.weight', 'encoder.layer.0.bn2.norm.weight', 'encoder.layer.0.bn2.norm.bias', 'encoder.layer.1.conv1.weight', 'encoder.layer.1.bn1.norm.weight', 'encoder.layer.1.bn1.norm.bias', 'encoder.layer.1.conv2.weight', 'encoder.layer.1.bn2.norm.weight', 'encoder.layer.1.bn2.norm.bias', 'encoder.layer.2.conv1.weight', 'encoder.layer.2.bn1.norm.weight', 'encoder.layer.2.bn1.norm.bias', 'encoder.layer.2.conv2.weight', 'encoder.layer.2.bn2.norm.weight', 'encoder.layer.2.bn2.norm.bias', 'pooler.attention_weights.weight', 'pooler.attention_weights.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "20/12/09 10:35:21 - INFO - tape.models.modeling_utils -   Weights from pretrained model not used in ProteinResNetForContactPrediction: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n",
            "20/12/09 10:35:21 - INFO - tape.visualization -   tensorboard file at: logs/contact_prediction_resnet_20-12-09-10-35-19_219648\n",
            "20/12/09 10:35:21 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/09 10:35:21 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/09 10:35:21 - WARNING - tape.visualization -   Cannot watch models when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/09 10:35:21 - INFO - tape.training -   device: cuda:0 n_gpu: 1, distributed_training: True, 16-bits training: False\n",
            "20/12/09 10:35:21 - INFO - tape.training -   ***** Running training *****\n",
            "20/12/09 10:35:21 - INFO - tape.training -     Num examples = 6324\n",
            "20/12/09 10:35:21 - INFO - tape.training -     Batch size = 150\n",
            "20/12/09 10:35:21 - INFO - tape.training -     Num epochs = 10\n",
            "20/12/09 10:35:21 - INFO - tape.training -     Num train steps = 421\n",
            "20/12/09 10:35:21 - INFO - tape.training -     Num parameters = 21059\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "20/12/09 10:36:21 - INFO - tape.training -   [Ep: 0.32][Iter: 20][Time: 60.07s][Loss: 0.32423][Precision_at_l5: 0.021263][LR: 0.00047852]\n",
            "20/12/09 10:37:16 - INFO - tape.training -   [Ep: 0.63][Iter: 40][Time: 54.98s][Loss: 0.20457][Precision_at_l5: 0.021948][LR: 0.00045465]\n",
            "20/12/09 10:38:12 - INFO - tape.training -   [Ep: 0.95][Iter: 60][Time: 55.27s][Loss: 0.15][Precision_at_l5: 0.020777][LR: 0.00043079]\n",
            "20/12/09 10:38:23 - INFO - tape.training -   Train: [Loss: 0.17041][Precision_at_l5: 0.021367]\n",
            "20/12/09 10:38:24 - INFO - tape.training -   Evaluation: [Loss: 0.1276][Precision_at_l5: 0.01217]\n",
            "20/12/09 10:38:24 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 10:38:24 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-09-10-35-19_219648\n",
            "20/12/09 10:39:14 - INFO - tape.training -   [Ep: 1.27][Iter: 80][Time: 50.61s][Loss: 0.12446][Precision_at_l5: 0.023341][LR: 0.00040692]\n",
            "20/12/09 10:40:15 - INFO - tape.training -   [Ep: 1.58][Iter: 100][Time: 60.07s][Loss: 0.12294][Precision_at_l5: 0.022595][LR: 0.00038305]\n",
            "20/12/09 10:41:11 - INFO - tape.training -   [Ep: 1.90][Iter: 120][Time: 55.99s][Loss: 0.11798][Precision_at_l5: 0.021673][LR: 0.00035919]\n",
            "20/12/09 10:41:29 - INFO - tape.training -   Train: [Loss: 0.12085][Precision_at_l5: 0.021719]\n",
            "20/12/09 10:41:30 - INFO - tape.training -   Evaluation: [Loss: 0.11808][Precision_at_l5: 0.02689]\n",
            "20/12/09 10:41:30 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 10:41:30 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-09-10-35-19_219648\n",
            "20/12/09 10:42:12 - INFO - tape.training -   [Ep: 2.22][Iter: 140][Time: 41.94s][Loss: 0.11831][Precision_at_l5: 0.02491][LR: 0.00033532]\n",
            "20/12/09 10:43:12 - INFO - tape.training -   [Ep: 2.54][Iter: 160][Time: 59.35s][Loss: 0.1207][Precision_at_l5: 0.024332][LR: 0.00031146]\n",
            "20/12/09 10:44:07 - INFO - tape.training -   [Ep: 2.85][Iter: 180][Time: 55.48s][Loss: 0.11757][Precision_at_l5: 0.023192][LR: 0.00028759]\n",
            "20/12/09 10:44:33 - INFO - tape.training -   Train: [Loss: 0.11787][Precision_at_l5: 0.024045]\n",
            "20/12/09 10:44:34 - INFO - tape.training -   Evaluation: [Loss: 0.11674][Precision_at_l5: 0.040527]\n",
            "20/12/09 10:44:34 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 10:44:34 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-09-10-35-19_219648\n",
            "20/12/09 10:45:07 - INFO - tape.training -   [Ep: 3.17][Iter: 200][Time: 32.34s][Loss: 0.11586][Precision_at_l5: 0.018129][LR: 0.00026372]\n",
            "20/12/09 10:46:04 - INFO - tape.training -   [Ep: 3.49][Iter: 220][Time: 57.87s][Loss: 0.11809][Precision_at_l5: 0.022246][LR: 0.00023986]\n",
            "20/12/09 10:46:59 - INFO - tape.training -   [Ep: 3.81][Iter: 240][Time: 54.38s][Loss: 0.11709][Precision_at_l5: 0.022976][LR: 0.00021599]\n",
            "20/12/09 10:47:34 - INFO - tape.training -   Train: [Loss: 0.11677][Precision_at_l5: 0.023653]\n",
            "20/12/09 10:47:35 - INFO - tape.training -   Evaluation: [Loss: 0.12154][Precision_at_l5: 0.03644]\n",
            "20/12/09 10:47:35 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 10:47:35 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-09-10-35-19_219648\n",
            "20/12/09 10:47:58 - INFO - tape.training -   [Ep: 4.13][Iter: 260][Time: 22.89s][Loss: 0.1175][Precision_at_l5: 0.025781][LR: 0.00019212]\n",
            "20/12/09 10:48:56 - INFO - tape.training -   [Ep: 4.44][Iter: 280][Time: 58.43s][Loss: 0.1177][Precision_at_l5: 0.024844][LR: 0.00016826]\n",
            "20/12/09 10:49:52 - INFO - tape.training -   [Ep: 4.76][Iter: 300][Time: 55.90s][Loss: 0.11628][Precision_at_l5: 0.024722][LR: 0.00014439]\n",
            "20/12/09 10:50:35 - INFO - tape.training -   Train: [Loss: 0.11588][Precision_at_l5: 0.024605]\n",
            "20/12/09 10:50:36 - INFO - tape.training -   Evaluation: [Loss: 0.11841][Precision_at_l5: 0.036241]\n",
            "20/12/09 10:50:36 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 10:50:36 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-09-10-35-19_219648\n",
            "20/12/09 10:50:51 - INFO - tape.training -   [Ep: 5.08][Iter: 320][Time: 15.11s][Loss: 0.11421][Precision_at_l5: 0.025758][LR: 0.00012053]\n",
            "20/12/09 10:51:51 - INFO - tape.training -   [Ep: 5.40][Iter: 340][Time: 59.70s][Loss: 0.1162][Precision_at_l5: 0.025218][LR: 9.6659e-05]\n",
            "20/12/09 10:52:44 - INFO - tape.training -   [Ep: 5.71][Iter: 360][Time: 53.31s][Loss: 0.11531][Precision_at_l5: 0.024397][LR: 7.2792e-05]\n",
            "20/12/09 10:53:36 - INFO - tape.training -   Train: [Loss: 0.11523][Precision_at_l5: 0.025187]\n",
            "20/12/09 10:53:37 - INFO - tape.training -   Evaluation: [Loss: 0.11469][Precision_at_l5: 0.043165]\n",
            "20/12/09 10:53:37 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 10:53:37 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-09-10-35-19_219648\n",
            "20/12/09 10:53:43 - INFO - tape.training -   [Ep: 6.03][Iter: 380][Time:  5.98s][Loss: 0.11132][Precision_at_l5: 0.032959][LR: 4.8926e-05]\n",
            "20/12/09 10:54:43 - INFO - tape.training -   [Ep: 6.35][Iter: 400][Time: 59.93s][Loss: 0.11397][Precision_at_l5: 0.028206][LR: 2.506e-05]\n",
            "20/12/09 10:55:40 - INFO - tape.training -   [Ep: 6.66][Iter: 420][Time: 57.58s][Loss: 0.1153][Precision_at_l5: 0.027036][LR: 1.1933e-06]\n",
            "20/12/09 10:56:37 - INFO - tape.training -   [Ep: 6.98][Iter: 440][Time: 57.01s][Loss: 0.11205][Precision_at_l5: 0.025706][LR: 0]\n",
            "20/12/09 10:56:42 - INFO - tape.training -   Train: [Loss: 0.11406][Precision_at_l5: 0.025962]\n",
            "20/12/09 10:56:44 - INFO - tape.training -   Evaluation: [Loss: 0.11533][Precision_at_l5: 0.043606]\n",
            "20/12/09 10:56:44 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 10:56:44 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-09-10-35-19_219648\n",
            "20/12/09 10:57:41 - INFO - tape.training -   [Ep: 7.30][Iter: 460][Time: 57.65s][Loss: 0.11356][Precision_at_l5: 0.02536][LR: 0]\n",
            "20/12/09 10:58:41 - INFO - tape.training -   [Ep: 7.62][Iter: 480][Time: 59.07s][Loss: 0.11604][Precision_at_l5: 0.024988][LR: 0]\n",
            "20/12/09 10:59:37 - INFO - tape.training -   [Ep: 7.93][Iter: 500][Time: 56.48s][Loss: 0.11183][Precision_at_l5: 0.024208][LR: 0]\n",
            "20/12/09 10:59:50 - INFO - tape.training -   Train: [Loss: 0.1141][Precision_at_l5: 0.025077]\n",
            "20/12/09 10:59:51 - INFO - tape.training -   Evaluation: [Loss: 0.11533][Precision_at_l5: 0.043606]\n",
            "20/12/09 10:59:51 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 10:59:51 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-09-10-35-19_219648\n",
            "20/12/09 11:00:39 - INFO - tape.training -   [Ep: 8.25][Iter: 520][Time: 48.20s][Loss: 0.11382][Precision_at_l5: 0.026343][LR: 0]\n",
            "20/12/09 11:01:40 - INFO - tape.training -   [Ep: 8.57][Iter: 540][Time: 60.67s][Loss: 0.11621][Precision_at_l5: 0.024811][LR: 0]\n",
            "20/12/09 11:02:36 - INFO - tape.training -   [Ep: 8.89][Iter: 560][Time: 56.06s][Loss: 0.11216][Precision_at_l5: 0.023483][LR: 0]\n",
            "20/12/09 11:02:57 - INFO - tape.training -   Train: [Loss: 0.11407][Precision_at_l5: 0.024202]\n",
            "20/12/09 11:02:58 - INFO - tape.training -   Evaluation: [Loss: 0.11533][Precision_at_l5: 0.043606]\n",
            "20/12/09 11:02:58 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:02:58 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-09-10-35-19_219648\n",
            "20/12/09 11:03:37 - INFO - tape.training -   [Ep: 9.21][Iter: 580][Time: 38.85s][Loss: 0.11313][Precision_at_l5: 0.028956][LR: 0]\n",
            "20/12/09 11:04:37 - INFO - tape.training -   [Ep: 9.52][Iter: 600][Time: 60.13s][Loss: 0.1157][Precision_at_l5: 0.026797][LR: 0]\n",
            "20/12/09 11:05:34 - INFO - tape.training -   [Ep: 9.84][Iter: 620][Time: 56.62s][Loss: 0.11367][Precision_at_l5: 0.024557][LR: 0]\n",
            "20/12/09 11:06:04 - INFO - tape.training -   Train: [Loss: 0.11405][Precision_at_l5: 0.024844]\n",
            "20/12/09 11:06:06 - INFO - tape.training -   Evaluation: [Loss: 0.11533][Precision_at_l5: 0.043606]\n",
            "20/12/09 11:06:06 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:06:06 - INFO - tape.training -   Saving model checkpoint to results/contact_prediction_resnet_20-12-09-10-35-19_219648\n",
            "20/12/09 11:06:06 - INFO - tape.training -   Finished training after 10 epochs.\n",
            "20/12/09 11:06:06 - Level 35 - tape.training -   Best Val Loss: 0.11469265073537827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLJBAn-qfDjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173d959f-450f-4427-eda2-0a5f41911d7b"
      },
      "source": [
        "!tape-eval resnet contact_prediction /content/results/contact_prediction_resnet_20-12-09-10-35-19_219648 --metrics accuracy "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/12/09 11:06:28 - INFO - tape.training -   device: cuda n_gpu: 1\n",
            "20/12/09 11:06:28 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/contact_prediction_resnet_20-12-09-10-35-19_219648/config.json\n",
            "20/12/09 11:06:28 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": -1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/12/09 11:06:28 - INFO - tape.models.modeling_utils -   loading weights file /content/results/contact_prediction_resnet_20-12-09-10-35-19_219648/pytorch_model.bin\n",
            "Evaluation: 100% 1/1 [00:00<00:00,  1.90it/s]\n",
            "20/12/09 11:06:31 - INFO - tape.training -   accuracy: 0.985771855221519\n",
            "{'accuracy': 0.985771855221519}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwqwkYKBclLT",
        "outputId": "1b34f28a-4247-4a66-b7a6-cd28eac5c6d5"
      },
      "source": [
        "!tape-train-distributed resnet fluorescence --model_config_file /content/results/baseline_resnet/config.json --from_pretrained /content/results/pretrained2 --batch_size 150 --learning_rate 5e-4 --num_train_epochs 10 --warmup_steps 2 --gradient_accumulation_steps 50 --seed 1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/12/09 11:06:45 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/pretrained2/config.json\n",
            "20/12/09 11:06:45 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": -1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/12/09 11:06:45 - INFO - tape.models.modeling_utils -   loading weights file /content/results/pretrained2/pytorch_model.bin\n",
            "20/12/09 11:06:45 - INFO - tape.models.modeling_utils -   Weights of ProteinResNetForValuePrediction not initialized from pretrained model: ['embeddings.inverse_frequency', 'embeddings.word_embeddings.weight', 'embeddings.layer_norm.weight', 'embeddings.layer_norm.bias', 'encoder.layer.0.conv1.weight', 'encoder.layer.0.bn1.norm.weight', 'encoder.layer.0.bn1.norm.bias', 'encoder.layer.0.conv2.weight', 'encoder.layer.0.bn2.norm.weight', 'encoder.layer.0.bn2.norm.bias', 'encoder.layer.1.conv1.weight', 'encoder.layer.1.bn1.norm.weight', 'encoder.layer.1.bn1.norm.bias', 'encoder.layer.1.conv2.weight', 'encoder.layer.1.bn2.norm.weight', 'encoder.layer.1.bn2.norm.bias', 'encoder.layer.2.conv1.weight', 'encoder.layer.2.bn1.norm.weight', 'encoder.layer.2.bn1.norm.bias', 'encoder.layer.2.conv2.weight', 'encoder.layer.2.bn2.norm.weight', 'encoder.layer.2.bn2.norm.bias', 'pooler.attention_weights.weight', 'pooler.attention_weights.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "20/12/09 11:06:45 - INFO - tape.models.modeling_utils -   Weights from pretrained model not used in ProteinResNetForValuePrediction: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n",
            "20/12/09 11:06:45 - INFO - tape.visualization -   tensorboard file at: logs/fluorescence_resnet_20-12-09-11-06-43_034707\n",
            "20/12/09 11:06:45 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/09 11:06:45 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/09 11:06:45 - WARNING - tape.visualization -   Cannot watch models when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/09 11:06:45 - INFO - tape.training -   device: cuda:0 n_gpu: 1, distributed_training: True, 16-bits training: False\n",
            "20/12/09 11:06:45 - INFO - tape.training -   ***** Running training *****\n",
            "20/12/09 11:06:45 - INFO - tape.training -     Num examples = 21446\n",
            "20/12/09 11:06:45 - INFO - tape.training -     Batch size = 150\n",
            "20/12/09 11:06:45 - INFO - tape.training -     Num epochs = 10\n",
            "20/12/09 11:06:45 - INFO - tape.training -     Num train steps = 1429\n",
            "20/12/09 11:06:45 - INFO - tape.training -     Num parameters = 38340\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "20/12/09 11:07:01 - INFO - tape.training -   [Ep: 0.14][Iter: 20][Time: 15.96s][Loss: 8.2659][LR: 0.00049369]\n",
            "20/12/09 11:07:16 - INFO - tape.training -   [Ep: 0.28][Iter: 40][Time: 14.90s][Loss: 3.5104][LR: 0.00048669]\n",
            "20/12/09 11:07:32 - INFO - tape.training -   [Ep: 0.42][Iter: 60][Time: 15.93s][Loss: 1.7061][LR: 0.00047968]\n",
            "20/12/09 11:07:47 - INFO - tape.training -   [Ep: 0.56][Iter: 80][Time: 14.82s][Loss: 1.0862][LR: 0.00047267]\n",
            "20/12/09 11:08:01 - INFO - tape.training -   [Ep: 0.70][Iter: 100][Time: 14.60s][Loss: 0.82968][LR: 0.00046566]\n",
            "20/12/09 11:08:17 - INFO - tape.training -   [Ep: 0.84][Iter: 120][Time: 15.96s][Loss: 0.73385][LR: 0.00045865]\n",
            "20/12/09 11:08:32 - INFO - tape.training -   [Ep: 0.98][Iter: 140][Time: 15.29s][Loss: 0.73432][LR: 0.00045165]\n",
            "20/12/09 11:08:35 - INFO - tape.training -   Train: [Loss: 1.5709]\n",
            "20/12/09 11:08:49 - INFO - tape.training -   Evaluation: [Loss: 0.73678]\n",
            "20/12/09 11:08:49 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:08:49 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-09-11-06-43_034707\n",
            "20/12/09 11:09:03 - INFO - tape.training -   [Ep: 1.13][Iter: 160][Time: 13.46s][Loss: 0.75656][LR: 0.00044464]\n",
            "20/12/09 11:09:19 - INFO - tape.training -   [Ep: 1.27][Iter: 180][Time: 15.97s][Loss: 0.73281][LR: 0.00043763]\n",
            "20/12/09 11:09:35 - INFO - tape.training -   [Ep: 1.41][Iter: 200][Time: 15.88s][Loss: 0.69747][LR: 0.00043062]\n",
            "20/12/09 11:09:50 - INFO - tape.training -   [Ep: 1.55][Iter: 220][Time: 15.02s][Loss: 0.73043][LR: 0.00042362]\n",
            "20/12/09 11:10:05 - INFO - tape.training -   [Ep: 1.69][Iter: 240][Time: 15.05s][Loss: 0.70359][LR: 0.00041661]\n",
            "20/12/09 11:10:21 - INFO - tape.training -   [Ep: 1.83][Iter: 260][Time: 16.08s][Loss: 0.68629][LR: 0.0004096]\n",
            "20/12/09 11:10:36 - INFO - tape.training -   [Ep: 1.97][Iter: 280][Time: 14.76s][Loss: 0.69684][LR: 0.00040259]\n",
            "20/12/09 11:10:40 - INFO - tape.training -   Train: [Loss: 0.70656]\n",
            "20/12/09 11:10:54 - INFO - tape.training -   Evaluation: [Loss: 0.74848]\n",
            "20/12/09 11:10:54 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:10:54 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-09-11-06-43_034707\n",
            "20/12/09 11:11:06 - INFO - tape.training -   [Ep: 2.11][Iter: 300][Time: 12.30s][Loss: 0.70332][LR: 0.00039559]\n",
            "20/12/09 11:11:22 - INFO - tape.training -   [Ep: 2.25][Iter: 320][Time: 15.71s][Loss: 0.71796][LR: 0.00038858]\n",
            "20/12/09 11:11:37 - INFO - tape.training -   [Ep: 2.39][Iter: 340][Time: 15.61s][Loss: 0.70934][LR: 0.00038157]\n",
            "20/12/09 11:11:53 - INFO - tape.training -   [Ep: 2.53][Iter: 360][Time: 15.41s][Loss: 0.73953][LR: 0.00037456]\n",
            "20/12/09 11:12:08 - INFO - tape.training -   [Ep: 2.67][Iter: 380][Time: 14.91s][Loss: 0.71061][LR: 0.00036755]\n",
            "20/12/09 11:12:23 - INFO - tape.training -   [Ep: 2.81][Iter: 400][Time: 15.25s][Loss: 0.69472][LR: 0.00036055]\n",
            "20/12/09 11:12:38 - INFO - tape.training -   [Ep: 2.95][Iter: 420][Time: 15.45s][Loss: 0.70789][LR: 0.00035354]\n",
            "20/12/09 11:12:43 - INFO - tape.training -   Train: [Loss: 0.71278]\n",
            "20/12/09 11:12:58 - INFO - tape.training -   Evaluation: [Loss: 0.72096]\n",
            "20/12/09 11:12:58 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:12:58 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-09-11-06-43_034707\n",
            "20/12/09 11:13:08 - INFO - tape.training -   [Ep: 3.10][Iter: 440][Time: 10.63s][Loss: 0.72704][LR: 0.00034653]\n",
            "20/12/09 11:13:24 - INFO - tape.training -   [Ep: 3.24][Iter: 460][Time: 15.38s][Loss: 0.72901][LR: 0.00033952]\n",
            "20/12/09 11:13:40 - INFO - tape.training -   [Ep: 3.38][Iter: 480][Time: 15.83s][Loss: 0.71042][LR: 0.00033252]\n",
            "20/12/09 11:13:55 - INFO - tape.training -   [Ep: 3.52][Iter: 500][Time: 15.83s][Loss: 0.71659][LR: 0.00032551]\n",
            "20/12/09 11:14:10 - INFO - tape.training -   [Ep: 3.66][Iter: 520][Time: 15.06s][Loss: 0.69522][LR: 0.0003185]\n",
            "20/12/09 11:14:26 - INFO - tape.training -   [Ep: 3.80][Iter: 540][Time: 15.16s][Loss: 0.69258][LR: 0.00031149]\n",
            "20/12/09 11:14:41 - INFO - tape.training -   [Ep: 3.94][Iter: 560][Time: 15.40s][Loss: 0.70834][LR: 0.00030448]\n",
            "20/12/09 11:14:48 - INFO - tape.training -   Train: [Loss: 0.70203]\n",
            "20/12/09 11:15:02 - INFO - tape.training -   Evaluation: [Loss: 0.69897]\n",
            "20/12/09 11:15:02 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:15:02 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-09-11-06-43_034707\n",
            "20/12/09 11:15:12 - INFO - tape.training -   [Ep: 4.08][Iter: 580][Time:  9.54s][Loss: 0.70869][LR: 0.00029748]\n",
            "20/12/09 11:15:27 - INFO - tape.training -   [Ep: 4.22][Iter: 600][Time: 14.97s][Loss: 0.71421][LR: 0.00029047]\n",
            "20/12/09 11:15:42 - INFO - tape.training -   [Ep: 4.36][Iter: 620][Time: 15.19s][Loss: 0.70166][LR: 0.00028346]\n",
            "20/12/09 11:15:57 - INFO - tape.training -   [Ep: 4.50][Iter: 640][Time: 15.51s][Loss: 0.71169][LR: 0.00027645]\n",
            "20/12/09 11:16:12 - INFO - tape.training -   [Ep: 4.64][Iter: 660][Time: 15.13s][Loss: 0.6979][LR: 0.00026945]\n",
            "20/12/09 11:16:28 - INFO - tape.training -   [Ep: 4.78][Iter: 680][Time: 15.49s][Loss: 0.69635][LR: 0.00026244]\n",
            "20/12/09 11:16:43 - INFO - tape.training -   [Ep: 4.92][Iter: 700][Time: 15.17s][Loss: 0.70531][LR: 0.00025543]\n",
            "20/12/09 11:16:51 - INFO - tape.training -   Train: [Loss: 0.70034]\n",
            "20/12/09 11:17:07 - INFO - tape.training -   Evaluation: [Loss: 0.7033]\n",
            "20/12/09 11:17:07 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:17:07 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-09-11-06-43_034707\n",
            "20/12/09 11:17:14 - INFO - tape.training -   [Ep: 5.07][Iter: 720][Time:  7.62s][Loss: 0.72418][LR: 0.00024842]\n",
            "20/12/09 11:17:30 - INFO - tape.training -   [Ep: 5.21][Iter: 740][Time: 15.63s][Loss: 0.71516][LR: 0.00024142]\n",
            "20/12/09 11:17:45 - INFO - tape.training -   [Ep: 5.35][Iter: 760][Time: 14.99s][Loss: 0.70462][LR: 0.00023441]\n",
            "20/12/09 11:18:01 - INFO - tape.training -   [Ep: 5.49][Iter: 780][Time: 15.88s][Loss: 0.7149][LR: 0.0002274]\n",
            "20/12/09 11:18:16 - INFO - tape.training -   [Ep: 5.63][Iter: 800][Time: 14.88s][Loss: 0.69365][LR: 0.00022039]\n",
            "20/12/09 11:18:30 - INFO - tape.training -   [Ep: 5.77][Iter: 820][Time: 14.82s][Loss: 0.71209][LR: 0.00021338]\n",
            "20/12/09 11:18:45 - INFO - tape.training -   [Ep: 5.91][Iter: 840][Time: 14.75s][Loss: 0.70227][LR: 0.00020638]\n",
            "20/12/09 11:18:55 - INFO - tape.training -   Train: [Loss: 0.69932]\n",
            "20/12/09 11:19:10 - INFO - tape.training -   Evaluation: [Loss: 0.69876]\n",
            "20/12/09 11:19:10 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:19:10 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-09-11-06-43_034707\n",
            "20/12/09 11:19:16 - INFO - tape.training -   [Ep: 6.06][Iter: 860][Time:  6.36s][Loss: 0.7318][LR: 0.00019937]\n",
            "20/12/09 11:19:32 - INFO - tape.training -   [Ep: 6.20][Iter: 880][Time: 15.36s][Loss: 0.71589][LR: 0.00019236]\n",
            "20/12/09 11:19:46 - INFO - tape.training -   [Ep: 6.34][Iter: 900][Time: 14.94s][Loss: 0.71119][LR: 0.00018535]\n",
            "20/12/09 11:20:02 - INFO - tape.training -   [Ep: 6.48][Iter: 920][Time: 15.98s][Loss: 0.71895][LR: 0.00017835]\n",
            "20/12/09 11:20:18 - INFO - tape.training -   [Ep: 6.62][Iter: 940][Time: 15.35s][Loss: 0.70955][LR: 0.00017134]\n",
            "20/12/09 11:20:32 - INFO - tape.training -   [Ep: 6.76][Iter: 960][Time: 14.68s][Loss: 0.70436][LR: 0.00016433]\n",
            "20/12/09 11:20:48 - INFO - tape.training -   [Ep: 6.90][Iter: 980][Time: 15.04s][Loss: 0.70693][LR: 0.00015732]\n",
            "20/12/09 11:20:59 - INFO - tape.training -   Train: [Loss: 0.70349]\n",
            "20/12/09 11:21:13 - INFO - tape.training -   Evaluation: [Loss: 0.70192]\n",
            "20/12/09 11:21:13 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:21:13 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-09-11-06-43_034707\n",
            "20/12/09 11:21:17 - INFO - tape.training -   [Ep: 7.04][Iter: 1000][Time:  4.58s][Loss: 0.75023][LR: 0.00015032]\n",
            "20/12/09 11:21:33 - INFO - tape.training -   [Ep: 7.18][Iter: 1020][Time: 15.05s][Loss: 0.71261][LR: 0.00014331]\n",
            "20/12/09 11:21:47 - INFO - tape.training -   [Ep: 7.32][Iter: 1040][Time: 14.85s][Loss: 0.72092][LR: 0.0001363]\n",
            "20/12/09 11:22:03 - INFO - tape.training -   [Ep: 7.46][Iter: 1060][Time: 15.56s][Loss: 0.70708][LR: 0.00012929]\n",
            "20/12/09 11:22:18 - INFO - tape.training -   [Ep: 7.60][Iter: 1080][Time: 14.82s][Loss: 0.7038][LR: 0.00012228]\n",
            "20/12/09 11:22:32 - INFO - tape.training -   [Ep: 7.74][Iter: 1100][Time: 14.46s][Loss: 0.69215][LR: 0.00011528]\n",
            "20/12/09 11:22:48 - INFO - tape.training -   [Ep: 7.88][Iter: 1120][Time: 15.59s][Loss: 0.69139][LR: 0.00010827]\n",
            "20/12/09 11:23:00 - INFO - tape.training -   Train: [Loss: 0.7006]\n",
            "20/12/09 11:23:15 - INFO - tape.training -   Evaluation: [Loss: 0.70134]\n",
            "20/12/09 11:23:15 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:23:15 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-09-11-06-43_034707\n",
            "20/12/09 11:23:19 - INFO - tape.training -   [Ep: 8.03][Iter: 1140][Time:  3.65s][Loss: 0.77395][LR: 0.00010126]\n",
            "20/12/09 11:23:34 - INFO - tape.training -   [Ep: 8.17][Iter: 1160][Time: 15.01s][Loss: 0.72014][LR: 9.4254e-05]\n",
            "20/12/09 11:23:49 - INFO - tape.training -   [Ep: 8.31][Iter: 1180][Time: 14.95s][Loss: 0.71057][LR: 8.7246e-05]\n",
            "20/12/09 11:24:04 - INFO - tape.training -   [Ep: 8.45][Iter: 1200][Time: 15.70s][Loss: 0.69358][LR: 8.0238e-05]\n",
            "20/12/09 11:24:20 - INFO - tape.training -   [Ep: 8.59][Iter: 1220][Time: 15.15s][Loss: 0.69965][LR: 7.3231e-05]\n",
            "20/12/09 11:24:35 - INFO - tape.training -   [Ep: 8.73][Iter: 1240][Time: 14.99s][Loss: 0.68426][LR: 6.6223e-05]\n",
            "20/12/09 11:24:50 - INFO - tape.training -   [Ep: 8.87][Iter: 1260][Time: 15.46s][Loss: 0.67954][LR: 5.9215e-05]\n",
            "20/12/09 11:25:04 - INFO - tape.training -   Train: [Loss: 0.69729]\n",
            "20/12/09 11:25:19 - INFO - tape.training -   Evaluation: [Loss: 0.69938]\n",
            "20/12/09 11:25:19 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:25:19 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-09-11-06-43_034707\n",
            "20/12/09 11:25:20 - INFO - tape.training -   [Ep: 9.01][Iter: 1280][Time:  1.74s][Loss: 0.73144][LR: 5.2207e-05]\n",
            "20/12/09 11:25:35 - INFO - tape.training -   [Ep: 9.15][Iter: 1300][Time: 14.92s][Loss: 0.70727][LR: 4.52e-05]\n",
            "20/12/09 11:25:51 - INFO - tape.training -   [Ep: 9.29][Iter: 1320][Time: 15.37s][Loss: 0.70038][LR: 3.8192e-05]\n",
            "20/12/09 11:26:07 - INFO - tape.training -   [Ep: 9.43][Iter: 1340][Time: 16.30s][Loss: 0.68338][LR: 3.1184e-05]\n",
            "20/12/09 11:26:22 - INFO - tape.training -   [Ep: 9.57][Iter: 1360][Time: 14.94s][Loss: 0.71034][LR: 2.4177e-05]\n",
            "20/12/09 11:26:37 - INFO - tape.training -   [Ep: 9.71][Iter: 1380][Time: 15.22s][Loss: 0.68883][LR: 1.7169e-05]\n",
            "20/12/09 11:26:53 - INFO - tape.training -   [Ep: 9.85][Iter: 1400][Time: 15.39s][Loss: 0.66524][LR: 1.0161e-05]\n",
            "20/12/09 11:27:08 - INFO - tape.training -   [Ep: 9.99][Iter: 1420][Time: 14.97s][Loss: 0.69458][LR: 3.1535e-06]\n",
            "20/12/09 11:27:08 - INFO - tape.training -   Train: [Loss: 0.69688]\n",
            "20/12/09 11:27:23 - INFO - tape.training -   Evaluation: [Loss: 0.69864]\n",
            "20/12/09 11:27:23 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:27:23 - INFO - tape.training -   Saving model checkpoint to results/fluorescence_resnet_20-12-09-11-06-43_034707\n",
            "20/12/09 11:27:23 - INFO - tape.training -   Finished training after 10 epochs.\n",
            "20/12/09 11:27:23 - Level 35 - tape.training -   Best Val Loss: 0.6986384391784668\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRHQSKIyfD5T",
        "outputId": "716b2731-ba19-4d3d-edb2-473f421e02a5"
      },
      "source": [
        "!tape-eval resnet fluorescence /content/results/fluorescence_resnet_20-12-09-11-06-43_034707 --metrics mse mae spearmanr  "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/12/09 11:27:33 - INFO - tape.training -   device: cuda n_gpu: 1\n",
            "20/12/09 11:27:33 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/fluorescence_resnet_20-12-09-11-06-43_034707/config.json\n",
            "20/12/09 11:27:33 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": -1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/12/09 11:27:33 - INFO - tape.models.modeling_utils -   loading weights file /content/results/fluorescence_resnet_20-12-09-11-06-43_034707/pytorch_model.bin\n",
            "Evaluation: 100% 27/27 [00:07<00:00,  3.63it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[:, None]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[None, :]\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
            "  return (a < x) & (x < b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
            "  return (a < x) & (x < b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
            "  cond2 = cond0 & (x <= _a)\n",
            "20/12/09 11:27:43 - INFO - tape.training -   mse: 2.17937970161438mae: 1.3012042045593262spearmanr: nan\n",
            "{'mse': 2.1793797, 'mae': 1.3012042, 'spearmanr': nan}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-faygRsAclNo",
        "outputId": "8d85d2e9-6739-48fe-ab88-593d18ee6d4d"
      },
      "source": [
        "!tape-train-distributed resnet remote_homology --model_config_file /content/results/baseline_resnet/config.json --from_pretrained /content/results/pretrained2 --batch_size 150 --learning_rate 5e-4 --num_train_epochs 10 --warmup_steps 2 --gradient_accumulation_steps 50 --seed 1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/12/09 11:27:48 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/pretrained2/config.json\n",
            "20/12/09 11:27:48 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": 1195,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/12/09 11:27:48 - INFO - tape.models.modeling_utils -   loading weights file /content/results/pretrained2/pytorch_model.bin\n",
            "20/12/09 11:27:48 - INFO - tape.models.modeling_utils -   Weights of ProteinResNetForSequenceClassification not initialized from pretrained model: ['embeddings.inverse_frequency', 'embeddings.word_embeddings.weight', 'embeddings.layer_norm.weight', 'embeddings.layer_norm.bias', 'encoder.layer.0.conv1.weight', 'encoder.layer.0.bn1.norm.weight', 'encoder.layer.0.bn1.norm.bias', 'encoder.layer.0.conv2.weight', 'encoder.layer.0.bn2.norm.weight', 'encoder.layer.0.bn2.norm.bias', 'encoder.layer.1.conv1.weight', 'encoder.layer.1.bn1.norm.weight', 'encoder.layer.1.bn1.norm.bias', 'encoder.layer.1.conv2.weight', 'encoder.layer.1.bn2.norm.weight', 'encoder.layer.1.bn2.norm.bias', 'encoder.layer.2.conv1.weight', 'encoder.layer.2.bn1.norm.weight', 'encoder.layer.2.bn1.norm.bias', 'encoder.layer.2.conv2.weight', 'encoder.layer.2.bn2.norm.weight', 'encoder.layer.2.bn2.norm.bias', 'pooler.attention_weights.weight', 'pooler.attention_weights.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "20/12/09 11:27:48 - INFO - tape.models.modeling_utils -   Weights from pretrained model not used in ProteinResNetForSequenceClassification: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n",
            "20/12/09 11:27:48 - INFO - tape.visualization -   tensorboard file at: logs/remote_homology_resnet_20-12-09-11-27-45_256541\n",
            "20/12/09 11:27:48 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/09 11:27:48 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/09 11:27:48 - WARNING - tape.visualization -   Cannot watch models when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/09 11:27:48 - INFO - tape.training -   device: cuda:0 n_gpu: 1, distributed_training: True, 16-bits training: False\n",
            "20/12/09 11:27:48 - INFO - tape.training -   ***** Running training *****\n",
            "20/12/09 11:27:48 - INFO - tape.training -     Num examples = 12312\n",
            "20/12/09 11:27:48 - INFO - tape.training -     Batch size = 150\n",
            "20/12/09 11:27:48 - INFO - tape.training -     Num epochs = 10\n",
            "20/12/09 11:27:48 - INFO - tape.training -     Num train steps = 820\n",
            "20/12/09 11:27:48 - INFO - tape.training -     Num parameters = 650862\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "20/12/09 11:28:04 - INFO - tape.training -   [Ep: 0.24][Iter: 20][Time: 16.71s][Loss: 6.7348][Accuracy: 0.039391][LR: 0.000489]\n",
            "20/12/09 11:28:20 - INFO - tape.training -   [Ep: 0.49][Iter: 40][Time: 15.45s][Loss: 6.0537][Accuracy: 0.073109][LR: 0.00047677]\n",
            "20/12/09 11:28:36 - INFO - tape.training -   [Ep: 0.73][Iter: 60][Time: 16.09s][Loss: 5.6972][Accuracy: 0.098198][LR: 0.00046455]\n",
            "20/12/09 11:28:52 - INFO - tape.training -   [Ep: 0.97][Iter: 80][Time: 15.82s][Loss: 5.4648][Accuracy: 0.1117][LR: 0.00045232]\n",
            "20/12/09 11:28:53 - INFO - tape.training -   Train: [Loss: 5.7917][Accuracy: 0.094959]\n",
            "20/12/09 11:28:56 - INFO - tape.training -   Evaluation: [Loss: 5.8433][Accuracy: 0.039295]\n",
            "20/12/09 11:28:56 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:28:56 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-09-11-27-45_256541\n",
            "20/12/09 11:29:11 - INFO - tape.training -   [Ep: 1.22][Iter: 100][Time: 14.85s][Loss: 5.2254][Accuracy: 0.11457][LR: 0.0004401]\n",
            "20/12/09 11:29:27 - INFO - tape.training -   [Ep: 1.46][Iter: 120][Time: 16.51s][Loss: 5.1676][Accuracy: 0.12876][LR: 0.00042787]\n",
            "20/12/09 11:29:43 - INFO - tape.training -   [Ep: 1.71][Iter: 140][Time: 15.94s][Loss: 5.1126][Accuracy: 0.13181][LR: 0.00041565]\n",
            "20/12/09 11:30:00 - INFO - tape.training -   [Ep: 1.95][Iter: 160][Time: 16.49s][Loss: 5.0765][Accuracy: 0.14055][LR: 0.00040342]\n",
            "20/12/09 11:30:03 - INFO - tape.training -   Train: [Loss: 5.1284][Accuracy: 0.13276]\n",
            "20/12/09 11:30:06 - INFO - tape.training -   Evaluation: [Loss: 5.748][Accuracy: 0.047425]\n",
            "20/12/09 11:30:06 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:30:06 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-09-11-27-45_256541\n",
            "20/12/09 11:30:19 - INFO - tape.training -   [Ep: 2.19][Iter: 180][Time: 13.25s][Loss: 5.022][Accuracy: 0.12717][LR: 0.0003912]\n",
            "20/12/09 11:30:35 - INFO - tape.training -   [Ep: 2.44][Iter: 200][Time: 16.07s][Loss: 5.0116][Accuracy: 0.13631][LR: 0.00037897]\n",
            "20/12/09 11:30:52 - INFO - tape.training -   [Ep: 2.68][Iter: 220][Time: 16.34s][Loss: 4.9624][Accuracy: 0.139][LR: 0.00036675]\n",
            "20/12/09 11:31:08 - INFO - tape.training -   [Ep: 2.93][Iter: 240][Time: 16.54s][Loss: 4.9713][Accuracy: 0.13914][LR: 0.00035452]\n",
            "20/12/09 11:31:13 - INFO - tape.training -   Train: [Loss: 4.9838][Accuracy: 0.13512]\n",
            "20/12/09 11:31:16 - INFO - tape.training -   Evaluation: [Loss: 5.7147][Accuracy: 0.047425]\n",
            "20/12/09 11:31:16 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:31:16 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-09-11-27-45_256541\n",
            "20/12/09 11:31:27 - INFO - tape.training -   [Ep: 3.17][Iter: 260][Time: 11.81s][Loss: 4.9542][Accuracy: 0.12197][LR: 0.0003423]\n",
            "20/12/09 11:31:45 - INFO - tape.training -   [Ep: 3.41][Iter: 280][Time: 17.28s][Loss: 4.9417][Accuracy: 0.13517][LR: 0.00033007]\n",
            "20/12/09 11:32:01 - INFO - tape.training -   [Ep: 3.66][Iter: 300][Time: 16.45s][Loss: 4.9012][Accuracy: 0.14113][LR: 0.00031785]\n",
            "20/12/09 11:32:18 - INFO - tape.training -   [Ep: 3.90][Iter: 320][Time: 16.35s][Loss: 4.9014][Accuracy: 0.13617][LR: 0.00030562]\n",
            "20/12/09 11:32:24 - INFO - tape.training -   Train: [Loss: 4.9068][Accuracy: 0.13805]\n",
            "20/12/09 11:32:26 - INFO - tape.training -   Evaluation: [Loss: 5.6976][Accuracy: 0.056911]\n",
            "20/12/09 11:32:26 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:32:26 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-09-11-27-45_256541\n",
            "20/12/09 11:32:37 - INFO - tape.training -   [Ep: 4.15][Iter: 340][Time: 10.63s][Loss: 4.9347][Accuracy: 0.11544][LR: 0.0002934]\n",
            "20/12/09 11:32:54 - INFO - tape.training -   [Ep: 4.39][Iter: 360][Time: 17.16s][Loss: 4.8929][Accuracy: 0.13386][LR: 0.00028117]\n",
            "20/12/09 11:33:11 - INFO - tape.training -   [Ep: 4.63][Iter: 380][Time: 17.05s][Loss: 4.8664][Accuracy: 0.13942][LR: 0.00026895]\n",
            "20/12/09 11:33:27 - INFO - tape.training -   [Ep: 4.88][Iter: 400][Time: 16.14s][Loss: 4.853][Accuracy: 0.14263][LR: 0.00025672]\n",
            "20/12/09 11:33:35 - INFO - tape.training -   Train: [Loss: 4.85][Accuracy: 0.14325]\n",
            "20/12/09 11:33:38 - INFO - tape.training -   Evaluation: [Loss: 5.7236][Accuracy: 0.058266]\n",
            "20/12/09 11:33:38 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:33:38 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-09-11-27-45_256541\n",
            "20/12/09 11:33:46 - INFO - tape.training -   [Ep: 5.12][Iter: 420][Time:  8.52s][Loss: 4.9421][Accuracy: 0.13286][LR: 0.0002445]\n",
            "20/12/09 11:34:04 - INFO - tape.training -   [Ep: 5.37][Iter: 440][Time: 17.35s][Loss: 4.8864][Accuracy: 0.1402][LR: 0.00023227]\n",
            "20/12/09 11:34:20 - INFO - tape.training -   [Ep: 5.61][Iter: 460][Time: 16.04s][Loss: 4.8493][Accuracy: 0.14199][LR: 0.00022005]\n",
            "20/12/09 11:34:36 - INFO - tape.training -   [Ep: 5.85][Iter: 480][Time: 15.94s][Loss: 4.8254][Accuracy: 0.13858][LR: 0.00020782]\n",
            "20/12/09 11:34:45 - INFO - tape.training -   Train: [Loss: 4.8209][Accuracy: 0.14309]\n",
            "20/12/09 11:34:48 - INFO - tape.training -   Evaluation: [Loss: 5.6966][Accuracy: 0.059621]\n",
            "20/12/09 11:34:48 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:34:48 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-09-11-27-45_256541\n",
            "20/12/09 11:34:55 - INFO - tape.training -   [Ep: 6.10][Iter: 500][Time:  6.85s][Loss: 5.0535][Accuracy: 0.11918][LR: 0.0001956]\n",
            "20/12/09 11:35:10 - INFO - tape.training -   [Ep: 6.34][Iter: 520][Time: 15.56s][Loss: 4.9164][Accuracy: 0.13376][LR: 0.00018337]\n",
            "20/12/09 11:35:28 - INFO - tape.training -   [Ep: 6.58][Iter: 540][Time: 17.07s][Loss: 4.831][Accuracy: 0.13899][LR: 0.00017115]\n",
            "20/12/09 11:35:45 - INFO - tape.training -   [Ep: 6.83][Iter: 560][Time: 17.24s][Loss: 4.8113][Accuracy: 0.13902][LR: 0.00015892]\n",
            "20/12/09 11:35:56 - INFO - tape.training -   Train: [Loss: 4.7917][Accuracy: 0.14325]\n",
            "20/12/09 11:35:59 - INFO - tape.training -   Evaluation: [Loss: 5.6863][Accuracy: 0.059621]\n",
            "20/12/09 11:35:59 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:35:59 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-09-11-27-45_256541\n",
            "20/12/09 11:36:04 - INFO - tape.training -   [Ep: 7.07][Iter: 580][Time:  5.28s][Loss: 4.9906][Accuracy: 0.11568][LR: 0.0001467]\n",
            "20/12/09 11:36:21 - INFO - tape.training -   [Ep: 7.32][Iter: 600][Time: 16.85s][Loss: 4.8747][Accuracy: 0.13318][LR: 0.00013447]\n",
            "20/12/09 11:36:38 - INFO - tape.training -   [Ep: 7.56][Iter: 620][Time: 16.47s][Loss: 4.7973][Accuracy: 0.14227][LR: 0.00012225]\n",
            "20/12/09 11:36:54 - INFO - tape.training -   [Ep: 7.80][Iter: 640][Time: 16.21s][Loss: 4.7842][Accuracy: 0.13954][LR: 0.00011002]\n",
            "20/12/09 11:37:07 - INFO - tape.training -   Train: [Loss: 4.7657][Accuracy: 0.14504]\n",
            "20/12/09 11:37:10 - INFO - tape.training -   Evaluation: [Loss: 5.6777][Accuracy: 0.060976]\n",
            "20/12/09 11:37:10 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:37:10 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-09-11-27-45_256541\n",
            "20/12/09 11:37:13 - INFO - tape.training -   [Ep: 8.05][Iter: 660][Time:  3.62s][Loss: 4.9539][Accuracy: 0.12695][LR: 9.78e-05]\n",
            "20/12/09 11:37:30 - INFO - tape.training -   [Ep: 8.29][Iter: 680][Time: 16.72s][Loss: 4.8299][Accuracy: 0.13926][LR: 8.5575e-05]\n",
            "20/12/09 11:37:47 - INFO - tape.training -   [Ep: 8.54][Iter: 700][Time: 16.72s][Loss: 4.7814][Accuracy: 0.14414][LR: 7.335e-05]\n",
            "20/12/09 11:38:03 - INFO - tape.training -   [Ep: 8.78][Iter: 720][Time: 16.21s][Loss: 4.7764][Accuracy: 0.14235][LR: 6.1125e-05]\n",
            "20/12/09 11:38:18 - INFO - tape.training -   Train: [Loss: 4.7464][Accuracy: 0.14545]\n",
            "20/12/09 11:38:21 - INFO - tape.training -   Evaluation: [Loss: 5.6812][Accuracy: 0.060976]\n",
            "20/12/09 11:38:21 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:38:21 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-09-11-27-45_256541\n",
            "20/12/09 11:38:22 - INFO - tape.training -   [Ep: 9.02][Iter: 740][Time:  1.85s][Loss: 4.8385][Accuracy: 0.132][LR: 4.89e-05]\n",
            "20/12/09 11:38:39 - INFO - tape.training -   [Ep: 9.27][Iter: 760][Time: 16.56s][Loss: 4.784][Accuracy: 0.13856][LR: 3.6675e-05]\n",
            "20/12/09 11:38:56 - INFO - tape.training -   [Ep: 9.51][Iter: 780][Time: 16.51s][Loss: 4.7532][Accuracy: 0.14518][LR: 2.445e-05]\n",
            "20/12/09 11:39:13 - INFO - tape.training -   [Ep: 9.76][Iter: 800][Time: 17.33s][Loss: 4.7472][Accuracy: 0.14247][LR: 1.2225e-05]\n",
            "20/12/09 11:39:29 - INFO - tape.training -   [Ep: 10.00][Iter: 820][Time: 16.47s][Loss: 4.6964][Accuracy: 0.14862][LR: 0]\n",
            "20/12/09 11:39:30 - INFO - tape.training -   Train: [Loss: 4.7332][Accuracy: 0.14431]\n",
            "20/12/09 11:39:32 - INFO - tape.training -   Evaluation: [Loss: 5.6896][Accuracy: 0.062331]\n",
            "20/12/09 11:39:32 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:39:32 - INFO - tape.training -   Saving model checkpoint to results/remote_homology_resnet_20-12-09-11-27-45_256541\n",
            "20/12/09 11:39:32 - INFO - tape.training -   Finished training after 10 epochs.\n",
            "20/12/09 11:39:32 - Level 35 - tape.training -   Best Val Loss: 5.677737236022949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbgTxvUifEUF"
      },
      "source": [
        "# !tape-eval resnet remote_homology /content/results/secondary_structure_transformer_20-11-16-15-36-39_069321 --metrics mse mae spearmanr "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9xC0m3CclQT",
        "outputId": "62e8f647-7f72-4207-d872-f34dfa1071ef"
      },
      "source": [
        "!tape-train-distributed resnet secondary_structure --model_config_file /content/results/baseline_resnet/config.json --from_pretrained /content/results/pretrained2 --batch_size 150 --learning_rate 5e-4 --num_train_epochs 10 --warmup_steps 2 --gradient_accumulation_steps 50 --seed 1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/12/09 11:39:38 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/pretrained2/config.json\n",
            "20/12/09 11:39:38 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": 3,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/12/09 11:39:38 - INFO - tape.models.modeling_utils -   loading weights file /content/results/pretrained2/pytorch_model.bin\n",
            "20/12/09 11:39:38 - INFO - tape.models.modeling_utils -   Weights of ProteinResNetForSequenceToSequenceClassification not initialized from pretrained model: ['embeddings.inverse_frequency', 'embeddings.word_embeddings.weight', 'embeddings.layer_norm.weight', 'embeddings.layer_norm.bias', 'encoder.layer.0.conv1.weight', 'encoder.layer.0.bn1.norm.weight', 'encoder.layer.0.bn1.norm.bias', 'encoder.layer.0.conv2.weight', 'encoder.layer.0.bn2.norm.weight', 'encoder.layer.0.bn2.norm.bias', 'encoder.layer.1.conv1.weight', 'encoder.layer.1.bn1.norm.weight', 'encoder.layer.1.bn1.norm.bias', 'encoder.layer.1.conv2.weight', 'encoder.layer.1.bn2.norm.weight', 'encoder.layer.1.bn2.norm.bias', 'encoder.layer.2.conv1.weight', 'encoder.layer.2.bn1.norm.weight', 'encoder.layer.2.bn1.norm.bias', 'encoder.layer.2.conv2.weight', 'encoder.layer.2.bn2.norm.weight', 'encoder.layer.2.bn2.norm.bias', 'pooler.attention_weights.weight', 'pooler.attention_weights.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "20/12/09 11:39:38 - INFO - tape.models.modeling_utils -   Weights from pretrained model not used in ProteinResNetForSequenceToSequenceClassification: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n",
            "20/12/09 11:39:38 - INFO - tape.visualization -   tensorboard file at: logs/secondary_structure_resnet_20-12-09-11-39-36_032594\n",
            "20/12/09 11:39:38 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/09 11:39:38 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/09 11:39:38 - WARNING - tape.visualization -   Cannot watch models when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/09 11:39:38 - INFO - tape.training -   device: cuda:0 n_gpu: 1, distributed_training: True, 16-bits training: False\n",
            "20/12/09 11:39:38 - INFO - tape.training -   ***** Running training *****\n",
            "20/12/09 11:39:38 - INFO - tape.training -     Num examples = 8678\n",
            "20/12/09 11:39:38 - INFO - tape.training -     Batch size = 150\n",
            "20/12/09 11:39:38 - INFO - tape.training -     Num epochs = 10\n",
            "20/12/09 11:39:38 - INFO - tape.training -     Num train steps = 578\n",
            "20/12/09 11:39:38 - INFO - tape.training -     Num parameters = 108038\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "20/12/09 11:39:56 - INFO - tape.training -   [Ep: 0.35][Iter: 20][Time: 18.11s][Loss: 1.0892][Accuracy: 0.38802][LR: 0.00048437]\n",
            "20/12/09 11:40:14 - INFO - tape.training -   [Ep: 0.69][Iter: 40][Time: 17.95s][Loss: 1.0778][Accuracy: 0.4062][LR: 0.00046701]\n",
            "20/12/09 11:40:30 - INFO - tape.training -   Train: [Loss: 1.076][Accuracy: 0.40834]\n",
            "20/12/09 11:40:37 - INFO - tape.training -   Evaluation: [Loss: 1.0536][Accuracy: 0.43319]\n",
            "20/12/09 11:40:37 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:40:37 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-09-11-39-36_032594\n",
            "20/12/09 11:40:41 - INFO - tape.training -   [Ep: 1.05][Iter: 60][Time:  3.05s][Loss: 1.0563][Accuracy: 0.42353][LR: 0.00044965]\n",
            "20/12/09 11:40:58 - INFO - tape.training -   [Ep: 1.40][Iter: 80][Time: 17.76s][Loss: 1.0616][Accuracy: 0.41631][LR: 0.00043229]\n",
            "20/12/09 11:41:16 - INFO - tape.training -   [Ep: 1.74][Iter: 100][Time: 18.22s][Loss: 1.0566][Accuracy: 0.42113][LR: 0.00041493]\n",
            "20/12/09 11:41:30 - INFO - tape.training -   Train: [Loss: 1.0574][Accuracy: 0.41971]\n",
            "20/12/09 11:41:37 - INFO - tape.training -   Evaluation: [Loss: 1.0334][Accuracy: 0.45834]\n",
            "20/12/09 11:41:37 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:41:37 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-09-11-39-36_032594\n",
            "20/12/09 11:41:43 - INFO - tape.training -   [Ep: 2.10][Iter: 120][Time:  5.57s][Loss: 1.0482][Accuracy: 0.44533][LR: 0.00039757]\n",
            "20/12/09 11:42:01 - INFO - tape.training -   [Ep: 2.45][Iter: 140][Time: 17.82s][Loss: 1.0389][Accuracy: 0.45264][LR: 0.00038021]\n",
            "20/12/09 11:42:19 - INFO - tape.training -   [Ep: 2.79][Iter: 160][Time: 18.18s][Loss: 1.0174][Accuracy: 0.48125][LR: 0.00036285]\n",
            "20/12/09 11:42:29 - INFO - tape.training -   Train: [Loss: 1.0169][Accuracy: 0.47911]\n",
            "20/12/09 11:42:37 - INFO - tape.training -   Evaluation: [Loss: 0.97341][Accuracy: 0.55071]\n",
            "20/12/09 11:42:37 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:42:37 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-09-11-39-36_032594\n",
            "20/12/09 11:42:45 - INFO - tape.training -   [Ep: 3.16][Iter: 180][Time:  8.36s][Loss: 0.97376][Accuracy: 0.52553][LR: 0.00034549]\n",
            "20/12/09 11:43:03 - INFO - tape.training -   [Ep: 3.50][Iter: 200][Time: 17.34s][Loss: 0.96836][Accuracy: 0.53038][LR: 0.00032813]\n",
            "20/12/09 11:43:21 - INFO - tape.training -   [Ep: 3.85][Iter: 220][Time: 18.20s][Loss: 0.95868][Accuracy: 0.53796][LR: 0.00031076]\n",
            "20/12/09 11:43:29 - INFO - tape.training -   Train: [Loss: 0.96198][Accuracy: 0.53624]\n",
            "20/12/09 11:43:36 - INFO - tape.training -   Evaluation: [Loss: 0.91615][Accuracy: 0.57688]\n",
            "20/12/09 11:43:36 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:43:36 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-09-11-39-36_032594\n",
            "20/12/09 11:43:47 - INFO - tape.training -   [Ep: 4.21][Iter: 240][Time: 10.97s][Loss: 0.94051][Accuracy: 0.55261][LR: 0.0002934]\n",
            "20/12/09 11:44:05 - INFO - tape.training -   [Ep: 4.55][Iter: 260][Time: 17.29s][Loss: 0.92983][Accuracy: 0.56029][LR: 0.00027604]\n",
            "20/12/09 11:44:22 - INFO - tape.training -   [Ep: 4.90][Iter: 280][Time: 17.66s][Loss: 0.91869][Accuracy: 0.56811][LR: 0.00025868]\n",
            "20/12/09 11:44:27 - INFO - tape.training -   Train: [Loss: 0.92181][Accuracy: 0.56709]\n",
            "20/12/09 11:44:35 - INFO - tape.training -   Evaluation: [Loss: 0.89065][Accuracy: 0.59819]\n",
            "20/12/09 11:44:35 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:44:35 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-09-11-39-36_032594\n",
            "20/12/09 11:44:49 - INFO - tape.training -   [Ep: 5.26][Iter: 300][Time: 13.90s][Loss: 0.91116][Accuracy: 0.57486][LR: 0.00024132]\n",
            "20/12/09 11:45:08 - INFO - tape.training -   [Ep: 5.60][Iter: 320][Time: 18.71s][Loss: 0.89945][Accuracy: 0.58257][LR: 0.00022396]\n",
            "20/12/09 11:45:25 - INFO - tape.training -   [Ep: 5.95][Iter: 340][Time: 17.60s][Loss: 0.89493][Accuracy: 0.58526][LR: 0.0002066]\n",
            "20/12/09 11:45:28 - INFO - tape.training -   Train: [Loss: 0.89504][Accuracy: 0.58554]\n",
            "20/12/09 11:45:36 - INFO - tape.training -   Evaluation: [Loss: 0.85683][Accuracy: 0.61363]\n",
            "20/12/09 11:45:36 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:45:36 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-09-11-39-36_032594\n",
            "20/12/09 11:45:52 - INFO - tape.training -   [Ep: 6.31][Iter: 360][Time: 16.56s][Loss: 0.8801][Accuracy: 0.59593][LR: 0.00018924]\n",
            "20/12/09 11:46:10 - INFO - tape.training -   [Ep: 6.66][Iter: 380][Time: 18.13s][Loss: 0.87734][Accuracy: 0.59863][LR: 0.00017187]\n",
            "20/12/09 11:46:28 - INFO - tape.training -   Train: [Loss: 0.87837][Accuracy: 0.59701]\n",
            "20/12/09 11:46:36 - INFO - tape.training -   Evaluation: [Loss: 0.87289][Accuracy: 0.59638]\n",
            "20/12/09 11:46:36 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:46:36 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-09-11-39-36_032594\n",
            "20/12/09 11:46:37 - INFO - tape.training -   [Ep: 7.02][Iter: 400][Time:  1.14s][Loss: 0.87605][Accuracy: 0.59708][LR: 0.00015451]\n",
            "20/12/09 11:46:54 - INFO - tape.training -   [Ep: 7.36][Iter: 420][Time: 17.17s][Loss: 0.87048][Accuracy: 0.60117][LR: 0.00013715]\n",
            "20/12/09 11:47:12 - INFO - tape.training -   [Ep: 7.71][Iter: 440][Time: 17.45s][Loss: 0.86581][Accuracy: 0.60373][LR: 0.00011979]\n",
            "20/12/09 11:47:27 - INFO - tape.training -   Train: [Loss: 0.86385][Accuracy: 0.6059]\n",
            "20/12/09 11:47:35 - INFO - tape.training -   Evaluation: [Loss: 0.85923][Accuracy: 0.61057]\n",
            "20/12/09 11:47:35 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:47:35 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-09-11-39-36_032594\n",
            "20/12/09 11:47:39 - INFO - tape.training -   [Ep: 8.07][Iter: 460][Time:  3.95s][Loss: 0.85508][Accuracy: 0.61327][LR: 0.00010243]\n",
            "20/12/09 11:47:57 - INFO - tape.training -   [Ep: 8.41][Iter: 480][Time: 17.99s][Loss: 0.85466][Accuracy: 0.61265][LR: 8.5069e-05]\n",
            "20/12/09 11:48:14 - INFO - tape.training -   [Ep: 8.76][Iter: 500][Time: 17.45s][Loss: 0.85245][Accuracy: 0.61289][LR: 6.7708e-05]\n",
            "20/12/09 11:48:26 - INFO - tape.training -   Train: [Loss: 0.85232][Accuracy: 0.61364]\n",
            "20/12/09 11:48:34 - INFO - tape.training -   Evaluation: [Loss: 0.83781][Accuracy: 0.62675]\n",
            "20/12/09 11:48:34 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:48:34 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-09-11-39-36_032594\n",
            "20/12/09 11:48:41 - INFO - tape.training -   [Ep: 9.12][Iter: 520][Time:  6.48s][Loss: 0.85645][Accuracy: 0.61415][LR: 5.0347e-05]\n",
            "20/12/09 11:48:58 - INFO - tape.training -   [Ep: 9.47][Iter: 540][Time: 17.74s][Loss: 0.8511][Accuracy: 0.61594][LR: 3.2986e-05]\n",
            "20/12/09 11:49:17 - INFO - tape.training -   [Ep: 9.81][Iter: 560][Time: 18.46s][Loss: 0.84579][Accuracy: 0.61785][LR: 1.5625e-05]\n",
            "20/12/09 11:49:27 - INFO - tape.training -   Train: [Loss: 0.84431][Accuracy: 0.61882]\n",
            "20/12/09 11:49:34 - INFO - tape.training -   Evaluation: [Loss: 0.83173][Accuracy: 0.63089]\n",
            "20/12/09 11:49:34 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:49:34 - INFO - tape.training -   Saving model checkpoint to results/secondary_structure_resnet_20-12-09-11-39-36_032594\n",
            "20/12/09 11:49:34 - INFO - tape.training -   Finished training after 10 epochs.\n",
            "20/12/09 11:49:34 - Level 35 - tape.training -   Best Val Loss: 0.8317327499389648\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmTVYN62fEwJ"
      },
      "source": [
        "# !tape-eval resnet secondary_structure /content/results/secondary_structure_transformer_20-11-16-15-36-39_069321 --metrics mse mae spearmanr accuracy "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAsP4o9HclSs",
        "outputId": "939a9f18-8547-4bf2-8edd-63065b595958"
      },
      "source": [
        "!tape-train-distributed resnet stability --model_config_file /content/results/baseline_resnet/config.json --from_pretrained /content/results/pretrained2 --batch_size 150 --learning_rate 5e-4 --num_train_epochs 10 --warmup_steps 2 --gradient_accumulation_steps 50 --seed 1"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/12/09 11:49:40 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/pretrained2/config.json\n",
            "20/12/09 11:49:40 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": -1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/12/09 11:49:40 - INFO - tape.models.modeling_utils -   loading weights file /content/results/pretrained2/pytorch_model.bin\n",
            "20/12/09 11:49:40 - INFO - tape.models.modeling_utils -   Weights of ProteinResNetForValuePrediction not initialized from pretrained model: ['embeddings.inverse_frequency', 'embeddings.word_embeddings.weight', 'embeddings.layer_norm.weight', 'embeddings.layer_norm.bias', 'encoder.layer.0.conv1.weight', 'encoder.layer.0.bn1.norm.weight', 'encoder.layer.0.bn1.norm.bias', 'encoder.layer.0.conv2.weight', 'encoder.layer.0.bn2.norm.weight', 'encoder.layer.0.bn2.norm.bias', 'encoder.layer.1.conv1.weight', 'encoder.layer.1.bn1.norm.weight', 'encoder.layer.1.bn1.norm.bias', 'encoder.layer.1.conv2.weight', 'encoder.layer.1.bn2.norm.weight', 'encoder.layer.1.bn2.norm.bias', 'encoder.layer.2.conv1.weight', 'encoder.layer.2.bn1.norm.weight', 'encoder.layer.2.bn1.norm.bias', 'encoder.layer.2.conv2.weight', 'encoder.layer.2.bn2.norm.weight', 'encoder.layer.2.bn2.norm.bias', 'pooler.attention_weights.weight', 'pooler.attention_weights.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "20/12/09 11:49:40 - INFO - tape.models.modeling_utils -   Weights from pretrained model not used in ProteinResNetForValuePrediction: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'mlm.bias', 'mlm.transform.dense.weight', 'mlm.transform.dense.bias', 'mlm.transform.LayerNorm.weight', 'mlm.transform.LayerNorm.bias', 'mlm.decoder.weight']\n",
            "20/12/09 11:49:40 - INFO - tape.visualization -   tensorboard file at: logs/stability_resnet_20-12-09-11-49-38_651743\n",
            "20/12/09 11:49:40 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/09 11:49:40 - WARNING - tape.visualization -   Cannot log config when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/09 11:49:40 - WARNING - tape.visualization -   Cannot watch models when using a TBVisualizer. Configure wandb for this functionality\n",
            "20/12/09 11:49:40 - INFO - tape.training -   device: cuda:0 n_gpu: 1, distributed_training: True, 16-bits training: False\n",
            "20/12/09 11:49:40 - INFO - tape.training -   ***** Running training *****\n",
            "20/12/09 11:49:40 - INFO - tape.training -     Num examples = 53614\n",
            "20/12/09 11:49:40 - INFO - tape.training -     Batch size = 150\n",
            "20/12/09 11:49:40 - INFO - tape.training -     Num epochs = 10\n",
            "20/12/09 11:49:40 - INFO - tape.training -     Num train steps = 3574\n",
            "20/12/09 11:49:40 - INFO - tape.training -     Num parameters = 38340\n",
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "20/12/09 11:49:56 - INFO - tape.training -   [Ep: 0.06][Iter: 20][Time: 15.80s][Loss: 0.36292][LR: 0.00049748]\n",
            "20/12/09 11:50:11 - INFO - tape.training -   [Ep: 0.11][Iter: 40][Time: 15.26s][Loss: 0.33235][LR: 0.00049468]\n",
            "20/12/09 11:50:26 - INFO - tape.training -   [Ep: 0.17][Iter: 60][Time: 14.71s][Loss: 0.35576][LR: 0.00049188]\n",
            "20/12/09 11:50:41 - INFO - tape.training -   [Ep: 0.22][Iter: 80][Time: 14.94s][Loss: 0.34853][LR: 0.00048908]\n",
            "20/12/09 11:50:56 - INFO - tape.training -   [Ep: 0.28][Iter: 100][Time: 15.06s][Loss: 0.33968][LR: 0.00048628]\n",
            "20/12/09 11:51:13 - INFO - tape.training -   [Ep: 0.34][Iter: 120][Time: 16.82s][Loss: 0.32806][LR: 0.00048348]\n",
            "20/12/09 11:51:28 - INFO - tape.training -   [Ep: 0.39][Iter: 140][Time: 15.07s][Loss: 0.33455][LR: 0.00048068]\n",
            "20/12/09 11:51:43 - INFO - tape.training -   [Ep: 0.45][Iter: 160][Time: 15.67s][Loss: 0.32867][LR: 0.00047788]\n",
            "20/12/09 11:51:59 - INFO - tape.training -   [Ep: 0.50][Iter: 180][Time: 15.64s][Loss: 0.33875][LR: 0.00047508]\n",
            "20/12/09 11:52:15 - INFO - tape.training -   [Ep: 0.56][Iter: 200][Time: 15.97s][Loss: 0.32643][LR: 0.00047228]\n",
            "20/12/09 11:52:30 - INFO - tape.training -   [Ep: 0.62][Iter: 220][Time: 15.36s][Loss: 0.33653][LR: 0.00046948]\n",
            "20/12/09 11:52:45 - INFO - tape.training -   [Ep: 0.67][Iter: 240][Time: 14.95s][Loss: 0.33789][LR: 0.00046669]\n",
            "20/12/09 11:53:01 - INFO - tape.training -   [Ep: 0.73][Iter: 260][Time: 15.96s][Loss: 0.3396][LR: 0.00046389]\n",
            "20/12/09 11:53:17 - INFO - tape.training -   [Ep: 0.78][Iter: 280][Time: 15.41s][Loss: 0.32439][LR: 0.00046109]\n",
            "20/12/09 11:53:32 - INFO - tape.training -   [Ep: 0.84][Iter: 300][Time: 15.52s][Loss: 0.33168][LR: 0.00045829]\n",
            "20/12/09 11:53:48 - INFO - tape.training -   [Ep: 0.90][Iter: 320][Time: 15.87s][Loss: 0.32761][LR: 0.00045549]\n",
            "20/12/09 11:54:03 - INFO - tape.training -   [Ep: 0.95][Iter: 340][Time: 15.21s][Loss: 0.31383][LR: 0.00045269]\n",
            "20/12/09 11:54:16 - INFO - tape.training -   Train: [Loss: 0.33255]\n",
            "20/12/09 11:54:23 - INFO - tape.training -   Evaluation: [Loss: 0.4327]\n",
            "20/12/09 11:54:23 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:54:23 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-09-11-49-38_651743\n",
            "20/12/09 11:54:26 - INFO - tape.training -   [Ep: 1.01][Iter: 360][Time:  2.65s][Loss: 0.35368][LR: 0.00044989]\n",
            "20/12/09 11:54:41 - INFO - tape.training -   [Ep: 1.06][Iter: 380][Time: 15.42s][Loss: 0.32954][LR: 0.00044709]\n",
            "20/12/09 11:54:56 - INFO - tape.training -   [Ep: 1.12][Iter: 400][Time: 14.80s][Loss: 0.31791][LR: 0.00044429]\n",
            "20/12/09 11:55:11 - INFO - tape.training -   [Ep: 1.18][Iter: 420][Time: 15.39s][Loss: 0.3298][LR: 0.00044149]\n",
            "20/12/09 11:55:27 - INFO - tape.training -   [Ep: 1.23][Iter: 440][Time: 15.77s][Loss: 0.33036][LR: 0.00043869]\n",
            "20/12/09 11:55:42 - INFO - tape.training -   [Ep: 1.29][Iter: 460][Time: 14.83s][Loss: 0.32891][LR: 0.00043589]\n",
            "20/12/09 11:55:57 - INFO - tape.training -   [Ep: 1.34][Iter: 480][Time: 15.00s][Loss: 0.32739][LR: 0.00043309]\n",
            "20/12/09 11:56:12 - INFO - tape.training -   [Ep: 1.40][Iter: 500][Time: 15.03s][Loss: 0.32595][LR: 0.00043029]\n",
            "20/12/09 11:56:27 - INFO - tape.training -   [Ep: 1.46][Iter: 520][Time: 15.10s][Loss: 0.32789][LR: 0.00042749]\n",
            "20/12/09 11:56:42 - INFO - tape.training -   [Ep: 1.51][Iter: 540][Time: 14.95s][Loss: 0.33107][LR: 0.00042469]\n",
            "20/12/09 11:56:57 - INFO - tape.training -   [Ep: 1.57][Iter: 560][Time: 15.03s][Loss: 0.31761][LR: 0.00042189]\n",
            "20/12/09 11:57:13 - INFO - tape.training -   [Ep: 1.62][Iter: 580][Time: 15.81s][Loss: 0.33723][LR: 0.00041909]\n",
            "20/12/09 11:57:28 - INFO - tape.training -   [Ep: 1.68][Iter: 600][Time: 14.99s][Loss: 0.34037][LR: 0.00041629]\n",
            "20/12/09 11:57:43 - INFO - tape.training -   [Ep: 1.74][Iter: 620][Time: 14.81s][Loss: 0.33731][LR: 0.00041349]\n",
            "20/12/09 11:57:58 - INFO - tape.training -   [Ep: 1.79][Iter: 640][Time: 14.85s][Loss: 0.32518][LR: 0.00041069]\n",
            "20/12/09 11:58:13 - INFO - tape.training -   [Ep: 1.85][Iter: 660][Time: 15.15s][Loss: 0.33167][LR: 0.00040789]\n",
            "20/12/09 11:58:28 - INFO - tape.training -   [Ep: 1.90][Iter: 680][Time: 15.08s][Loss: 0.3302][LR: 0.0004051]\n",
            "20/12/09 11:58:44 - INFO - tape.training -   [Ep: 1.96][Iter: 700][Time: 15.98s][Loss: 0.31619][LR: 0.0004023]\n",
            "20/12/09 11:58:55 - INFO - tape.training -   Train: [Loss: 0.32672]\n",
            "20/12/09 11:59:02 - INFO - tape.training -   Evaluation: [Loss: 0.45225]\n",
            "20/12/09 11:59:02 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 11:59:02 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-09-11-49-38_651743\n",
            "20/12/09 11:59:07 - INFO - tape.training -   [Ep: 2.02][Iter: 720][Time:  4.81s][Loss: 0.33338][LR: 0.0003995]\n",
            "20/12/09 11:59:23 - INFO - tape.training -   [Ep: 2.07][Iter: 740][Time: 16.01s][Loss: 0.32476][LR: 0.0003967]\n",
            "20/12/09 11:59:38 - INFO - tape.training -   [Ep: 2.13][Iter: 760][Time: 15.63s][Loss: 0.31836][LR: 0.0003939]\n",
            "20/12/09 11:59:53 - INFO - tape.training -   [Ep: 2.18][Iter: 780][Time: 15.22s][Loss: 0.32528][LR: 0.0003911]\n",
            "20/12/09 12:00:08 - INFO - tape.training -   [Ep: 2.24][Iter: 800][Time: 14.91s][Loss: 0.32733][LR: 0.0003883]\n",
            "20/12/09 12:00:23 - INFO - tape.training -   [Ep: 2.30][Iter: 820][Time: 14.82s][Loss: 0.32787][LR: 0.0003855]\n",
            "20/12/09 12:00:38 - INFO - tape.training -   [Ep: 2.35][Iter: 840][Time: 15.19s][Loss: 0.32189][LR: 0.0003827]\n",
            "20/12/09 12:00:54 - INFO - tape.training -   [Ep: 2.41][Iter: 860][Time: 15.66s][Loss: 0.32887][LR: 0.0003799]\n",
            "20/12/09 12:01:10 - INFO - tape.training -   [Ep: 2.46][Iter: 880][Time: 15.67s][Loss: 0.32694][LR: 0.0003771]\n",
            "20/12/09 12:01:25 - INFO - tape.training -   [Ep: 2.52][Iter: 900][Time: 15.12s][Loss: 0.32008][LR: 0.0003743]\n",
            "20/12/09 12:01:40 - INFO - tape.training -   [Ep: 2.58][Iter: 920][Time: 15.39s][Loss: 0.31644][LR: 0.0003715]\n",
            "20/12/09 12:01:55 - INFO - tape.training -   [Ep: 2.63][Iter: 940][Time: 15.06s][Loss: 0.32144][LR: 0.0003687]\n",
            "20/12/09 12:02:11 - INFO - tape.training -   [Ep: 2.69][Iter: 960][Time: 15.27s][Loss: 0.33103][LR: 0.0003659]\n",
            "20/12/09 12:02:25 - INFO - tape.training -   [Ep: 2.74][Iter: 980][Time: 14.74s][Loss: 0.3263][LR: 0.0003631]\n",
            "20/12/09 12:02:40 - INFO - tape.training -   [Ep: 2.80][Iter: 1000][Time: 15.11s][Loss: 0.31288][LR: 0.0003603]\n",
            "20/12/09 12:02:56 - INFO - tape.training -   [Ep: 2.86][Iter: 1020][Time: 15.27s][Loss: 0.32508][LR: 0.0003575]\n",
            "20/12/09 12:03:10 - INFO - tape.training -   [Ep: 2.91][Iter: 1040][Time: 14.85s][Loss: 0.3194][LR: 0.0003547]\n",
            "20/12/09 12:03:26 - INFO - tape.training -   [Ep: 2.97][Iter: 1060][Time: 15.06s][Loss: 0.31257][LR: 0.0003519]\n",
            "20/12/09 12:03:34 - INFO - tape.training -   Train: [Loss: 0.32244]\n",
            "20/12/09 12:03:41 - INFO - tape.training -   Evaluation: [Loss: 0.43605]\n",
            "20/12/09 12:03:41 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 12:03:41 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-09-11-49-38_651743\n",
            "20/12/09 12:03:49 - INFO - tape.training -   [Ep: 3.03][Iter: 1080][Time:  7.24s][Loss: 0.32315][LR: 0.0003491]\n",
            "20/12/09 12:04:04 - INFO - tape.training -   [Ep: 3.08][Iter: 1100][Time: 15.35s][Loss: 0.31977][LR: 0.0003463]\n",
            "20/12/09 12:04:20 - INFO - tape.training -   [Ep: 3.14][Iter: 1120][Time: 16.03s][Loss: 0.32128][LR: 0.00034351]\n",
            "20/12/09 12:04:36 - INFO - tape.training -   [Ep: 3.19][Iter: 1140][Time: 15.64s][Loss: 0.33088][LR: 0.00034071]\n",
            "20/12/09 12:04:51 - INFO - tape.training -   [Ep: 3.25][Iter: 1160][Time: 15.69s][Loss: 0.32714][LR: 0.00033791]\n",
            "20/12/09 12:05:06 - INFO - tape.training -   [Ep: 3.30][Iter: 1180][Time: 14.88s][Loss: 0.32493][LR: 0.00033511]\n",
            "20/12/09 12:05:21 - INFO - tape.training -   [Ep: 3.36][Iter: 1200][Time: 15.14s][Loss: 0.3224][LR: 0.00033231]\n",
            "20/12/09 12:05:38 - INFO - tape.training -   [Ep: 3.42][Iter: 1220][Time: 16.16s][Loss: 0.3268][LR: 0.00032951]\n",
            "20/12/09 12:05:53 - INFO - tape.training -   [Ep: 3.47][Iter: 1240][Time: 15.13s][Loss: 0.3254][LR: 0.00032671]\n",
            "20/12/09 12:06:08 - INFO - tape.training -   [Ep: 3.53][Iter: 1260][Time: 15.13s][Loss: 0.32098][LR: 0.00032391]\n",
            "20/12/09 12:06:23 - INFO - tape.training -   [Ep: 3.58][Iter: 1280][Time: 15.53s][Loss: 0.3176][LR: 0.00032111]\n",
            "20/12/09 12:06:39 - INFO - tape.training -   [Ep: 3.64][Iter: 1300][Time: 15.25s][Loss: 0.32204][LR: 0.00031831]\n",
            "20/12/09 12:06:54 - INFO - tape.training -   [Ep: 3.70][Iter: 1320][Time: 15.19s][Loss: 0.33276][LR: 0.00031551]\n",
            "20/12/09 12:07:09 - INFO - tape.training -   [Ep: 3.75][Iter: 1340][Time: 15.42s][Loss: 0.32561][LR: 0.00031271]\n",
            "20/12/09 12:07:24 - INFO - tape.training -   [Ep: 3.81][Iter: 1360][Time: 14.68s][Loss: 0.31308][LR: 0.00030991]\n",
            "20/12/09 12:07:39 - INFO - tape.training -   [Ep: 3.86][Iter: 1380][Time: 15.25s][Loss: 0.31994][LR: 0.00030711]\n",
            "20/12/09 12:07:54 - INFO - tape.training -   [Ep: 3.92][Iter: 1400][Time: 15.20s][Loss: 0.31177][LR: 0.00030431]\n",
            "20/12/09 12:08:10 - INFO - tape.training -   [Ep: 3.98][Iter: 1420][Time: 15.22s][Loss: 0.31224][LR: 0.00030151]\n",
            "20/12/09 12:08:16 - INFO - tape.training -   Train: [Loss: 0.32127]\n",
            "20/12/09 12:08:23 - INFO - tape.training -   Evaluation: [Loss: 0.43638]\n",
            "20/12/09 12:08:23 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 12:08:23 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-09-11-49-38_651743\n",
            "20/12/09 12:08:33 - INFO - tape.training -   [Ep: 4.03][Iter: 1440][Time:  9.49s][Loss: 0.2807][LR: 0.00029871]\n",
            "20/12/09 12:08:48 - INFO - tape.training -   [Ep: 4.09][Iter: 1460][Time: 15.55s][Loss: 0.30404][LR: 0.00029591]\n",
            "20/12/09 12:09:04 - INFO - tape.training -   [Ep: 4.15][Iter: 1480][Time: 15.36s][Loss: 0.32461][LR: 0.00029311]\n",
            "20/12/09 12:09:20 - INFO - tape.training -   [Ep: 4.20][Iter: 1500][Time: 16.29s][Loss: 0.32818][LR: 0.00029031]\n",
            "20/12/09 12:09:35 - INFO - tape.training -   [Ep: 4.26][Iter: 1520][Time: 14.71s][Loss: 0.33081][LR: 0.00028751]\n",
            "20/12/09 12:09:49 - INFO - tape.training -   [Ep: 4.31][Iter: 1540][Time: 14.90s][Loss: 0.32174][LR: 0.00028471]\n",
            "20/12/09 12:10:05 - INFO - tape.training -   [Ep: 4.37][Iter: 1560][Time: 15.12s][Loss: 0.32071][LR: 0.00028191]\n",
            "20/12/09 12:10:20 - INFO - tape.training -   [Ep: 4.43][Iter: 1580][Time: 15.77s][Loss: 0.32474][LR: 0.00027912]\n",
            "20/12/09 12:10:36 - INFO - tape.training -   [Ep: 4.48][Iter: 1600][Time: 15.39s][Loss: 0.32474][LR: 0.00027632]\n",
            "20/12/09 12:10:51 - INFO - tape.training -   [Ep: 4.54][Iter: 1620][Time: 15.12s][Loss: 0.32052][LR: 0.00027352]\n",
            "20/12/09 12:11:06 - INFO - tape.training -   [Ep: 4.59][Iter: 1640][Time: 15.30s][Loss: 0.3158][LR: 0.00027072]\n",
            "20/12/09 12:11:22 - INFO - tape.training -   [Ep: 4.65][Iter: 1660][Time: 15.42s][Loss: 0.32277][LR: 0.00026792]\n",
            "20/12/09 12:11:37 - INFO - tape.training -   [Ep: 4.70][Iter: 1680][Time: 14.99s][Loss: 0.32983][LR: 0.00026512]\n",
            "20/12/09 12:11:52 - INFO - tape.training -   [Ep: 4.76][Iter: 1700][Time: 15.19s][Loss: 0.31976][LR: 0.00026232]\n",
            "20/12/09 12:12:08 - INFO - tape.training -   [Ep: 4.82][Iter: 1720][Time: 15.94s][Loss: 0.32021][LR: 0.00025952]\n",
            "20/12/09 12:12:23 - INFO - tape.training -   [Ep: 4.87][Iter: 1740][Time: 14.91s][Loss: 0.32326][LR: 0.00025672]\n",
            "20/12/09 12:12:38 - INFO - tape.training -   [Ep: 4.93][Iter: 1760][Time: 15.31s][Loss: 0.30972][LR: 0.00025392]\n",
            "20/12/09 12:12:53 - INFO - tape.training -   [Ep: 4.98][Iter: 1780][Time: 14.99s][Loss: 0.31101][LR: 0.00025112]\n",
            "20/12/09 12:12:57 - INFO - tape.training -   Train: [Loss: 0.32095]\n",
            "20/12/09 12:13:04 - INFO - tape.training -   Evaluation: [Loss: 0.44592]\n",
            "20/12/09 12:13:04 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 12:13:04 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-09-11-49-38_651743\n",
            "20/12/09 12:13:15 - INFO - tape.training -   [Ep: 5.04][Iter: 1800][Time: 11.92s][Loss: 0.30911][LR: 0.00024832]\n",
            "20/12/09 12:13:31 - INFO - tape.training -   [Ep: 5.10][Iter: 1820][Time: 15.14s][Loss: 0.31091][LR: 0.00024552]\n",
            "20/12/09 12:13:46 - INFO - tape.training -   [Ep: 5.15][Iter: 1840][Time: 15.65s][Loss: 0.32896][LR: 0.00024272]\n",
            "20/12/09 12:14:02 - INFO - tape.training -   [Ep: 5.21][Iter: 1860][Time: 15.97s][Loss: 0.33124][LR: 0.00023992]\n",
            "20/12/09 12:14:18 - INFO - tape.training -   [Ep: 5.27][Iter: 1880][Time: 16.25s][Loss: 0.32906][LR: 0.00023712]\n",
            "20/12/09 12:14:34 - INFO - tape.training -   [Ep: 5.32][Iter: 1900][Time: 15.24s][Loss: 0.32102][LR: 0.00023432]\n",
            "20/12/09 12:14:49 - INFO - tape.training -   [Ep: 5.38][Iter: 1920][Time: 15.73s][Loss: 0.32108][LR: 0.00023152]\n",
            "20/12/09 12:15:05 - INFO - tape.training -   [Ep: 5.43][Iter: 1940][Time: 15.72s][Loss: 0.32226][LR: 0.00022872]\n",
            "20/12/09 12:15:21 - INFO - tape.training -   [Ep: 5.49][Iter: 1960][Time: 15.53s][Loss: 0.32471][LR: 0.00022592]\n",
            "20/12/09 12:15:36 - INFO - tape.training -   [Ep: 5.55][Iter: 1980][Time: 15.42s][Loss: 0.32083][LR: 0.00022312]\n",
            "20/12/09 12:15:53 - INFO - tape.training -   [Ep: 5.60][Iter: 2000][Time: 16.40s][Loss: 0.31904][LR: 0.00022032]\n",
            "20/12/09 12:16:08 - INFO - tape.training -   [Ep: 5.66][Iter: 2020][Time: 15.49s][Loss: 0.32619][LR: 0.00021753]\n",
            "20/12/09 12:16:23 - INFO - tape.training -   [Ep: 5.71][Iter: 2040][Time: 14.81s][Loss: 0.32886][LR: 0.00021473]\n",
            "20/12/09 12:16:38 - INFO - tape.training -   [Ep: 5.77][Iter: 2060][Time: 14.95s][Loss: 0.31668][LR: 0.00021193]\n",
            "20/12/09 12:16:53 - INFO - tape.training -   [Ep: 5.83][Iter: 2080][Time: 14.88s][Loss: 0.31691][LR: 0.00020913]\n",
            "20/12/09 12:17:08 - INFO - tape.training -   [Ep: 5.88][Iter: 2100][Time: 15.25s][Loss: 0.32693][LR: 0.00020633]\n",
            "20/12/09 12:17:23 - INFO - tape.training -   [Ep: 5.94][Iter: 2120][Time: 15.42s][Loss: 0.31238][LR: 0.00020353]\n",
            "20/12/09 12:17:39 - INFO - tape.training -   [Ep: 5.99][Iter: 2140][Time: 16.00s][Loss: 0.31318][LR: 0.00020073]\n",
            "20/12/09 12:17:41 - INFO - tape.training -   Train: [Loss: 0.32089]\n",
            "20/12/09 12:17:48 - INFO - tape.training -   Evaluation: [Loss: 0.44431]\n",
            "20/12/09 12:17:48 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 12:17:48 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-09-11-49-38_651743\n",
            "20/12/09 12:18:02 - INFO - tape.training -   [Ep: 6.05][Iter: 2160][Time: 13.82s][Loss: 0.29767][LR: 0.00019793]\n",
            "20/12/09 12:18:17 - INFO - tape.training -   [Ep: 6.11][Iter: 2180][Time: 14.77s][Loss: 0.30665][LR: 0.00019513]\n",
            "20/12/09 12:18:32 - INFO - tape.training -   [Ep: 6.16][Iter: 2200][Time: 15.51s][Loss: 0.32592][LR: 0.00019233]\n",
            "20/12/09 12:18:48 - INFO - tape.training -   [Ep: 6.22][Iter: 2220][Time: 15.42s][Loss: 0.32847][LR: 0.00018953]\n",
            "20/12/09 12:19:03 - INFO - tape.training -   [Ep: 6.27][Iter: 2240][Time: 15.16s][Loss: 0.32832][LR: 0.00018673]\n",
            "20/12/09 12:19:18 - INFO - tape.training -   [Ep: 6.33][Iter: 2260][Time: 14.98s][Loss: 0.31925][LR: 0.00018393]\n",
            "20/12/09 12:19:34 - INFO - tape.training -   [Ep: 6.39][Iter: 2280][Time: 16.34s][Loss: 0.32049][LR: 0.00018113]\n",
            "20/12/09 12:19:50 - INFO - tape.training -   [Ep: 6.44][Iter: 2300][Time: 15.37s][Loss: 0.32177][LR: 0.00017833]\n",
            "20/12/09 12:20:05 - INFO - tape.training -   [Ep: 6.50][Iter: 2320][Time: 15.03s][Loss: 0.32889][LR: 0.00017553]\n",
            "20/12/09 12:20:20 - INFO - tape.training -   [Ep: 6.55][Iter: 2340][Time: 15.02s][Loss: 0.3196][LR: 0.00017273]\n",
            "20/12/09 12:20:35 - INFO - tape.training -   [Ep: 6.61][Iter: 2360][Time: 14.89s][Loss: 0.32091][LR: 0.00016993]\n",
            "20/12/09 12:20:50 - INFO - tape.training -   [Ep: 6.67][Iter: 2380][Time: 14.97s][Loss: 0.32598][LR: 0.00016713]\n",
            "20/12/09 12:21:04 - INFO - tape.training -   [Ep: 6.72][Iter: 2400][Time: 14.74s][Loss: 0.33379][LR: 0.00016433]\n",
            "20/12/09 12:21:19 - INFO - tape.training -   [Ep: 6.78][Iter: 2420][Time: 15.09s][Loss: 0.3148][LR: 0.00016153]\n",
            "20/12/09 12:21:34 - INFO - tape.training -   [Ep: 6.83][Iter: 2440][Time: 15.01s][Loss: 0.32107][LR: 0.00015873]\n",
            "20/12/09 12:21:50 - INFO - tape.training -   [Ep: 6.89][Iter: 2460][Time: 15.67s][Loss: 0.32645][LR: 0.00015594]\n",
            "20/12/09 12:22:05 - INFO - tape.training -   [Ep: 6.95][Iter: 2480][Time: 14.88s][Loss: 0.31118][LR: 0.00015314]\n",
            "20/12/09 12:22:20 - INFO - tape.training -   Train: [Loss: 0.32083]\n",
            "20/12/09 12:22:27 - INFO - tape.training -   Evaluation: [Loss: 0.43825]\n",
            "20/12/09 12:22:27 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 12:22:27 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-09-11-49-38_651743\n",
            "20/12/09 12:22:28 - INFO - tape.training -   [Ep: 7.00][Iter: 2500][Time:  1.00s][Loss: 0.30638][LR: 0.00015034]\n",
            "20/12/09 12:22:44 - INFO - tape.training -   [Ep: 7.06][Iter: 2520][Time: 15.86s][Loss: 0.31297][LR: 0.00014754]\n",
            "20/12/09 12:23:00 - INFO - tape.training -   [Ep: 7.11][Iter: 2540][Time: 15.61s][Loss: 0.31107][LR: 0.00014474]\n",
            "20/12/09 12:23:15 - INFO - tape.training -   [Ep: 7.17][Iter: 2560][Time: 15.72s][Loss: 0.32358][LR: 0.00014194]\n",
            "20/12/09 12:23:31 - INFO - tape.training -   [Ep: 7.23][Iter: 2580][Time: 15.68s][Loss: 0.32722][LR: 0.00013914]\n",
            "20/12/09 12:23:47 - INFO - tape.training -   [Ep: 7.28][Iter: 2600][Time: 15.61s][Loss: 0.32753][LR: 0.00013634]\n",
            "20/12/09 12:24:02 - INFO - tape.training -   [Ep: 7.34][Iter: 2620][Time: 15.57s][Loss: 0.32224][LR: 0.00013354]\n",
            "20/12/09 12:24:19 - INFO - tape.training -   [Ep: 7.39][Iter: 2640][Time: 16.41s][Loss: 0.3231][LR: 0.00013074]\n",
            "20/12/09 12:24:34 - INFO - tape.training -   [Ep: 7.45][Iter: 2660][Time: 15.12s][Loss: 0.3189][LR: 0.00012794]\n",
            "20/12/09 12:24:49 - INFO - tape.training -   [Ep: 7.51][Iter: 2680][Time: 15.47s][Loss: 0.32595][LR: 0.00012514]\n",
            "20/12/09 12:25:04 - INFO - tape.training -   [Ep: 7.56][Iter: 2700][Time: 15.19s][Loss: 0.31402][LR: 0.00012234]\n",
            "20/12/09 12:25:19 - INFO - tape.training -   [Ep: 7.62][Iter: 2720][Time: 15.09s][Loss: 0.32324][LR: 0.00011954]\n",
            "20/12/09 12:25:35 - INFO - tape.training -   [Ep: 7.67][Iter: 2740][Time: 15.94s][Loss: 0.33368][LR: 0.00011674]\n",
            "20/12/09 12:25:52 - INFO - tape.training -   [Ep: 7.73][Iter: 2760][Time: 16.31s][Loss: 0.32371][LR: 0.00011394]\n",
            "20/12/09 12:26:07 - INFO - tape.training -   [Ep: 7.79][Iter: 2780][Time: 15.78s][Loss: 0.31347][LR: 0.00011114]\n",
            "20/12/09 12:26:23 - INFO - tape.training -   [Ep: 7.84][Iter: 2800][Time: 15.31s][Loss: 0.3249][LR: 0.00010834]\n",
            "20/12/09 12:26:38 - INFO - tape.training -   [Ep: 7.90][Iter: 2820][Time: 15.69s][Loss: 0.32187][LR: 0.00010554]\n",
            "20/12/09 12:26:54 - INFO - tape.training -   [Ep: 7.95][Iter: 2840][Time: 15.02s][Loss: 0.30681][LR: 0.00010274]\n",
            "20/12/09 12:27:06 - INFO - tape.training -   Train: [Loss: 0.32068]\n",
            "20/12/09 12:27:13 - INFO - tape.training -   Evaluation: [Loss: 0.44109]\n",
            "20/12/09 12:27:13 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 12:27:13 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-09-11-49-38_651743\n",
            "20/12/09 12:27:16 - INFO - tape.training -   [Ep: 8.01][Iter: 2860][Time:  3.38s][Loss: 0.34364][LR: 9.9944e-05]\n",
            "20/12/09 12:27:31 - INFO - tape.training -   [Ep: 8.07][Iter: 2880][Time: 14.91s][Loss: 0.32502][LR: 9.7144e-05]\n",
            "20/12/09 12:27:46 - INFO - tape.training -   [Ep: 8.12][Iter: 2900][Time: 15.22s][Loss: 0.31789][LR: 9.4345e-05]\n",
            "20/12/09 12:28:01 - INFO - tape.training -   [Ep: 8.18][Iter: 2920][Time: 15.27s][Loss: 0.32861][LR: 9.1545e-05]\n",
            "20/12/09 12:28:17 - INFO - tape.training -   [Ep: 8.23][Iter: 2940][Time: 15.33s][Loss: 0.32931][LR: 8.8746e-05]\n",
            "20/12/09 12:28:31 - INFO - tape.training -   [Ep: 8.29][Iter: 2960][Time: 14.75s][Loss: 0.32602][LR: 8.5946e-05]\n",
            "20/12/09 12:28:46 - INFO - tape.training -   [Ep: 8.35][Iter: 2980][Time: 14.92s][Loss: 0.31884][LR: 8.3147e-05]\n",
            "20/12/09 12:29:01 - INFO - tape.training -   [Ep: 8.40][Iter: 3000][Time: 15.11s][Loss: 0.32454][LR: 8.0347e-05]\n",
            "20/12/09 12:29:18 - INFO - tape.training -   [Ep: 8.46][Iter: 3020][Time: 16.40s][Loss: 0.3211][LR: 7.7548e-05]\n",
            "20/12/09 12:29:34 - INFO - tape.training -   [Ep: 8.51][Iter: 3040][Time: 15.97s][Loss: 0.3248][LR: 7.4748e-05]\n",
            "20/12/09 12:29:50 - INFO - tape.training -   [Ep: 8.57][Iter: 3060][Time: 16.18s][Loss: 0.31147][LR: 7.1948e-05]\n",
            "20/12/09 12:30:06 - INFO - tape.training -   [Ep: 8.63][Iter: 3080][Time: 15.85s][Loss: 0.32218][LR: 6.9149e-05]\n",
            "20/12/09 12:30:21 - INFO - tape.training -   [Ep: 8.68][Iter: 3100][Time: 15.54s][Loss: 0.33271][LR: 6.6349e-05]\n",
            "20/12/09 12:30:37 - INFO - tape.training -   [Ep: 8.74][Iter: 3120][Time: 15.31s][Loss: 0.32645][LR: 6.355e-05]\n",
            "20/12/09 12:30:53 - INFO - tape.training -   [Ep: 8.79][Iter: 3140][Time: 15.91s][Loss: 0.31265][LR: 6.075e-05]\n",
            "20/12/09 12:31:08 - INFO - tape.training -   [Ep: 8.85][Iter: 3160][Time: 15.26s][Loss: 0.32706][LR: 5.7951e-05]\n",
            "20/12/09 12:31:23 - INFO - tape.training -   [Ep: 8.91][Iter: 3180][Time: 15.32s][Loss: 0.32066][LR: 5.5151e-05]\n",
            "20/12/09 12:31:39 - INFO - tape.training -   [Ep: 8.96][Iter: 3200][Time: 15.82s][Loss: 0.31205][LR: 5.2352e-05]\n",
            "20/12/09 12:31:49 - INFO - tape.training -   Train: [Loss: 0.32069]\n",
            "20/12/09 12:31:56 - INFO - tape.training -   Evaluation: [Loss: 0.43976]\n",
            "20/12/09 12:31:56 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 12:31:56 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-09-11-49-38_651743\n",
            "20/12/09 12:32:02 - INFO - tape.training -   [Ep: 9.02][Iter: 3220][Time:  5.39s][Loss: 0.26465][LR: 4.9552e-05]\n",
            "20/12/09 12:32:17 - INFO - tape.training -   [Ep: 9.08][Iter: 3240][Time: 15.20s][Loss: 0.29876][LR: 4.6753e-05]\n",
            "20/12/09 12:32:32 - INFO - tape.training -   [Ep: 9.13][Iter: 3260][Time: 15.47s][Loss: 0.31138][LR: 4.3953e-05]\n",
            "20/12/09 12:32:47 - INFO - tape.training -   [Ep: 9.19][Iter: 3280][Time: 15.04s][Loss: 0.321][LR: 4.1153e-05]\n",
            "20/12/09 12:33:02 - INFO - tape.training -   [Ep: 9.24][Iter: 3300][Time: 14.99s][Loss: 0.32549][LR: 3.8354e-05]\n",
            "20/12/09 12:33:18 - INFO - tape.training -   [Ep: 9.30][Iter: 3320][Time: 15.89s][Loss: 0.32661][LR: 3.5554e-05]\n",
            "20/12/09 12:33:34 - INFO - tape.training -   [Ep: 9.36][Iter: 3340][Time: 15.40s][Loss: 0.32333][LR: 3.2755e-05]\n",
            "20/12/09 12:33:49 - INFO - tape.training -   [Ep: 9.41][Iter: 3360][Time: 15.17s][Loss: 0.323][LR: 2.9955e-05]\n",
            "20/12/09 12:34:04 - INFO - tape.training -   [Ep: 9.47][Iter: 3380][Time: 15.00s][Loss: 0.32519][LR: 2.7156e-05]\n",
            "20/12/09 12:34:19 - INFO - tape.training -   [Ep: 9.52][Iter: 3400][Time: 15.31s][Loss: 0.3162][LR: 2.4356e-05]\n",
            "20/12/09 12:34:36 - INFO - tape.training -   [Ep: 9.58][Iter: 3420][Time: 16.45s][Loss: 0.31506][LR: 2.1557e-05]\n",
            "20/12/09 12:34:51 - INFO - tape.training -   [Ep: 9.64][Iter: 3440][Time: 15.67s][Loss: 0.32143][LR: 1.8757e-05]\n",
            "20/12/09 12:35:06 - INFO - tape.training -   [Ep: 9.69][Iter: 3460][Time: 14.87s][Loss: 0.32829][LR: 1.5957e-05]\n",
            "20/12/09 12:35:22 - INFO - tape.training -   [Ep: 9.75][Iter: 3480][Time: 15.38s][Loss: 0.32692][LR: 1.3158e-05]\n",
            "20/12/09 12:35:38 - INFO - tape.training -   [Ep: 9.80][Iter: 3500][Time: 16.23s][Loss: 0.31375][LR: 1.0358e-05]\n",
            "20/12/09 12:35:52 - INFO - tape.training -   [Ep: 9.86][Iter: 3520][Time: 14.68s][Loss: 0.32131][LR: 7.5588e-06]\n",
            "20/12/09 12:36:09 - INFO - tape.training -   [Ep: 9.91][Iter: 3540][Time: 16.55s][Loss: 0.31515][LR: 4.7592e-06]\n",
            "20/12/09 12:36:25 - INFO - tape.training -   [Ep: 9.97][Iter: 3560][Time: 15.90s][Loss: 0.30957][LR: 1.9597e-06]\n",
            "20/12/09 12:36:33 - INFO - tape.training -   Train: [Loss: 0.32074]\n",
            "20/12/09 12:36:40 - INFO - tape.training -   Evaluation: [Loss: 0.43997]\n",
            "20/12/09 12:36:40 - INFO - tape.training -   ** ** * Saving trained model ** ** * \n",
            "20/12/09 12:36:40 - INFO - tape.training -   Saving model checkpoint to results/stability_resnet_20-12-09-11-49-38_651743\n",
            "20/12/09 12:36:40 - INFO - tape.training -   Finished training after 10 epochs.\n",
            "20/12/09 12:36:40 - Level 35 - tape.training -   Best Val Loss: 0.43269670009613037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL4bl_DFfFNl",
        "outputId": "2208b194-14d1-4257-b4f6-ef30a18548db"
      },
      "source": [
        "!tape-eval resnet stability /content/results/stability_resnet_20-12-09-11-49-38_651743 --metrics mse mae spearmanr  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20/12/09 12:38:24 - INFO - tape.training -   device: cuda n_gpu: 1\n",
            "20/12/09 12:38:24 - INFO - tape.models.modeling_utils -   loading configuration file /content/results/stability_resnet_20-12-09-11-49-38_651743/config.json\n",
            "20/12/09 12:38:24 - INFO - tape.models.modeling_utils -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 32,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 64,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 4096,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 3,\n",
            "  \"num_labels\": -1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30\n",
            "}\n",
            "\n",
            "20/12/09 12:38:24 - INFO - tape.models.modeling_utils -   loading weights file /content/results/stability_resnet_20-12-09-11-49-38_651743/pytorch_model.bin\n",
            "Evaluation: 100% 13/13 [00:02<00:00,  5.96it/s]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[:, None]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[None, :]\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
            "  return (a < x) & (x < b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
            "  return (a < x) & (x < b)\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
            "  cond2 = cond0 & (x <= _a)\n",
            "20/12/09 12:38:29 - INFO - tape.training -   mse: 0.8436692953109741mae: 0.8278120160102844spearmanr: nan\n",
            "{'mse': 0.8436693, 'mae': 0.827812, 'spearmanr': nan}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}